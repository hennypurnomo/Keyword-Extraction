{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, re, string, itertools\n",
    "from lxml import etree\n",
    "import pickle, json\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "from nltk.stem.porter import *\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents, sent_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk.chunk import tree2conlltags\n",
    "from pandas import DataFrame\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def create_pickle(data, name):\n",
    "    with open('%s.pickle' % name,'wb') as handle:\n",
    "        result=pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return result\n",
    "\n",
    "def open_pickle(name):\n",
    "    with open('%s.pickle' % name,'rb') as handle:\n",
    "        result=pickle.load(handle)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is depends\n",
    "#dont remove 's\n",
    "def clean_xml(text): \n",
    "\n",
    "    clean=re.sub(\"(\\n){1,}\",'', text) #remove brackets\n",
    "    #clean=re.sub(\"\\\\'s\",\" 's\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n"
     ]
    }
   ],
   "source": [
    "##347 files\n",
    "\n",
    "def load_xml(path):\n",
    "    all_files=[]\n",
    "    for file in path:\n",
    "        \n",
    "        root=etree.parse(file, parser=etree.XMLParser(encoding='utf-8', recover=True)).getroot()\n",
    "        \n",
    "        #create a list that contain a dictionary for label per document\n",
    "        dict_doc={'doc_id': None, 'title': None, 'text': None}\n",
    "        \n",
    "        file_id=os.path.basename(file.rstrip('.S'))\n",
    "        dict_doc['doc_id']=file_id\n",
    "        \n",
    "        title=[]\n",
    "        text=[]\n",
    "        \n",
    "        #extract the headline \n",
    "        for head in root.findall('HEAD'):\n",
    "            for s in head:\n",
    "                #put punctuation if headline more than one sentence\n",
    "                title.append(clean_xml(s.text))\n",
    "        \n",
    "        for h3 in root.findall('H3'):\n",
    "            for ti in h3:\n",
    "                for s in ti:\n",
    "                    title.append(clean_xml(s.text))\n",
    "                    \n",
    "        for headline in root.findall('HEADLINE'):\n",
    "            for p in headline:\n",
    "                for s in p:\n",
    "                    title.append(clean_xml(s.text))\n",
    "                  \n",
    "        for headline in root.findall('HEADLINE'):\n",
    "            for s in headline:\n",
    "                title.append(clean_xml(s.text))\n",
    "                \n",
    "        for hl in root.findall('HL'):\n",
    "            for s in hl:\n",
    "                title.append(clean_xml(s.text))\n",
    "        \n",
    "        for t in root.findall('TEXT'):\n",
    "            for s in t:\n",
    "                text.append(clean_xml(s.text))\n",
    "        \n",
    "        for t in root.findall('TEXT'):\n",
    "            for p in t:\n",
    "                for s in p:\n",
    "                    text.append(clean_xml(s.text))\n",
    "                    \n",
    "        dict_doc['title']=' '.join(title)\n",
    "        dict_doc['text']=' '.join(text)\n",
    "    \n",
    "        all_files.append(dict_doc)\n",
    "    return all_files\n",
    "\n",
    "train_directory=glob.glob('./data/duc2002/xml/*/*.S') #need to clean the title! still dirty\n",
    "#train_directory=glob.glob('./data/duc2002/xml/d120i/*.S') #have trouble in parsing\n",
    "train_raw=load_xml(train_directory)\n",
    "print(len(train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(raw_data):\n",
    "    train_data=[]\n",
    "    for doc in raw_data:\n",
    "        train_data.append(doc['text'])\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create candidate per sentence\n",
    "#TO-DO: filtering candidate from unwanted phrase\n",
    "def extract_candidate(raw_data):\n",
    "    sentence_candidate=[]\n",
    "    for doc in raw_data:\n",
    "        sentences=[sent for sent in sent_tokenize(doc['text'])]\n",
    "        sentence_candidate.append(sentences)\n",
    "    return sentence_candidate\n",
    "\n",
    "candidates=extract_candidate(train_raw)\n",
    "#print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Governor Deukmejian has rightly called the Legislature into special session to take necessary action after last Tuesday's earthquake.\", 'But the Governor should cease  distancing himself from the issue of what caused the collapse of the Nimitz Freeway in Oakland.', \"Vulnerable because of his past opposition to a gasoline tax increase that would augment transportation funding, the Governor seems more interested in diverting blame than in learning everything possible from Tuesday's disaster.\", 'The challenge is to rebuild  so that hundreds of thousands of commuters can get back to work.', 'The special legislative session should consider a temporary gasoline tax increase to fund highway reconstruction.']\n"
     ]
    }
   ],
   "source": [
    "###find the reason file is different with the text\n",
    "from collections import OrderedDict\n",
    "def extract_goldlabel(directory):\n",
    "    all_labels=[]\n",
    "    for file in directory:\n",
    "        #ORDER is random, put on dictionary\n",
    "        root=etree.parse(file, parser=etree.XMLParser(encoding='utf-8', recover=True)).getroot()    \n",
    "        #check if title of document exists in candidate\n",
    "        #per_group=[]\n",
    "        per_group={}\n",
    "        for sum_text in root.findall('SUM'):\n",
    "            file_id=sum_text.get('DOCREF')\n",
    "            doc=[sent for sent in sent_tokenize(clean_xml(sum_text.text))]\n",
    "            per_group[file_id]=doc\n",
    "        #sort per group\n",
    "        ordered_files=OrderedDict(sorted(per_group.items(), key=lambda x: x[0]))\n",
    "        ordered_labels=[label for label in ordered_files.values()]\n",
    "        all_labels.append(ordered_labels)\n",
    "    return list(chain.from_iterable(all_labels))\n",
    "\n",
    "train_label_directory=glob.glob('./data/duc2002/label/version1/*/perdocs')\n",
    "labels=extract_goldlabel(train_label_directory)\n",
    "#print(label)\n",
    "all_n=[]\n",
    "for doc in labels:\n",
    "    #all_n.append(len(doc))\n",
    "    all_n.append(doc)\n",
    "print(all_n[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"George Deukmejian is right to call the Legislature into special session within the next two weeks to deal with the effects of last Tuesday's Northern California earthquake.\", 'The governor is wrong, however, in his campaign to distance himself from the California Department of Transportation on the issue of what caused the Nimitz Freeway in Oakland to collapse, and what could or should have been done to have prevented it.', 'This has the earmarks of a preemptive defense against any allegation that California stinted on highway reinforcement because transportation funds have been short during his administration, possibly because he had opposed a gasoline tax increase .', 'In the Bay Area, that includes hundreds of thousands of commuters who did not suffer personal damage, but face massive obstacles in getting to work .', 'This has the earmarks of a preemptive defense against any allegation that California stinted on highway reinforcement because transportation funds have been short during his administration, possibly because he had opposed a gasoline tax increase .']\n",
      "[0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def create_label(candidates, label):\n",
    "    matched_sentences=[]\n",
    "    for n_doc in range(0, len(candidates)):\n",
    "        doc=[]\n",
    "        for n_label in labels[n_doc]:\n",
    "            label=[]\n",
    "            for n_sent in candidates[n_doc]:\n",
    "                n_match = len(set([x for x in n_sent.split(\" \")]).intersection([x for x in n_label.split(\" \")]))\n",
    "                label.append((n_sent, n_match))\n",
    "                order = max(label, key = lambda x:x[1])\n",
    "            #check order if exist, order[1], or next\n",
    "            doc.append(order[0])\n",
    "        matched_sentences.append(doc)\n",
    "        \n",
    "    print(matched_sentences[8])\n",
    "    all_labels=[]\n",
    "    for n_doc in range(0, len(candidates)):\n",
    "        doc=[]\n",
    "        for n_sent in candidates[n_doc]:\n",
    "            #doc.append(n_sent)\n",
    "            if n_sent not in matched_sentences[n_doc]:\n",
    "                #doc.append(n_sent)\n",
    "                doc.append(0)\n",
    "            else:\n",
    "                doc.append(1)\n",
    "        all_labels.append(doc)\n",
    "    '''   \n",
    "    all_n=[]\n",
    "    for doc in all_labels:\n",
    "        all_n.append(doc.count(1))\n",
    "    '''\n",
    "    return all_labels[8]\n",
    "\n",
    "print(create_label(candidates, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gg', 3), ('h', 2), ('a', 1)]\n"
     ]
    }
   ],
   "source": [
    "t=[('a',1),('h',2),('gg',3)]\n",
    "u=[number for number in enumerate(t)]\n",
    "h=['a','b','v']\n",
    "order = sorted(t, key = lambda x:x[1], reverse = True)\n",
    "\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 8, 18, 8]\n"
     ]
    }
   ],
   "source": [
    "def create_label(candidates, label):\n",
    "    matched_sentences=[]\n",
    "    all_labels=[]\n",
    "    for n_doc in range(0, len(candidates)):\n",
    "        doc=[]\n",
    "        for n_label in labels[n_doc]:\n",
    "            label = []\n",
    "            index = []\n",
    "            sentence_position = [number for number in enumerate(candidates[n_doc])]\n",
    "            for element in sentence_position:\n",
    "                n_match = len(set([x for x in element[1].split(\" \")]).intersection([x for x in n_label.split(\" \")]))\n",
    "                label.append((element[0], element[1], n_match))\n",
    "                order = max(label, key = lambda x:x[2]) # default by max\n",
    "                #order = sorted(label, key = lambda x:x[2], reverse = True) #order by the highest matches\n",
    "                selected_position = order[0]\n",
    "                del candidates[n_doc][selected_position]\n",
    "                selected_position.append(order[0][0])\n",
    "                  \n",
    "                ##append all order [0] if position in selected postion\n",
    "            #check if the candidate label is exist\n",
    "            #doc.append(selected_position)\n",
    "            doc.append(order[1])\n",
    "        matched_sentences.append(doc)\n",
    "        '''\n",
    "        per_doc=[]\n",
    "        for n_sent in candidates[n_doc]:\n",
    "            #doc.append(n_sent)\n",
    "            if n_sent in matched_sentences[n_doc]:\n",
    "                per_doc.append(n_sent)\n",
    "                #per_doc.append(1)\n",
    "            #else:\n",
    "                #per_doc.append(0)\n",
    "        all_labels.append(per_doc)\n",
    "        '''\n",
    "    '''   \n",
    "    all_n=[]\n",
    "    for doc in all_labels:\n",
    "        all_n.append(doc.count(1))\n",
    "    '''\n",
    "    return matched_sentences[8]\n",
    "\n",
    "print(create_label(candidates, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    \n",
    "    all_labels=[]\n",
    "    for n_doc in range(len(candidates)):\n",
    "        doc=[]\n",
    "        for n_sent in candidates[n_doc]:\n",
    "            if n_sent in matched_sentences[n_doc]:\n",
    "                doc.append(1)\n",
    "            else:\n",
    "                doc.append(0)\n",
    "        all_labels.append(doc)\n",
    "    '''\n",
    "    '''\n",
    "    #####temporary\n",
    "    all_n=[]\n",
    "    for doc in all_labels:\n",
    "        all_n.append(doc.count(1))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_tfidf(corpus):\n",
    "    \n",
    "    #porter stemmer\n",
    "    stemmer=PorterStemmer()\n",
    "\n",
    "    class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "        def build_tokenizer(self):\n",
    "            tokenizer=super(TfidfVectorizer, self).build_tokenizer()\n",
    "            return lambda doc: (stemmer.stem(token) for token in tokenizer(doc) if token not in stop_words)\n",
    "    \n",
    "    stop_words=text.ENGLISH_STOP_WORDS\n",
    "    \n",
    "    #pattern=\"(?u)\\\\b[\\\\w-]+\\\\b\"\n",
    "    tfidf=StemmedTfidfVectorizer(ngram_range=(1,1), stop_words=stop_words,\n",
    "                                token_pattern=r\"(?u)\\b[A-Za-z-]+\\b\")\n",
    "    \n",
    "    matrix=tfidf.fit_transform(corpus)\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "\n",
    "    #how to print tf-idf from https://stackoverflow.com/questions/34449127/\n",
    "    #sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "    candidates=[]\n",
    "    for doc in range(0,len(corpus)):\n",
    "        feature_index=matrix[doc,:].nonzero()[1]\n",
    "        tfidf_doc=zip(feature_index, [matrix[doc, x] for x in feature_index])\n",
    "        #remove character s from 's\n",
    "        names_tfidf=[(w, s) for w, s in [(feature_names[i], s) for (i, s) in tfidf_doc] if w != \"s\"]\n",
    "        candidates.append(names_tfidf)\n",
    "    \n",
    "    #this is the candidates per document\n",
    "    #vocab_perdoc=tfidf.inverse_transform(matrix)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(candidates, label):\n",
    "    y_label=[]    \n",
    "    for n_doc in range(0, len(candidates)):\n",
    "        doc=[]\n",
    "        for n_sent in range(len(candidates[n_doc])):\n",
    "            #summary_labels=label[n_doc]\n",
    "            summary_labels=label[n_doc]\n",
    "            #not exact matching, just overlapping \n",
    "            matches=[]\n",
    "            for lab in summary_labels:\n",
    "            #if candidates[n_doc][n_sent] in summary_labels:\n",
    "                #tokens=word_tokenize(lab)\n",
    "                if re.search(r'%s' % lab, candidates[n_doc][n_sent]):\n",
    "                    doc.append(1)\n",
    "                else:\n",
    "                    doc.append(0)\n",
    "        y_label.append(doc)\n",
    "    return y_label\n",
    "print(create_label(candidates, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(raw_data, candidates, tfidf):\n",
    "    #can be used without using len\n",
    "    def feature_position(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_sent in range(len(candidates[n_doc])):\n",
    "                position=float(\"{0:.2F}\".format((n_sent+1)/len(candidates[n_doc])))\n",
    "                doc.append(position)\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def first_sentence(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for el in range(len(candidates[n_doc])):\n",
    "                if el==0:\n",
    "                    doc.append(1)\n",
    "                else:\n",
    "                    doc.append(0)\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def sentence_length(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(t)):\n",
    "            doc=[]\n",
    "            for el in range(len(t[n_doc])):\n",
    "                sentence_length=len(t[n_doc][el])\n",
    "                doc.append(sentence_length)\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def is_quote(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(t)):\n",
    "            doc=[]\n",
    "            for el in range(len(t[n_doc])):\n",
    "                if re.search(r\"(\\\"|\\').*(\\\"|\\')\",t[n_doc][el]):\n",
    "                    doc.append(1)\n",
    "                else:\n",
    "                    doc.append(0)\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def is_number(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(t)):\n",
    "            doc=[]\n",
    "            for el in range(len(t[n_doc])):\n",
    "                if re.search(r\"\\d\",t[n_doc][el]):\n",
    "                    doc.append(1)\n",
    "                else:\n",
    "                    doc.append(0)\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "\n",
    "    def tfidf(candidates, tfidf):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_sent in range(len(candidates[n_doc])):\n",
    "                matched_word=[]\n",
    "                total=0\n",
    "                counter=0\n",
    "                for (word, value) in tf_idf[n_doc]:\n",
    "                    if word in candidates[n_doc][n_sent].lower():\n",
    "                        total+=value\n",
    "                        counter+=1\n",
    "                        matched_word.append(total/(counter))\n",
    "                doc.append(float(\"{0:.4F}\".format(matched_word[-1])))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def doc_tfidf(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in candidates:\n",
    "            tf_idf=calculate_ngram_tfidf(n_doc)\n",
    "            doc=[]\n",
    "            for n_sent in tf_idf:\n",
    "                sent=[]\n",
    "                values=[]\n",
    "                total=0\n",
    "                for (word, value) in n_sent:\n",
    "                    total+=value\n",
    "                    counter+=1\n",
    "                    values.append(total/len(n_sent))\n",
    "                    sent.append(values)\n",
    "                doc.append(float(\"{0:.4F}\".format(values[-1])))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def propername_count(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_sent in range(len(candidates[n_doc])):\n",
    "                #CHECK with NNP\n",
    "                doc.append(len(re.findall(r\"\\b[A-Z]\\w+\\b\",candidates[n_doc][n_sent])))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def uppercase_count(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_sent in range(len(candidates[n_doc])):\n",
    "                #CHECK with NNP\n",
    "                doc.append(len(re.findall(r\"\\b[A-Z]+\\b\",candidates[n_doc][n_sent])))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def cuephrase_count(candidates)\n",
    "        cuephrase_file=open('./duc2002/cue_phrases.txt', encoding='utf-8').read()\n",
    "        cue_phrase=[word.rstrip(\" \") for word in cuephrase_file.split(\"\\n\")]\n",
    "        feature=[]\n",
    "        for n_doc in candidates:\n",
    "            doc=[]\n",
    "            for n_sent in n_doc:\n",
    "                matches=[]\n",
    "                for phrase in cue_phrase:\n",
    "                    #refine overlapping cue phrase, like by and by the time\n",
    "                    pattern=re.compile(r'%s' % phrase, re.IGNORECASE)\n",
    "                    if pattern.findall(n_sent):\n",
    "                        matches.append(1) #phrase\n",
    "                    else:\n",
    "                        matches.append(0)\n",
    "                doc.append(matches.count(1))\n",
    "                #doc.append(matches)\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def title_score(candidates, raw_data):\n",
    "        feature=[]\n",
    "        title=[doc['title'] for doc in raw_data]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "\n",
    "            tokenized_title=[word.lower() for word in word_tokenize(title[n_doc]) if re.search(r\"\\w\", word)]\n",
    "            for n_sent in range(len(candidates[n_doc])):\n",
    "                #tokenize candidates match with title\n",
    "                matched_words=[word for word in word_tokenize(candidates[n_doc][n_sent].lower()) if word in tokenized_title]\n",
    "                doc.append(len(matched_words))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    \n",
    "    \n",
    "tf_idf=calculate_ngram_tfidf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###testing part\n",
    "import re\n",
    "corpus=['Pljeskavica is made of ground pork and onions, and it is served on 5858 bread and eaten with the hands.It is sold at fast-food restaurants across the country and $45 costs about a dollar.', \n",
    "   \"``In fact, this is a clash between the Big Mac and Pljeskavica,'' said an official of Genex, Yugoslavia's largest state-run enterprise that will operate the McDonald's.\"]\n",
    "\n",
    "candidates=[['Pljeskavica is made of ground pork and onions, and it is served on 5858 bread and eaten with the hands.',\n",
    "             'It is sold at fast-food restaurants across the country and $45 costs about a dollar.'],\n",
    "            [\"``For this reason, In fact, this is a clash between the Big Mac and Pljeskavica,'' said an official of Genex, Yugoslavia's largest state-run enterprise that will operate the McDonald's.\",\n",
    "           \"Besides that, missing you! By the time, love you. Moreover, hate you MAD\"]]\n",
    "title=['Pljeskavica Is Made Of Ground Pork','Love You, Hate You']\n",
    "\n",
    "feature=[]\n",
    "for n_doc in range(len(candidates)):\n",
    "    doc=[]\n",
    "    for n_sent in range(len(candidates[n_doc])):\n",
    "        doc.append(len(re.findall(r\"\\b[A-Z]+\\b\",candidates[n_doc][n_sent])))\n",
    "    feature.append(doc)\n",
    "   \n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###sorting candidates based on n sentences\n",
    "def get_top_candidates(candidates_list, number_sentences):\n",
    "    best_candidates=[]\n",
    "    for doc in candidates_list:\n",
    "        #sort candidates by tf-idf value\n",
    "        sorted_candidates=sorted(doc, key=lambda x: x[1], reverse=True)[:number_sentences]\n",
    "        #best_candidates.append(sorted_candidates)\n",
    "        best_candidates.append([x for x,_ in sorted_candidates])\n",
    "    return best_candidates\n",
    "\n",
    "def calculate_fmeasure(candidates_list, gold_data):\n",
    "    #true positive\n",
    "    all_matches=[]\n",
    "    for index in range(len(candidates_list)):\n",
    "        #store all measure per document in dic\n",
    "        value={'tp': None, 'fp': None, 'fn': None, 'gold': None}\n",
    "        value['gold']=len(gold_data[index])\n",
    "        #counter true positive per document\n",
    "        true_positive=0\n",
    "        #loop between elements\n",
    "        for element_candidate in candidates_list[index]:                    \n",
    "            for element_goldkeyphrase in gold_data[index]:\n",
    "                #matched predicted keyword in gold keyphrase\n",
    "                if element_candidate==element_goldkeyphrase:\n",
    "                    #matches_perdoc.append(element_candidate)\n",
    "                    true_positive+=1\n",
    "            #if need the detail of evaluation\n",
    "            value['tp']=int(true_positive) #matched pair\n",
    "            value['fp']=int(15-true_positive) #depend how many keyword should we use\n",
    "            value['fn']=int(value['gold']-value['tp'])\n",
    "        #return all metrics per document\n",
    "        all_matches.append(value)\n",
    "\n",
    "    true_positive=sum(doc['tp'] for doc in all_matches)\n",
    "    false_positive=sum(doc['fp'] for doc in all_matches)\n",
    "    false_negative=sum(doc['fn'] for doc in all_matches)\n",
    "    \n",
    "    #matched/total top n\n",
    "    precision=float(true_positive/(false_positive+true_positive))\n",
    "    #matched/total gold standard\n",
    "    recall=float(true_positive/(false_negative+true_positive))\n",
    "    # calculate with micro averagedprecision\n",
    "    #f_measure=2*(precision*recall)/(precision+recall)\n",
    "    f_measure=float(\"{0:.2F}\".format(2*(precision*recall)/(precision+recall)*100))\n",
    "    return f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##temp\n",
    "title=calculate_term_frequency(title_raw)\n",
    "    feature=[]\n",
    "    for n_doc in range(len(candidates)):\n",
    "        doc=[]\n",
    "        for n_cand in range(len(candidates[n_doc])):\n",
    "            title_perdoc=[feature for (feature, value) in title[n_doc]]\n",
    "            abstract_perdoc=[feature for (feature, value) in abstract[n_doc]]\n",
    "            introduction_perdoc=[feature for (feature, value) in introduction[n_doc]]\n",
    "            if candidates[n_doc][n_cand][0] in title_perdoc:\n",
    "                binary_title=1\n",
    "                value=[value for (feature, value) in title[n_doc] if feature in candidates[n_doc][n_cand][0]]\n",
    "                frequency_title=value[0]\n",
    "            else:\n",
    "                binary_title=0\n",
    "                frequency_title=0\n",
    "            doc.append(((binary_title)))\n",
    "        feature.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautifulsoup version\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def load_xml(path):\n",
    "    all_files=[]\n",
    "    for file in path:\n",
    "        soup=BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        #create a list that contain a dictionary for label per document\n",
    "        dict_doc={'doc_id': None, 'title': None, 'full_text': None}\n",
    "        \n",
    "        file_id=os.path.basename(file.rstrip('.S'))\n",
    "        dict_doc['doc_id']=file_id\n",
    "        \n",
    "        title=[]\n",
    "        text=[]\n",
    "        \n",
    "        #extract the headline \n",
    "        #for head in soup.find_all('HEAD'):\n",
    "        #    #put punctuation if headline more than one sentence\n",
    "        #    title.append(head.find(\"s\", recursive=False).string)\n",
    "        \n",
    "        for s in soup.findAll('s'):\n",
    "            if s.parent.name=='HEAD':\n",
    "                title.append(s.string)\n",
    "        \n",
    "        for h3 in soup.find_all('H3'):\n",
    "            for ti in h3:\n",
    "                for s in ti:\n",
    "                    title.append(s.text())\n",
    "                    \n",
    "        for headline in soup.find_all('HEADLINE'):\n",
    "            for p in headline:\n",
    "                for s in p:\n",
    "                    title.append(s.text)\n",
    "                  \n",
    "        for headline in soup.find_all('HEADLINE'):\n",
    "            for s in headline:\n",
    "                title.append(s.text)\n",
    "                \n",
    "        for hl in soup.find_all('HL'):\n",
    "            for s in hl:\n",
    "                title.append(s.text)\n",
    "                    \n",
    "        dict_doc['title']=c;eatitle\n",
    "        #dict_doc['text']=' '.join(text)\n",
    "    \n",
    "        all_files.append(dict_doc)\n",
    "    return all_files\n",
    "\n",
    "train_directory=glob.glob('./duc2002/xml/dummy/d065j/*.S')\n",
    "#train_directory=glob.glob('./duc2002/xml/**/*.S')\n",
    "train_raw=load_xml(train_directory)\n",
    "print(train_raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
