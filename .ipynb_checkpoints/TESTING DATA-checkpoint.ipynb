{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, re, string, itertools\n",
    "import logging\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "from nltk.stem.porter import *\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk.chunk import tree2conlltags\n",
    "from pandas import DataFrame\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn import svm                                       #library for creating the classifier, SVM\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input_list):\n",
    "    result=[]\n",
    "    #remove unwanted character per line\n",
    "    for line in input_list:\n",
    "        clean=re.sub(\"(\\.)?\\n\",'', line) #remove \\n\n",
    "        clean=re.sub(\"('s)\",'', clean) #remove \\n\n",
    "        clean=re.sub(\"\\[([0-9]{1,2}\\,?\\s?)+\\]\",'', clean) #remove [2]\n",
    "        clean=re.sub(\"\\(([0-9]{1,2}\\,?\\s?)+\\)\",'', clean) #remove (2)\n",
    "            #remove fig. 2 etc, need improvement to catch the sentence after it\n",
    "        clean=re.sub(\"([Ff]ig.|[Ff]igure|[Tt]ab.|[Tt]able)\\s?[0-9]{1,2}\",'', clean) #remove fig. 2 etc\n",
    "        result.append(clean)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'doc_id': 'C-1', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Scalable Grid Service Discovery Based on UDDI*'}, {'doc_id': 'I-1', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Aborting Tasks in BDI Agents'}, {'doc_id': 'J-1', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Generalized Trade Reduction Mechanisms'}, {'doc_id': 'H-2', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Personalized Query Expansion for the Web'}, {'doc_id': 'J-2', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Worst-Case Optimal Redistribution of VCG Payments'}, {'doc_id': 'C-3', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Self-Adaptive Applications on the Grid'}, {'doc_id': 'H-3', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Using Query Contexts in Information Retrieval'}, {'doc_id': 'J-3', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Budget Optimization in Search-Based Advertising Auctions'}, {'doc_id': 'C-4', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Intra-flow Loss Recovery and Control for VolP'}, {'doc_id': 'H-4', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Towards Task-based Personal Information Management Evaluations'}, {'doc_id': 'I-4', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Meta-Level Coordination for Solving Negotiation Chains in Semi-Cooperative Multi-Agent Systems'}, {'doc_id': 'J-4', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Revenue Analysis of a Family of Ranking Rules for'}, {'doc_id': 'H-5', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Utility-based Information Distillation Over Temporally Sequenced Documents'}, {'doc_id': 'I-5', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Towards Self-organising Agent-based Resource Allocation in a Multi-Server Environment'}, {'doc_id': 'C-6', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Design and Implementation of a Distributed Content Management System'}, {'doc_id': 'I-6', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Dynamic Semantics for Agent Communication Languages'}, {'doc_id': 'H-7', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Efficient Bayesian Hierarchical User Modeling for Recommendation Systems'}, {'doc_id': 'I-7', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Commitment and Extortion'}, {'doc_id': 'J-7', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'The Role of Compatibility in the Diffusion of Technologies Through Social Networks'}, {'doc_id': 'C-8', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Operation Context and Context-based Operational Transformation'}, {'doc_id': 'H-8', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Robust Test Collections for Retrieval Evaluation'}, {'doc_id': 'J-8', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Strong Equilibrium in Cost Sharing Connection Games∗ Amir Epstein'}, {'doc_id': 'C-9', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'EDAS: Providing an Environment for Decentralized Adaptive Services'}, {'doc_id': 'H-9', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Learn from Web Search Logs to Organize Search Results'}, {'doc_id': 'I-9', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Temporal Linear Logic as a Basis for Flexible Agent Interactions'}, {'doc_id': 'J-9', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Computation in a Distributed Information Market∗'}, {'doc_id': 'H-10', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Regularized Clustering for Documents ∗'}, {'doc_id': 'I-10', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'SMILE: Sound Multi-agent Incremental LEarning ;-)∗'}, {'doc_id': 'J-10', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Understanding User Behavior in Online Feedback Reporting'}, {'doc_id': 'H-11', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Laplacian Optimal Design for Image Retrieval'}, {'doc_id': 'I-11', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Real-Time Agent Characterization'}, {'doc_id': 'J-11', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Trading Networks with Price-Setting Agents'}, {'doc_id': 'H-12', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Fast Generation of Result Snippets in Web Search Andrew Turpin &'}, {'doc_id': 'I-12', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Sharing Experiences to Learn User Characteristics in Dynamic Environments with Sparse Data'}, {'doc_id': 'H-13', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'The Influence of Caption Features on Clickthrough Patterns in Web Search'}, {'doc_id': 'J-13', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'On The Complexity of Combinatorial Auctions: Structured Item Graphs and Hypertree Decompositions'}, {'doc_id': 'C-14', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Sensor Deployment Strategy for Target Detection'}, {'doc_id': 'H-14', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Studying the Use of Popular Destinations to Enhance Web Search Interaction'}, {'doc_id': 'I-14', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A Reinforcement Learning based Distributed Search Algorithm For Hierarchical Peer-to-Peer Information'}, {'doc_id': 'J-14', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Computing Good Nash Equilibria in Graphical Games ∗'}, {'doc_id': 'I-15', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Information Searching and Sharing in Large-Scale Dynamic Networks'}, {'doc_id': 'J-15', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Generalized Value Decomposition and Structured'}, {'doc_id': 'H-16', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'The Impact of Caching on Search Engines'}, {'doc_id': 'I-16', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'An Advanced Bidding Agent for Advertisement Selection on Public Displays'}, {'doc_id': 'C-17', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Deployment Issues of a VoIP Conferencing System in a Virtual Conferencing Environment'}, {'doc_id': 'H-17', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee'}, {'doc_id': 'J-17', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Truthful Mechanism Design for Multi-Dimensional'}, {'doc_id': 'C-18', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'An Initial Analysis and Presentation of Malware Exhibiting Swarm-Like Behavior'}, {'doc_id': 'H-18', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Topic Segmentation with Shared Topic Detection and Alignment of Multiple Documents'}, {'doc_id': 'I-18', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Collaboration Among a Satellite Swarm'}, {'doc_id': 'J-18', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Mediators in Position Auctions'}, {'doc_id': 'C-19', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Service Interface: A New Abstraction for Implementing and'}, {'doc_id': 'H-19', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Analyzing Feature Trajectories for Event Detection Qi He'}, {'doc_id': 'I-19', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Bidding Optimally in Concurrent Second-Price Auctions of Perfectly Substitutable Goods'}, {'doc_id': 'C-20', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Live Data Center Migration across WANs: A Robust Cooperative Context Aware Approach'}, {'doc_id': 'H-20', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'New Event Detection Based on Indexing-tree and Named Entity'}, {'doc_id': 'I-20', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Computing the Banzhaf Power Index in Network Flow Games'}, {'doc_id': 'J-20', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Clearing Algorithms for Barter Exchange Markets: Enabling Nationwide Kidney Exchanges'}, {'doc_id': 'H-21', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Robust Classification of Rare Queries Using Web Knowledge'}, {'doc_id': 'I-21', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Interactions between Market Barriers and Communication Networks in Marketing Systems'}, {'doc_id': 'J-21', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A Strategic Model for Information Markets'}, {'doc_id': 'C-22', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Runtime Metrics Collection for Middleware Supported Adaptation of Mobile Applications'}, {'doc_id': 'I-22', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Realistic Cognitive Load Modeling for Enhancing Shared Mental Models in Human-Agent Collaboration'}, {'doc_id': 'J-22', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Betting on Permutations'}, {'doc_id': 'C-23', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Implementation of a Dynamic Adjustment Mechanism with Efficient Replica Selection in Data Grid Environments'}, {'doc_id': 'J-23', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Frugality Ratios And Improved Truthful Mechanisms for Vertex Cover'}, {'doc_id': 'H-24', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Investigating the Querying and Browsing Behavior of Advanced Search Engine Users'}, {'doc_id': 'H-25', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Term Feedback for Information Retrieval with Language Models'}, {'doc_id': 'J-25', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Betting Boolean-Style: A Framework for Trading in Securities Based on Logical Formulas'}, {'doc_id': 'H-26', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A Support Vector Method for Optimizing Average Precision'}, {'doc_id': 'I-26', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Sequential Decision Making in Parallel Two-Sided Economic Search'}, {'doc_id': 'J-26', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Combinatorial Agency'}, {'doc_id': 'C-27', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A High-Accuracy, Low-Cost Localization System for Wireless Sensor Networks'}, {'doc_id': 'J-27', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Learning From Revealed Preference'}, {'doc_id': 'C-28', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'PackageBLAST: An Adaptive Multi-Policy Grid Service for Biological Sequence Comparison'}, {'doc_id': 'J-28', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Approximately-Strategyproof and Tractable Multi-Unit Auctions'}, {'doc_id': 'C-29', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Implementation and Performance Evaluation of CONFLEX-G: Grid-enabled Molecular Conformational'}, {'doc_id': 'H-29', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Estimation and Use of Uncertainty in Pseudo-relevance Feedback'}, {'doc_id': 'I-29', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Distributed Management of Flexible Times Schedules'}, {'doc_id': 'C-30', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Bullet: High Bandwidth Data Dissemination Using an Overlay Mesh'}, {'doc_id': 'H-30', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Latent Concept Expansion Using Markov Random Fields'}, {'doc_id': 'I-30', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Distributed Task Allocation in Social Networks'}, {'doc_id': 'J-30', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Implementation with a Bounded Action Space'}, {'doc_id': 'C-31', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Apocrita: A Distributed Peer-to-Peer File Sharing System'}, {'doc_id': 'H-31', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A Study of Poisson Query Generation Model for Information Retrieval'}, {'doc_id': 'I-31', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Reasoning about Judgment and Preference Aggregation Thomas'}, {'doc_id': 'J-31', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Computing the Optimal Strategy to Commit to∗'}, {'doc_id': 'C-32', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'BuddyCache: High-Performance Object Storage for Collaborative Strong-Consistency Applications'}, {'doc_id': 'H-32', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Interesting Nuggets and Their Impact on Definitional Question Answering'}, {'doc_id': 'I-32', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'An Adversarial Environment Model for Bounded Rational Agents in Zero-Sum Interactions'}, {'doc_id': 'J-32', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Nash Equilibria in Graphical Games on Trees Revisited ∗'}, {'doc_id': 'C-33', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Rewards-Based Negotiation for Providing Context Information'}, {'doc_id': 'I-33', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A Formal Road from Institutional Norms to Organizational Structures'}, {'doc_id': 'C-34', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Researches on Scheme of Pairwise Key Establishment'}, {'doc_id': 'I-34', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Resolving Conflict and Inconsistency in Norm-Regulated Virtual Organizations'}, {'doc_id': 'I-35', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Distributed Norm Management in Regulated'}, {'doc_id': 'C-36', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Encryption-Enforced Access Control in Dynamic'}, {'doc_id': 'C-38', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'A Framework for Architecting Peer-to-Peer Receiver-driven Overlays'}, {'doc_id': 'C-40', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Edge Indexing in a Grid for Highly Dynamic Virtual'}, {'doc_id': 'C-86', 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Addressing Strategic Behavior in a Deployed Microeconomic Resource Allocator'}]\n"
     ]
    }
   ],
   "source": [
    "def load_files(path):\n",
    "    raw=[]\n",
    "    for file in path:\n",
    "        dict_doc={'doc_id': None, 'title': None, 'abstract': None, 'full-text': None, 'candidates': None}\n",
    "        file_id=os.path.basename(file).rstrip('.txt.final') #catch only file name  \n",
    "        dict_doc['doc_id']=file_id\n",
    "        \n",
    "        source=open(file,encoding='utf-8').readlines()\n",
    "        source=clean(source)\n",
    "        \n",
    "        ##########detect title\n",
    "        beginning=re.sub(\"\\n\", \"\", source[0]) #retrieve title\n",
    "        candidate=re.sub(\"\\n\", \"\", source[1]) # retrieve title candidate\n",
    "        h_candidate=word_tokenize(re.sub(\"-\",' ',candidate)) #tokenize the candidate\n",
    "        \n",
    "        title=[]\n",
    "        name=[]\n",
    "        for word in h_candidate:\n",
    "            if wordnet.synsets(word): #check if title candidate exist on wordnet\n",
    "                title.append(word)\n",
    "            else:\n",
    "                name.append(word)\n",
    "            #if title>\n",
    "            if len(title)>len(name): \n",
    "                newtitle=beginning+' '+candidate\n",
    "            elif len(title)==len(name):\n",
    "                newtitle=beginning\n",
    "            else:\n",
    "                newtitle=beginning\n",
    "\n",
    "        dict_doc['title']=newtitle\n",
    "        \n",
    "        content=source[2:]\n",
    "        ######check header, inconsistency all file\n",
    "        r_intro=re.compile(\"^1\\.?\\s[A-Z]+\")\n",
    "        r_ref=re.compile(\"[0-9]{1,2}?\\.?\\s?R[EFERENCES|eferences]\") #detect reference\n",
    "        #r_header=re.compile(\"[0-9]{1,2}?\\.?\\s?[A-Z]\")\n",
    "        \n",
    "        in_abstract=content.index('ABSTRACT')\n",
    "        in_authorkey=content.index('Categories and Subject Descriptors')\n",
    "        \n",
    "        list_intro=[i for i, item in enumerate(content) if re.search(r_intro, item)]\n",
    "        in_intro=list_intro[0]\n",
    "        list_ref=[i for i, item in enumerate(content) if re.search(r_ref, item)]\n",
    "        in_ref=list_ref[0]\n",
    "        \n",
    "        abstract=content[in_abstract+1:in_authorkey] #eliminate keyword and category\n",
    "        body=content[in_intro+1:in_ref] #remove reference       \n",
    "        \n",
    "        list_title=[]\n",
    "        list_title.append(newtitle)\n",
    "        \n",
    "        full_text=list(chain(list_title,abstract, body))\n",
    "        #dict_doc['abstract']=abstract\n",
    "        #dict_doc['body']=body\n",
    "        #dict_doc['full_text']=full_text\n",
    "        \n",
    "        #per sentence in a document\n",
    "        raw.append(dict_doc)\n",
    "    return raw\n",
    "\n",
    "train_directory=sorted(glob.glob('./se_txt/test/*.txt.final'), key=lambda name: int(name[17:-10]))\n",
    "source=load_files(train_directory)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_corpus(raw_data):\n",
    "    train_data=[]\n",
    "    for doc in raw_data:\n",
    "        #add to list and join all element in full text into a text\n",
    "        train_data.append(' '.join(doc['full_text']))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_tfidf(corpus):\n",
    "    \n",
    "    #porter stemmer\n",
    "    stemmer=PorterStemmer()\n",
    "\n",
    "    #eliminate ngram which starts or ends from stopwords\n",
    "    #from https://stackoverflow.com/questions/49746555/sklearn-tfidfvectorizer-generate-custom\n",
    "    #-ngrams-by-not-removing-stopword-in-the/49775000#49775000\n",
    "    class NewTfidfVectorizer(TfidfVectorizer):\n",
    "        def _word_ngrams(self, tokens, stop_words=None):\n",
    "            # First get tokens without stop words\n",
    "            tokens = super(TfidfVectorizer, self)._word_ngrams(tokens, None)\n",
    "            if stop_words is not None:\n",
    "                new_tokens=[]\n",
    "                for token in tokens:\n",
    "                    split_words = token.split(' ')\n",
    "                    # Only check the first and last word for stop words\n",
    "                    if len(token)>2 and split_words[0] not in stop_words and split_words[-1] not in stop_words:\n",
    "                        #stem every word in token\n",
    "                        if len(split_words)==1 and len(split_words[0])>2:\n",
    "                            new_tokens.append(stemmer.stem(token))\n",
    "                        elif len(split_words)==2 and split_words[-1]==\"'\":\n",
    "                            del(token)\n",
    "                        elif len(split_words[0])<3 and len(split_words[1])<3:\n",
    "                            del(token)\n",
    "                        elif split_words[1]==\"'\" and split_words[2]==\"s\":\n",
    "                            new_tokens.append(stemmer.stem(split_words[0])+split_words[1]+split_words[2])\n",
    "                        else:\n",
    "                            new_tokens.append(' '.join(list(stemmer.stem(word) for word in word_tokenize(token))))\n",
    "                    '''\n",
    "                    if len(token)>2 and split_words[0] not in stop_words and split_words[-1] not in stop_words:\n",
    "                        #stem every word in token\n",
    "                        token1=' '.join(list(stemmer.stem(word) for word in word_tokenize(token)))\n",
    "                        new_tokens.append(token1)\n",
    "                    '''\n",
    "                return new_tokens\n",
    "            return tokens\n",
    "    \n",
    "    stop_words=text.ENGLISH_STOP_WORDS\n",
    "    \n",
    "    #pattern=\"(?u)\\\\b[\\\\w-]+\\\\b\"\n",
    "    tfidf=NewTfidfVectorizer(ngram_range=(1,5), stop_words=stop_words,\n",
    "                                token_pattern=r\"(?u)\\b[A-Za-z-]+\\b|'\")\n",
    "    \n",
    "    #tfidf=NewTfidfVectorizer(ngram_range=(1,5), stop_words=stop_words,\n",
    "    #                            token_pattern=r\"(?u)\\b[A-Za-z-]+('s)?\\b\")\n",
    "    \n",
    "    matrix=tfidf.fit_transform(corpus)\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "\n",
    "    #how to print tf-idf from https://stackoverflow.com/questions/34449127/\n",
    "    #sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "    candidates=[]\n",
    "    for doc in range(0,len(corpus)):\n",
    "        feature_index=matrix[doc,:].nonzero()[1]\n",
    "        tfidf_doc=zip(feature_index, [matrix[doc, x] for x in feature_index])\n",
    "        names_tfidf=[(w, s) for w, s in [(feature_names[i], s) for (i, s) in tfidf_doc]]\n",
    "        candidates.append(names_tfidf)\n",
    "    \n",
    "    #this is the candidates per document\n",
    "    #vocab_perdoc=tfidf.inverse_transform(matrix)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_nounphrases(raw_data):\n",
    "    \n",
    "    #porter stemmer\n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    #from http://bdewilde.github.io/blog/2014/09/23/intro-to-automatic-keyphrase-extraction/\n",
    "    grammar=r'NP: {(<JJ.*>* <NN.*>+ <IN>)? (<JJ.*>* <NN.*>+)+}' #only detect noun phrases that contain specific pattern, hypen word is counted as one NN\n",
    "    \n",
    "    #test new grammar\n",
    "    #grammar=r'NP: {(<JJ>* <VBN>? <NN.*>+ <IN>)? <JJ>* <VBG>? <NN.*>+}' \n",
    "    \n",
    "    punct = set(string.punctuation) #list of punctuation\n",
    "    chunker = RegexpParser(grammar) #chunker from nltk\n",
    "    \n",
    "    def lambda_unpack(f):\n",
    "        return lambda args:f(*args)\n",
    "    \n",
    "    postag_sents = pos_tag_sents(word_tokenize(sent) for sent in raw_data) #tokenize and create pos tag per sentence\n",
    "    #list of IOB of noun phrases based on the specific grammar\n",
    "    noun_phrases = list(chain.from_iterable(tree2conlltags(chunker.parse(tagged_sent)) for tagged_sent in postag_sents)) \n",
    "    \n",
    "    #join B-NP and I-NP tags as one noun phrase excluding O tags\n",
    "    #merged_nounphrase = [' '.join(stemmer.stem(word) for word, pos, chunk in group if re.search(r\"(?u)\\b[A-Za-z-]+\\b\", word)).lower() for key, group in\n",
    "    #                itertools.groupby(noun_phrases, lambda_unpack(lambda word, pos, chunk: chunk != 'O')) if key]\n",
    "    \n",
    "    merged_nounphrase = [' '.join(stemmer.stem(word) for word, pos, chunk in group).lower() for key, group in\n",
    "                    itertools.groupby(noun_phrases, lambda_unpack(lambda word, pos, chunk: chunk != 'O')) if key]\n",
    "    \n",
    "    #filter noun phrases from stopwords and punctuation\n",
    "    all_nounphrases=[cand for cand in merged_nounphrase\n",
    "            if len(cand)>2 and not all(char in punct for char in cand)]\n",
    "    \n",
    "    #all_nounphrases=[cand for cand in merged_nounphrase\n",
    "    #        if len(cand)>2 and cand not in stop_words and not all(char in punct for char in cand)]\n",
    "    \n",
    "    #select distinct noun phrases\n",
    "    vocabulary=(list(set(all_nounphrases)))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nounphrase_tfidf(corpus, voc):\n",
    "    \n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "        '''\n",
    "        def build_analyzer(self):\n",
    "            analyzer=super(TfidfVectorizer, self).build_analyzer()\n",
    "            #doc=' '.join(list(stemmer.stem(word) for word in analyzer(word_tokenize(doc))))\n",
    "            return lambda doc: (stemmer.stem(word) for word in analyzer(doc))\n",
    "            #return lambda doc: (' '.join(list(stemmer.stem(word) for word in word_tokenize(analyzer(doc)))))\n",
    "        '''\n",
    "        def build_tokenizer(self):\n",
    "            tokenizer=super(TfidfVectorizer, self).build_tokenizer()\n",
    "            return lambda doc: (stemmer.stem(token) for token in tokenizer(doc) if token not in stop_words)\n",
    "\n",
    "    stop_words=set(text.ENGLISH_STOP_WORDS)\n",
    "    s=['of','in','on','for']\n",
    "    stop_words=stop_words.difference(s)\n",
    "    tfidf=StemmedTfidfVectorizer(ngram_range=(1,5), stop_words=stop_words, vocabulary=voc, token_pattern=r\"(?u)\\b[A-Za-z-]+\\b\")\n",
    "    \n",
    "    matrix=tfidf.fit_transform(corpus)\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "\n",
    "    #how to print tf-idf from https://stackoverflow.com/questions/34449127/\n",
    "    #sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "    candidates=[]\n",
    "    for doc in range(0,len(corpus)):\n",
    "        feature_index=matrix[doc,:].nonzero()[1]\n",
    "        tfidf_doc=zip(feature_index, [matrix[doc, x] for x in feature_index])\n",
    "        names_tfidf=[(w, s) for w, s in [(feature_names[i], s) for (i, s) in tfidf_doc]]\n",
    "        candidates.append(names_tfidf)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###sorting candidates based on 15 keywords\n",
    "def get_topcandidates(candidates_list, number_keyphrases):\n",
    "    best_candidates=[]\n",
    "    for doc in candidates_list:\n",
    "        #sort candidates by tf-idf value\n",
    "        sorted_candidates=sorted(doc, key=lambda x: x[1], reverse=True)[:number_keyphrases]\n",
    "        #best_candidates.append(sorted_candidates)\n",
    "        best_candidates.append([x for x,_ in sorted_candidates])\n",
    "        #remove overlapping keywords\n",
    "    return best_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###compare candidates to goldstandard\n",
    "def extract_goldkeyphrases(gold_data):\n",
    "    r_plus=re.compile(\"^.*\\+.*$\")\n",
    "    r_slash=re.compile(\"^.*\\s.*\\/.*$\")\n",
    "    \n",
    "    gold_standard=[]\n",
    "    for line in gold_data.split('\\n'):\n",
    "        doc=[]      \n",
    "        for key in line[6:].split(','):\n",
    "            if key[0]==' ':\n",
    "                doc.append(key[1:])\n",
    "            elif re.search(r_plus, key):\n",
    "                split=[]\n",
    "                for element in key.split('+'):\n",
    "                    doc.append(element)\n",
    "            elif re.search(r_slash, key):\n",
    "                split=[]\n",
    "                for element in key.split('/'):\n",
    "                    doc.append(element)\n",
    "            else:\n",
    "                doc.append(key)\n",
    "        gold_standard.append(doc)\n",
    "    return gold_standard\n",
    "\n",
    "def calculate_fmeasure(candidates_list, gold_data):\n",
    "    #true positive\n",
    "    all_matches=[]\n",
    "    for index in range(len(candidates_list)):\n",
    "        #store all measure per document in dic\n",
    "        value={'tp': None, 'fp': None, 'fn': None, 'gold': None}\n",
    "        value['gold']=len(gold_data[index])\n",
    "        #counter true positive per document\n",
    "        true_positive=0\n",
    "        #loop between elements\n",
    "        for element_candidate in candidates_list[index]:                    \n",
    "            for element_goldkeyphrase in gold_data[index]:\n",
    "                #matched predicted keyword in gold keyphrase\n",
    "                if element_candidate==element_goldkeyphrase:\n",
    "                    #matches_perdoc.append(element_candidate)\n",
    "                    true_positive+=1\n",
    "            #if need the detail of evaluation\n",
    "            value['tp']=int(true_positive) #matched pair\n",
    "            value['fp']=int(15-true_positive) #depend how many keyword should we use\n",
    "            value['fn']=int(value['gold']-value['tp'])\n",
    "        #return all metrics per document\n",
    "        all_matches.append(value)\n",
    "\n",
    "    true_positive=sum(doc['tp'] for doc in all_matches)\n",
    "    false_positive=sum(doc['fp'] for doc in all_matches)\n",
    "    false_negative=sum(doc['fn'] for doc in all_matches)\n",
    "    \n",
    "    #matched/total top n\n",
    "    precision=float(true_positive/(false_positive+true_positive))\n",
    "    #matched/total gold standard\n",
    "    recall=float(true_positive/(false_negative+true_positive))\n",
    "    # calculate with micro averagedprecision\n",
    "    f_measure=2*(precision*recall)/(precision+recall)\n",
    "    return f_measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['registri', 'uddi', 'dht', 'servic', 'uddi registri', 'proxi', 'proxi registri', 'queri', 'hash', 'grid', 'key', 'discoveri', 'uddi key', 'publish', 'node'], ['sensor', 'target', 'detect', 'prob', 'path', 'fusion', 'target detect', 'exposur', 'deploy', 'travers', 'consensu', 'path exposur', 'sensor field', 'decis fusion', 'grid'], ['conferenc', 'confer', 'audio', 'client', 'mix', 'stream', 'voip', 'floor', 'internet', 'video', 'speaker', 'voip conferenc', 'floor control', 'particip', 'sip'], ['worm', 'swarm', 'infect', 'password', 'host', 'swarm worm', 'zachik', 'scan', 'target', 'behavior', 'vulner', 'slammer', 'propag', 'zachik worm', 'action'], ['protocol', 'modul', 'protocol modul', 'servic interfac', 'stack', 'interfac', 'protocol framework', 'repli', 'event', 'servic', 'event-bas', 'service-bas', 'framework', 'request', 'notif'], ['migrat', 'data center', 'server', 'center', 'replic', 'data', 'storag', 'network', 'server migrat', 'virtual server', 'outag', 'wan', 'virtual', 'servic', 'remot'], ['metric', 'mobil', 'mobil object', 'object', 'mobjex', 'adapt', 'metric collect', 'runtim', 'object framework', 'mobil object framework', 'mobil applic', 'softwar metric', 'applic', 'collect', 'solut'], ['co-alloc', 'data grid', 'data', 'server', 'replica', 'grid', 'data transfer', 'transfer', 'download', 'slowest server', 'wait for the slowest', 'wait for the slowest server', 'storag resourc', 'slowest', 'scheme'], ['sensor', 'sensor node', 'node', 'local', 'hardwar', 'spotlight', 'devic', 'wireless', 'wireless sensor', 'locat', 'effect rang', 'local scheme', 'cost', 'sensor network', 'network'], ['blast', 'grid', 'work unit', 'alloc', 'sequenc', 'slave', 'align', 'alloc polici', 'task alloc', 'master', 'unit', 'packageblast', 'sequenc comparison', 'self schedul', 'databas'], ['worker', 'trial structur', 'conflex-g', 'omnirpc', 'trial', 'worker program', 'conflex', 'program', 'rpc', 'cluster', 'structur', 'denni', 'remot', 'conform', 'initi'], ['processor', 'applic', 'node', 'adapt', 'cluster', 'resourc', 'overload', 'runtim', 'grid', 'scenario', 'benchmark', 'remov', 'averag effici', 'iter durat', 'weight averag effici'], ['bullet', 'overlay', 'tree', 'node', 'bandwidth', 'packet', 'overlay tree', 'data', 'tfrc', 'ticket', 'summari ticket', 'peer', 'ransub', 'receiv', 'tcp'], ['document', 'file', 'edit', 'file share', 'apocrita', 'user', 'share', 's machin', 'present apocrita', 'user s machin', 'access', 'organ', 'author', 'amend', 'intranet'], ['buddycach', 'client', 'collabor', 'object', 'cach', 'server', 'latenc', 'collabor applic', 'access', 'network', 'storag', 'wide-area', 'share object', 'access to share', 'share'], ['negoti', 'context', 'context provid', 'provid', 'qoc', 'reward', 'context inform', 'provid context', 'proce', 'reput', 'ept', 'util', 'qoc requir', 'context manag', 'offer and reward'], ['pairwis key', 'node', 'sensor', 'key', 'pairwis', 'sensor network', 'hypercub', 'direct pairwis', 'direct pairwis key', 'key establish', 'establish', 'pairwis key establish', 'sensor node', 'predistribut', 'compromis'], ['encrypt', 'broker', 'event', 'subscrib', 'publish', 'attribut', 'event type', 'publish subscrib', 'authoris', 'key', 'access', 'access control', 'event content', 'encrypt key', 'attribut encrypt'], ['peer', 'overlay', 'pro', 'particip peer', 'bandwidth', 'parent', 'receiver-driven', 'parent peer', 'particip', 'deliv qualiti', 'peer-to-p', 'deliv', 'stream', 'gossip', 'avail bandwidth'], ['packet', 'loss', 'frame', 'burst', 'conceal', 'voic', 'flow', 'speech', 'sensit', 'burst loss', 'decod', 'end-to-end', 'mark', 'state', 'probabl'], ['visibl', 'user', 'spatial', 'object', 'virtual', 'mmog', 'spatial index', 'world', 'dynam extens', 'index method', 'concurr user', 'index', 'virtual environ', 'move', 'real-tim'], ['content', 'manag', 'polici', 'content manag', 'storag', 'spectrum', 'polici manag', 'store', 'storag manag', 'media', 'refer', 'spectrum architectur', 'layer', 'chunk', 'file'], ['oper', 'document state', 'transform', 'origin oper', 'document', 'undo', 'causal', 'state', 'execut', 'it-transform', 'invers oper', 'origin', 'invers', 'context', 'oper context'], ['bid', 'auction', 'user', 'mirag', 'hour', 'alloc', 'resourc', 'strategyproof', 'testb', 'node hour', '-hour', 'window', 'mote', 'node', 'combinatori'], ['servic', 'servic environ', 'resourc', 'environ', 'migrat', 'eda', 'resourc manag', 'home environ', 'home', 'decentr', 'manag', 'fragment', 'fragment object', 'node', 'infrastructur'], ['cluster', 'regular', 'dataset', 'document', 'matrix', 'clgr', 'method', 'global regular', 'local', 'data point', 'predictor', 'local regular', 'cluster assign', 'label', 'global'], ['imag', 'activ learn', 'imag retriev', 'label', 'experiment design', 'learn', 'retriev', 'relev feedback', 'activ', 'cbir', 'design', 'svm', 'loss function', 'feedback', 'laplacian'], ['snippet', 'document', 'cach', 'search', 'compress', 'ram', 'searcher', 'snippet gener', 'file', 'query-bias', 'c million', 'document in ram', 'c million page', 'queri', 'search engin'], ['caption', 'snippet', 'page', 'url', 'search', 'titl', 'queri', 'web', 'web search', 'search engin', 'engin', 'queri term', 'user', 'result', 'clickthrough'], ['trail', 'queri', 'destin', 'search', 'user', 'page', 'suggest', 'engin', 'visit', 'domain', 'search result', 'search engin', 'browser', 'brows', 'search trail'], ['cach', 'post list', 'static cach', 'queri', 'post', 'static', 'list', 'answer', 'dynam cach', 'cach post', 'cach post list', 'memori', 'cach queri', 'cach of post', 'cach of post list'], ['prune', 'queri', 'index', 'p-index', 'document', 'prune polici', 'fraction', 'keyword', 'answer', 'document prune', 'invert', 'size', 'search engin', 'size s', 'polici'], ['segment', 'document', 'topic', 'topic segment', 'term cluster', 'align', 'term', 'mil', 'wmil', 'segment and align', 'term weight', 'cluster', 'multi-docu', 'weight', 'wmi'], ['event', 'aperiod', 'featur', 'period', 'news', 'event detect', 'detect', 'period event', 'easter', 'repres featur', 'unaudit', 'aperiod event', 'correl', 'word', 'april'], ['queri', 'desktop', 'keyword', 'expans', 'document', 'term', 'person', 'co-occurr', 'search', 'user', 'sentenc', 'log', 'web', 'compound', 'relev'], ['stori', 'ned', 'news', 'topic', 'indexing-tre', 'cluster', 'detect', 'new event', 'event', 'compar time', 'term of differ', 'term of differ type', 'name entiti', 'accuraci', 'new'], ['queri', 'classif', 'taxonomi', 'search', 'classifi', 'advertis', 'search engin', 'queri classif', 'engin', 'search result', 'use', 'document', 'ad', 'rare queri', 'queri in set'], ['advanc', 'search', 'advanc syntax', 'syntax', 'user', 'queri', 'search engin', 'advanc search', 'use advanc', 'advanc search engin', 'use of advanc', 'advanc search engin user', 'relationship between the use', 'use of advanc syntax', 'use'], ['feedback', 'term feedback', 'queri model', 'term', 'queri', 'relev', 'document', 'user', 'model', 'retriev', 'judg', 'languag model', 'present term', 'queri model construct', 'irrelev'], ['map', 'svm', 'rank', 'document', 'trec', 'non-relev', 'svm map', 'rocarea', 'non-relev document', 'score', 'optj', 'submiss', 'train', 'function', 'optim'], ['feedback', 'feedback model', 'queri', 'model', 'document', 'languag model', 'languag', 'top-retriev', 'top-retriev document', 'uncertainti', 'sampl', 'score', 'estim', 'distribut', 'origin queri'], ['queri', 'domain', 'domain model', 'model', 'document', 'relat', 'term', 'dom', 'use', 'context', 'feedback', 'avgp', 'avgp recal', 'user', 'contextu'], ['expans', 'queri expans', 'expans techniqu', 'queri', 'mrf', 'mrf model', 'model', 'queri expans techniqu', 'techniqu', 'term depend', 'latent concept', 'concept expans', 'latent concept expans', 'latent', 'retriev'], ['poisson', 'smooth', 'model', 'multinomi', 'languag model', 'queri', 'languag', 'document', 'poisson languag', 'poisson languag model', 'term', 'retriev', 'background model', 'poisson model', 'two-stag smooth'], ['nugget', 'answer', 'interest nugget', 'definit question', 'question answer', 'topic', 'definit question answer', 'question', 'inform nugget', 'definit', 'interest', 'human', 'foreman', 'topic nugget', 'answer nugget'], ['pim', 're-find', 're-find inform', 'evalu', 'task', 'pim evalu', 'inform', 'person', 're-find task', 'manag and re-find', 'peopl', 'person inform', 'manag', 'inform manag', 'person inform manag'], ['passag', 'novelti', 'queri', 'user', 'novelti detect', 'relev', 'adapt filter', 'feedback', 'list', 'rank list', 'rank', 'queri profil', 'document', 'span of text', 'filter'], ['user', 'recommend', 'learn', 'bayesian hierarch', 'profil', 'user profil', 'em algorithm', 'bayesian', 'hierarch', 'bayesian hierarch model', 'million of user', 'hierarch model', 'paramet', 'model paramet', 'algorithm'], ['document', 'confid', 'judgment', 'relev', 'expert', 'rank', 'relev judgment', 'estim', 'evalu', 'probabl', 'reusabl', 'confid estim', 'topic', 'judg', 'calibr'], ['cluster', 'search result', 'jaguar', 'search', 'queri', 'result', 'user', 'label', 'interest aspect', 'car', 'aspect', 'past queri', 'search log', 'log', 'organ'], ['abort', 'plan', 'failur', 'task', 'abort-method', 'pap', 'execut', 'agent', 'goal', 'plan claus', 'claus', 'program', 'goal construct', 'fail', 'san v'], ['agent', 'mas-consist', 'ma', 'agent ri', 'a-consist', 'learn', 'updat', 'inform k', 'updat mechan', 'piec of inform', 'mechan', 'learner', 'con', 'cover', 'piec of inform k'], ['agent', 'bee', 'agent s', 'plan', 'emot', 'behavior', 'plan recognit', 'predict', 'state', 'intent', 'recognit', 'action', 'hidden', 'hmm', 'intern state'], ['owner', 'interrupt', 'agent', 'estim', 'distribut function', 'cost', 'observ', 'fast-pac', 'distribut', 'user', 'interrupt cost', 'environ', 'ca modul', 'reli', 'level'], ['qsj', 'agent', 'rout', 'search session', 'queri', 'rout polici', 'neighbor agent', 'ai qsj', 'search', 'session', 'neighbor', 'agent ai', 'polici', 'learn', 'directconn'], ['inform search', 'search and share', 'inform search and share', 'network', 'agent', 'dynam network', 'search', 'inform', 'inform provis', 'share in large-scal', 'method for inform', 'share', 'propos method', 'provis', 'large-scal'], ['advertis', 'advert', 'bid', 'advertis agent', 'agent', 'display', 'user', 'advanc bid', 'bid agent', 'bid strategi', 'public', 'public display', 'advertis cycl', 'auction', 'advanc'], ['satellit', 'constel', 'swarm', 'satellit swarm', 'commun', 'agent', 'plan', 'mission', 'intersatellit', 'request', 'decis rule', 'satellit constel', 'protocol', 'ground', 'on-board'], ['bidder', 'auction', 'global bidder', 'bid', 'global', 'optim bid', 'local bidder', 'second-pric', 'market', 'second-pric auction', 'valuat distribut', 'bid strategi', 'strategi', 'concurr', 'perfect substitut'], ['flow', 'banzhaf', 'coalit', 'network flow', 'banzhaf index', 'game', 'index', 'flow game', 'network flow game', 'vertex', 'edg', 'power index', 'network', 'banzhaf power', 'power'], ['barrier', 'product', 'market barrier', 'agent', 'market', 'referr', 'word-of-mouth', 'defect', 'word-of-mouth commun', 'behaviour', 'perform', 'habitu', 'satisfi agent', 'satisfact', 'satisfi'], ['team', 'cognit', 'load', 'human', 'cognit load', 'hap', 'agent', 'mental', 'mental model', 'share mental', 'share', 'share mental model', 'smm', 'teammat', 'secondari task'], ['agent', 'partnership', 'search', 'util', 'commit', 'reject', 'strategi', 'expect util', 'i-dm', 'reserv valu', 'commit messag', 'reserv', 'agent ai', 'interact', 'two-sid'], ['schedul', 'agent', 'execut', 'qualiti', 'activ', 'method', 'task', 'stn', 'constraint', 'time', 'taem', 'mnew', 'qualiti propag', 'option', 'chang'], ['task', 'gdap', 'resourc', 'alloc', 'agent', 'task alloc', 'network', 'social network', 'social', 'rsc', 'task t', 'upper bound', 'resourc ratio', 'upper', 'resourc type'], ['judgment', 'swf', 'agenda', 'judgment aggreg', 'aggreg', 'logic', 'prefer', 'jar', 'judgment profil', 'profil', 'agent', 'formula', 'jal', 'aggreg rule', 'prefer aggreg'], ['adversari', 'aag', 'agent', 'axiom', 'action', 'eval', 'player', 'game', 'aal', 'adversari environ', 'black', 'allianc', 'connect-four', 'bel', 'environ'], ['institut', 'transit', 'transit type', 'norm', 'state', 'role', 'enact', 'type', 'axiom', 'agent', 'state type', 'concret', 'brute', 'terminolog', 'rea'], ['norm', 'agent', 'vo', 'action', 'execut state', 'virtual organ', 'state', 'conflict', 'role', 'inconsist', 'norm-regul', 'variabl', 'prohibit', 'first-ord', 'virtual'], ['norm', 'norm scene', 'scene', 'cpn', 'norm structur', 'norm posit', 'conflict', 'prohibit', 'oblig', 'norm transit', 'transit', 'arc', 'illocut', 'agent', 'utter'], ['negoti', 'agent', 'task', 'pc manufactur', 'deadlin', 'manufactur', 'negoti chain', 'hardwar', 'local', 'negoti deadlin', 'chain', 'order', 'time', 'meta-level', 'order hardwar'], ['resourc', 'resourc alloc', 'alloc', 'agent', 'distribut', 'self-organis', 'resourc consum', 'distribut resourc alloc', 'resourc alloc problem', 'unreli', 'distribut resourc', 'consum', 'alloc problem', 'server', 'techniqu'], ['commit', 'semant', 'agent', 'acl', 'behaviour', 'compliant', 'state', 'action', 'transit', 'acl semant', 'env', 'expect behaviour', 'fulfil', 'expect', 'pre'], ['commit', 'extort', 'player', 'action', 'game', 'threat', 'promis', 'schell', 'commit type', 'condit commit', 'strateg', 'situat', 'tactic', 'theori', 'strateg posit'], ['commit', 'cu', 'cricket', 'agent', 'mer', 'pre-commit', 'credit', 'cricket b', 'protocol', 'logic', 'linear logic', 'interact', 'formula', 'bat', 'tll'], ['mechan', 'budget balanc', 'welfar', 'balanc', 'distribut market', 'budget', 'incent compat', 'individu ration', 'incent', 'double-sid', 'gener trade', 'trade reduct', 'compat ic', 'ration ir', 'balanc bb'], ['review', 'rate', 'hotel', 'featur', 'user', 'textual', 'tripadvisor', 'citi', 'weight', 'high', 'comment', 'featur f', 'textual comment', 'cleanli', 'numer rate'], ['trader', 'trader t', 'buyer', 'seller', 'trade', 'profit', 'equilibrium', 'price', 'qti', 'bid', 'dual', 'ask', 'buyer and seller', 'seller and buyer', 'good'], ['item graph', 'item', 'structur item', 'structur item graph', 'graph', 'hypertre', 'combinatori auction', 'treewidth', 'combinatori', 'auction', 'hypergraph', 'hypertre decomposit', 'structur', 'tractabl', 'determin problem'], ['nash', 'nash equilibrium', 'equilibrium', 'nash equilibria', 'graphic game', 'equilibria', 'game', 'payoff', 'player', 'graphic', 'exact nash', 'polynomi', 'underli graph', 'exact', 'exact nash equilibria'], ['gai', 'seller', 'auction', 'attribut', 'price', 'prefer', 'cdi', 'sub-configur', 'multiattribut', 'phase', 'mvf', 'configur', 'buyer', 'function', 'bid'], ['truth', 'machin', 'truth mechan', 'mechan', 'multidimension', 'schedul', 'job', 'domain', 'cycl monoton', 'player', 'monoton', 'process time', 'assign', 'pij', 'makespan'], ['mediat', 'posit auction', 'player', 'auction', 'posit', 'bid', 'vcg', 'outcom function', 'vcg outcom function', 'vcg outcom', 'game', 'implement the vcg', 'ex post', 'implement the vcg outcom', 'implement the vcg outcom function'], ['redistribut', 'mechan', 'payment', 'vcg', 'redistribut payment', 'worst-cas', 'bid', 'agent', 'vcg payment', 'bid vector', 'redistribut mechan', 'percentag', 'total vcg', 'total vcg payment', 'individu ration'], ['cycl', 'kidney', 'patient', 'column', 'market', 'exchang', 'cplex', 'kidney exchang', 'column gener', 'donor', 'ilp', 'clear problem', 'clear', 'formul', 'constraint'], ['market', 'project game', 'dpm', 'trader', 'inform market', 'msr', 'game', 'trade', 'project', 'score rule', 'strateg', 'profit', 'inform', 'score', 'parimutuel'], ['bet', 'match', 'feedback arc', 'arc set', 'feedback arc set', 'edg', 'arc', 'optim match', 'minimum feedback', 'minimum feedback arc', 'worst-cas profit', 'minimum feedback arc set', 'candid', 'trader', 'profit'], ['ntumin', 'ntumin c', 'ntumax', 'tumax', 'ntumax c', 'payment', 'tumin', 'payment bound', 'tumax c', 'vertex cover', 'feasibl set', 'tumin c', 'vertex', 'cheapest', 'frugal'], ['secur', 'market', 'event', 'struck', 'stock', 'secur market', 'compound secur', 'compound', 'hedg', 'risk', 'futur', 'match problem', 'trader', 'state', 'bid'], ['contract', 'agent', 'technolog', 'optim contract', 'princip', 'exert', 'agenc', 'transit', 'optim', 'orbit', 'non-strateg', 'non-strateg case', 'exert effort', 'princip s', 'transit point'], ['demand', 'demand function', 'forecast', 'function', 'util', 'bundl', 'util function', 'afriat', 'price', 'rationaliz', 'observ', 'budget', 'prefer', 'afriat s', 'concav'], ['auction', 'approxim scheme', 'approxim', 'seller', 'revers', 'marginal-decreas', 'revers auction', 'scheme', 'multi-unit', 'vcg', 'bid', 'vcg mechan', 'buyer', 'alloc problem', 'alloc'], ['bid', 'keyword', 'click', 'budget', 'advertis', 'strategi', 'queri', 'landscap', 'uniform strategi', 'uniform', 'costq', 'budget optim', 'optim', 'clicksq', 'auction'], ['player', 'social-choic', 'action', 'mechan', 'function', 'social-valu', 'optim', 'social-choic function', 'social', 'multilinear', 'k-action', 'strategi', 'single-cross', 'social-valu function', 'social valu'], ['player', 'strategi', 'leader', 'commit', 'game', 'strategi to commit', 'play', 'pure strategi', 'mix strategi', 'mix', 'pure', 'normal-form', 'optim', 'bayesian', 'follow'], ['breakpoint', 'polici', 'breakpoint polici', 'respons polici', 'best respons polici', 'best respons', 'nash', 'play', 'graphic game', 'respons', 'nash equilibrium', 'vertex', 'payoff', 'game', 'graphic'], ['bidder', 'bid', 'equilibrium', 'symmetr equilibrium', 'advertis', 'revenu', 'symmetr', 'keyword auction', 'auction', 'keyword', 'click', 'click-through', 'click-through rate', 'rank', 'wsv'], ['epidem', 'technolog', 'payoff', 'game', 'strategi', 'zab', 'node', 'contagion', 'infinit', 'adopt', 'compat', 'region', 'diffus', 'best-respons', 'strategi b'], ['player', 'connect game', 'strong equilibrium', 'game', 'equilibrium', 'cost', 'fair connect', 'fair connect game', 'strong', 'connect', 'sink', 'graph', 'edg', 'fair', 'sourc'], ['market', 'secur', 'inform', 'converg', 'trader', 'threshold secur', 'price', 'inform market', 'n round', 'distribut', 'threshold', 'distribut inform', 'market price', 'payoff', 'threshold function']]\n"
     ]
    }
   ],
   "source": [
    "#load directory of training data to feed to scikit learn\n",
    "train_directory=glob.glob('./se_txt/test/*.txt.final')\n",
    "gold_standard=open('./se_txt/test_answer/test.combined.stem.final', encoding='utf-8').read()\n",
    "source=load_files(train_directory)\n",
    "train_data=tfidf_corpus(source)\n",
    "gold_data=extract_goldkeyphrases(gold_standard)\n",
    "#tdidf value for ngram version\n",
    "candidates_ngram=calculate_ngram_tfidf(train_data) #can be used for training data too\n",
    "top_keyphrases_ngram=get_topcandidates(candidates_ngram, 15)\n",
    "fmeasure_ngram=calculate_fmeasure(top_keyphrases_ngram, gold_data)\n",
    "print(top_keyphrases_ngram)\n",
    "#print(\"fmeasure testing ngram:\", fmeasure_ngram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['registri', 'uddi', 'dht', 'servic', 'uddi registri', 'proxi', 'proxi registri', 'queri', 'hash', 'grid', 'key', 'discoveri', 'uddi key', 'publish', 'node'], ['sensor', 'target', 'detect', 'prob', 'target detect', 'path', 'exposur', 'deploy', 'consensu', 'path exposur', 'sensor field', 'decis fusion', 'grid', 'field', 'region'], ['conferenc', 'confer', 'audio', 'client', 'stream', 'voip', 'floor', 'internet', 'speaker', 'video', 'floor control', 'particip', 'sip', 'qualiti', 'number'], ['worm', 'swarm', 'infect', 'password', 'host', 'swarm worm', 'zachik', 'scan', 'target', 'behavior', 'vulner', 'slammer', 'propag', 'zachik worm', 'action'], ['protocol', 'modul', 'protocol modul', 'servic interfac', 'stack', 'interfac', 'protocol framework', 'repli', 'event', 'servic', 'framework', 'request', 'notif', 'listen', 'handler'], ['migrat', 'data center', 'server', 'center', 'replic', 'server migrat', 'data', 'storag', 'network', 'virtual server', 'outag', 'wan', 'virtual', 'servic', 'remot'], ['metric', 'mobil object', 'object', 'mobjex', 'metric collect', 'adapt', 'runtim', 'mobil object framework', 'softwar metric', 'mobil applic', 'applic', 'collect', 'solut', 'implement', 'middlewar'], ['co-alloc', 'data grid', 'data', 'server', 'replica', 'grid', 'transfer', 'download', 'slowest server', 'storag resourc', 'scheme', 'storag', 'dataset', 'idl time', 'grid environ'], ['sensor', 'sensor node', 'node', 'local', 'hardwar', 'spotlight', 'devic', 'locat', 'effect rang', 'cost', 'sensor network', 'network', 'rang', 'deploy', 'sophist'], ['blast', 'grid', 'work unit', 'alloc', 'n s', 'sequenc', 'align', 'alloc polici', 'task alloc', 'master', 'unit', 'self schedul', 'packageblast', 'sequenc comparison', 'databas'], ['worker', 'trial structur', 'conflex-g', 'omnirpc', 'trial', 'worker program', 'conflex', 'program', 'rpc', 'cluster', 'structur', 'denni', 'remot', 'conform', 'initi'], ['processor', 'applic', 'node', 'adapt', 'cluster', 'resourc', 'overload', 'runtim', 'grid', 'scenario', 'benchmark', 'remov', 'iter durat', 'weight averag effici', 'overhead'], ['bullet', 'overlay', 'tree', 'node', 'bandwidth', 'packet', 'overlay tree', 'data', 'summari ticket', 'tfrc', 'peer', 'ransub', 'receiv', 'tcp', 'rate'], ['document', 'file', 'apocrita', 'user', 'share', 's machin', 'present apocrita', 'access', 'organ', 'author', 'document for variou purpos', 'search tool', 'multipl differ document', 'incorrect version', 'download file'], ['buddycach', 'client', 'collabor', 'object', 'cach', 'server', 'latenc', 'collabor applic', 'access', 'network', 'storag', 'share object', 'share', 'repositori', 'group'], ['negoti', 'context provid', 'context', 'provid', 'provid context', 'qoc', 'reward', 'context inform', 'proce', 'ua c', 'reput', 'util', 'negoti process', 'context manag', 'qoc requir'], ['pairwis key', 'node', 'sensor', 'key', 'sensor network', 'node b', 'hypercub', 'direct pairwis key', 'establish', 'pairwis key establish', 'sensor node', 'compromis', 'key predistribut', 'network', 'scheme'], ['encrypt', 'broker', 'event', 'subscrib', 'publish', 'attribut', 'event type', 'key', 'access', 'attribut encrypt', 'event content', 'access control', 'encrypt key', 'encrypt event', 'broker network'], ['peer', 'overlay', 'pro', 'bandwidth', 'parent', 'particip', 'peer-to-p', 'stream', 'gossip', 'avail bandwidth', 'receiv', 'key compon', 'heterogen', 'asymmetri', 'pal'], ['packet', 'loss', 'frame', 'burst', 'conceal', 'voic', 'flow', 'speech', 'sensit', 'burst loss', 'decod', 'end-to-end', 'mark', 'state', 'probabl'], ['user', 'object', 'virtual', 'spatial index', 'mmog', 'world', 'dynam extens', 'index', 'virtual environ', 'concurr user', 'real-tim', 'geometri', 'server', 'scalabl', 'spatial index method'], ['content', 'manag', 'polici', 'content manag', 'storag', 'spectrum', 'polici manag', 'store', 'storag manag', 'media', 'refer', 'spectrum architectur', 'polici refer', 'layer', 'chunk'], ['oper', 'document state', 'transform', 'origin oper', 'document', 'undo', 'causal', 'state', 'execut', 'oper context', 'invers oper', 'it-transform', 'origin', 'invers', 'oa ob'], ['bid', 'auction', 'user', 'mirag', 'hour', 'alloc', 'resourc', 'strategyproof', 'testb', 'node hour', 'window', 'mote', 'node', 'repeat combinatori auction', 'resourc alloc'], ['servic', 'servic environ', 'resourc', 'environ', 'migrat', 'eda', 'home environ', 'resourc manag', 'home', 'manag', 'fragment', 'fragment object', 'node', 'infrastructur', 'adapt servic'], ['cluster', 'regular', 'dataset', 'document', 'matrix', 'clgr', 'method', 'global regular', 'local', 'local regular', 'data point', 'cluster assign', 'label', 'criterion', 'data'], ['imag', 'activ learn', 'label', 'experiment design', 'learn', 'retriev', 'relev feedback', 'activ', 'cbir', 'design', 'svm', 'loss function', 'feedback', 'experiment', 'activ learn algorithm'], ['snippet', 'document', 'cach', 'search', 'compress', 'ram', 'searcher', 'file', 'document in ram', 'document content', 'queri', 'search engin', 'gener', 'filesystem', 'page'], ['caption', 'snippet', 'page', 'url', 'search', 'titl', 'queri', 'web', 'web search', 'search engin', 'engin', 'queri term', 'user', 'result', 'clickthrough'], ['trail', 'queri', 'destin', 'search', 'user', 'page', 'suggest', 'engin', 'domain', 'search result', 'search engin', 'browser', 'brows', 'search trail', 'session trail'], ['cach', 'post list', 'static cach', 'queri', 'post', 'list', 'answer', 'dynam cach', 'cach post list', 'memori', 'cach answer', 'queri answer', 'engin', 'cach level', 'term'], ['prune', 'queri', 'index', 'p-index', 'document', 'prune polici', 'fraction', 'keyword', 'answer', 'document prune', 'size s', 'prune index', 'size', 'search engin', 'fraction of queri'], ['segment', 'document', 'topic', 'topic segment', 'align', 'term', 'term cluster', 'wmil', 'mil', 'term weight', 'cluster', 'weight', 'wmi', 'sentenc', 'multi-docu segment'], ['event', 'featur', 'period', 'event detect', 'news', 'detect', 'period event', 'easter', 'repres featur', 'aperiod event', 'correl', 'word', 'april', 'tdt', 'dfidf'], ['queri', 'desktop', 'keyword', 'expans', 'document', 'term', 'person', 'co-occurr', 'search', 'user', 'sentenc', 'log', 'web', 'compound', 'relev'], ['stori', 'ned', 'news', 'topic', 'indexing-tre', 'cluster', 'detect', 'new event', 'event', 'term of differ type', 'accuraci', 'detect procedur', 'news indexing-tre', 'similar stori', 'new event detect'], ['queri', 'classif', 'taxonomi', 'search', 'classifi', 'search engin', 'advertis', 'queri classif', 'search result', 'engin', 'use', 'queri in set', 'document', 'rare queri', 'web'], ['advanc', 'search', 'advanc syntax', 'syntax', 'user', 'queri', 'search engin', 'use of advanc syntax', 'advanc search engin user', 'use', 'engin', 'search engin user', 'searcher', 'web search', 'queri oper'], ['feedback', 'term feedback', 'term', 'queri model', 'queri', 'relev', 'document', 'user', 'model', 'retriev', 'judg', 'languag model', 'present term', 'relev feedback', 'languag'], ['map', 'svm', 'rank', 'document', 'trec', 'rocarea', 'non-relev document', 'score', 'optj', 'submiss', 'train', 'function', 'optim', 'retriev function', 'base function'], ['feedback', 'feedback model', 'queri', 'model', 'document', 'languag model', 'languag', 'top-retriev document', 'uncertainti', 'sampl', 'score', 'estim', 'distribut', 'origin queri', 'feedback algorithm'], ['queri', 'domain', 'domain model', 'model', 'document', 'relat', 'term', 'dom', 'use', 'context', 'feedback', 'avgp', 'user', 'contextu factor', 'queri domain'], ['expans', 'queri expans', 'queri', 'mrf', 'mrf model', 'model', 'queri expans techniqu', 'techniqu', 'term depend', 'latent concept expans', 'retriev', 'markov random field', 'use', 'concept', 'term'], ['poisson', 'smooth', 'model', 'multinomi', 'languag model', 'queri', 'languag', 'document', 'poisson languag model', 'term', 'retriev', 'background model', 'two-stag smooth', 'poisson model', 'two-stag'], ['nugget', 'answer', 'definit question', 'inform nugget', 'topic', 'question', 'definit', 'human', 'answer nugget', 'foreman', 'topic nugget', 'inform', 'question topic', 'boxer', 'human reader'], ['pim', 're-find inform', 'evalu', 'task', 'pim evalu', 'inform', 'person', 'peopl', 'person inform', 'manag', 'difficulti', 'person collect', 'collect', 'pim research', 'kind of task'], ['passag', 'novelti', 'queri', 'user', 'novelti detect', 'relev', 'adapt filter', 'feedback', 'list', 'rank list', 'rank', 'queri profil', 'document', 'span of text', 'filter'], ['user', 'recommend', 'learn', 'profil', 'user profil', 'em algorithm', 'bayesian', 'bayesian hierarch model', 'hierarch model', 'million of user', 'paramet', 'algorithm', 'model paramet', 'model', 'particular user'], ['document', 'confid', 'judgment', 'relev', 'expert', 'rank', 'estim', 'relev judgment', 'evalu', 'probabl', 'confid estim', 'reusabl', 'topic', 'judg', 'calibr'], ['cluster', 'search result', 'jaguar', 'search', 'queri', 'result', 'user', 'label', 'car', 'aspect', 'past queri', 'search log', 'log', 'organ', 'search engin'], ['abort', 'plan', 'failur', 'task', 'abort-method', 'pap', 'execut', 'agent', 'v v', 'goal', 'plan claus', 'claus', 'program', 'fail', 'goal construct'], ['agent', 'mas-consist', 'agent ri', 'a-consist', 'learn', 'updat', 'inform k', 'updat mechan', 'piec of inform', 'mechan', 'learner', 'cover', 'piec of inform k', 'hypothesi', 'piec'], ['agent', 'bee', 'agent s', 'plan', 'emot', 'behavior', 'plan recognit', 'predict', 'state', 'intent', 'recognit', 'action', 'hidden', 'hmm', 'intern state'], ['owner', 'interrupt', 'agent', 'estim', 'distribut function', 'cost', 'observ', 'distribut', 'user', 'interrupt cost', 'environ', 'ca modul', 'reli', 'level', 'data'], ['qsj', 'agent', 'rout', 'search session', 'queri', 'rout polici', 'neighbor agent', 'search', 'session', 'neighbor', 'agent ai', 'polici', 'learn', 'directconn', 'pdn'], ['inform search', 'network', 'agent', 'dynam network', 'search', 'inform', 'share', 'provis', 'overlay structur', 'method', 'overlay', 'peer', 'optim polici', 'effect inform search', 'inform provis abil'], ['advertis', 'advert', 'bid', 'advertis agent', 'agent', 'display', 'user', 'bid agent', 'bid strategi', 'public', 'advertis cycl', 'public display', 'auction', 'advanc', 'advanc bid agent'], ['satellit', 'constel', 'swarm', 'satellit swarm', 'commun', 'agent', 'plan', 'mission', 'request', 'satellit constel', 'protocol', 'ground', 'vicin', 'on-board', 'orbit'], ['bidder', 'auction', 'global bidder', 'bid', 'optim bid', 'local bidder', 'second-pric', 'market', 'second-pric auction', 'number of auction', 'bid strategi', 'valuat distribut', 'strategi', 'concurr', 'perfect substitut'], ['flow', 'banzhaf', 'coalit', 'banzhaf index', 'game', 'index', 'flow game', 'network flow game', 'vertex', 'edg', 'power index', 'network', 'power', 'match', 'agent'], ['barrier', 'product', 'market barrier', 'agent', 'market', 'referr', 'word-of-mouth', 'defect', 'word-of-mouth commun', 'behaviour', 'perform', 'habitu', 'satisfact', 'satisfi', 'product use'], ['team', 'load', 'human', 'cognit load', 'hap', 'agent', 'mental model', 'share', 'share mental model', 'smm', 'teammat', 'secondari task', 'model', 'process load', 'capac'], ['agent', 'partnership', 'search', 'util', 'commit', 'reject', 'strategi', 'expect util', 'i-dm', 'reserv valu', 'commit messag', 'agent ai', 'interact', 's-dm', 'use'], ['schedul', 'agent', 'execut', 'qualiti', 'activ', 'method', 'task', 'stn', 'constraint', 'time', 'qualiti propag', 'mnew', 'option', 'chang', 'agent s'], ['task', 'gdap', 'resourc', 'alloc', 'agent', 'task alloc', 'network', 'social network', 'rsc', 'task t', 'upper bound', 'resourc ratio', 'upper', 'resourc type', 'bound'], ['judgment', 'swf', 'judgment aggreg', 'agenda', 'aggreg', 'logic', 'prefer', 'jar', 'judgment profil', 'profil', 'agent', 'formula', 'jal', 'aggreg rule', 'prefer aggreg'], ['adversari', 'aag', 'agent', 'axiom', 'action', 'eval', 'player', 'game', 'aal', 'adversari environ', 'black', 'allianc', 'bel', 'connect-four', 'environ'], ['institut', 'transit', 'transit type', 'norm', 'state', 'role', 'enact', 'type', 'axiom', 'agent', 'state type', 'concret', 'brute', 'terminolog', 'rea'], ['norm', 'agent', 'action', 'execut state', 'virtual organ', 'state', 'conflict', 'role', 'inconsist', 'variabl', 'prohibit', 'virtual', 'formula', 'atom formula', 'oblig'], ['norm', 'norm scene', 'scene', 'cpn', 'norm posit', 'norm structur', 'conflict', 'prohibit', 'oblig', 'norm transit', 'transit', 'arc', 'illocut', 'agent', 'utter'], ['negoti', 'agent', 'task', 'pc manufactur', 'deadlin', 'negoti chain', 'hardwar', 'local', 'negoti deadlin', 'chain', 'order', 'time', 'order hardwar', 'distribut center', 'flexibl'], ['resourc', 'resourc alloc', 'alloc', 'agent', 'distribut', 'self-organis', 'resourc consum', 'resourc alloc problem', 'consum', 'server', 'alloc problem', 'techniqu', 'task', 'effici resourc alloc', 'resourc load'], ['commit', 'semant', 'agent', 'acl', 'behaviour', 'compliant', 'state', 'action', 'transit', 'acl semant', 'env', 'fulfil', 'expect', 'pre', 'dialogu oper'], ['commit', 'extort', 'player', 'action', 'game', 'threat', 'promis', 'commit type', 'condit commit', 'strateg', 'situat', 'tactic', 'theori', 'strateg posit', 'pareto effici'], ['commit', 'agent', 'mer', 'pre-commit', 'credit', 'protocol', 'logic', 'linear logic', 'interact', 'formula', 'cricket bat', 'tll', 'resourc', 'paypal', 'linear'], ['mechan', 'budget balanc', 'welfar', 'budget', 'incent compat', 'individu ration', 'incent', 'ic mechan', 'gener trade reduct', 'double-sid auction', 'compat', 'market', 'social welfar', 'trade', 'deficit'], ['review', 'rate', 'hotel', 'featur', 'user', 'tripadvisor', 'citi', 'weight', 'comment', 'featur f', 'textual comment', 'prior expect', 'numer rate', 'high weight', 'wi f'], ['trader', 'trader t', 'buyer', 'seller', 'trade', 'profit', 'equilibrium', 'price', 'qti', 'bid', 'dual', 'ask', 'good', 'buyer j', 'agent'], ['item graph', 'item', 'structur item graph', 'graph', 'combinatori auction', 'treewidth', 'auction', 'hypertre decomposit', 'hypergraph', 'polynomi time on instanc', 'structur', 'tractabl', 'winner determin problem', 'decomposit', 'instanc'], ['nash', 'nash equilibrium', 'equilibrium', 'nash equilibria', 'graphic game', 'equilibria', 'game', 'payoff', 'player', 'graphic', 'polynomi', 'underli graph', 'exact', 'exact nash equilibria', 'algorithm'], ['gai', 'seller', 'auction', 'attribut', 'price', 'prefer', 'cdi', 'sub-configur', 'phase', 'mvf', 'configur', 'buyer', 'function', 'bid', 'wtp'], ['truth', 'machin', 'truth mechan', 'mechan', 'multidimension', 'schedul', 'job', 'domain', 'cycl monoton', 'player', 'monoton', 'process time', 'assign', 'pij', 'makespan'], ['mediat', 'posit auction', 'player', 'auction', 'posit', 'bid', 'vcg', 'outcom function', 'vcg outcom function', 'vcg outcom', 'game', 'v v', 'rule', 'ex post equilibrium', 't-strategi'], ['redistribut', 'n m', 'm n', 'mechan', 'payment', 'vcg', 'redistribut payment', 'worst-cas', 'bid', 'n j', 'agent', 'vcg payment', 'redistribut mechan', 'bid vector', 'percentag'], ['cycl', 'kidney', 'patient', 'column', 'market', 'exchang', 'column gener', 'kidney exchang', 'cplex', 'donor', 'clear problem', 'ilp', 'clear', 'formul', 'constraint'], ['market', 'project game', 'dpm', 'trader', 'msr', 'inform market', 'game', 'trade', 'project', 'score rule', 'strateg', 'profit', 'inform', 'score', 'dynam parimutuel market'], ['bet', 'match', 'feedback arc', 'edg', 'arc', 'minimum feedback arc', 'optim match', 'worst-cas profit', 'minimum feedback arc set', 'candid', 'trader', 'profit', 'auction', 'order', 'optim'], ['ntumin', 'ntumax', 'tumax', 'payment', 'payment bound', 'tumin', 'vertex cover', 'feasibl set', 'vertex', 'cheapest', 'auction', 'cost', 'frugal ratio', 'bid', 'bound'], ['secur', 'market', 'event', 'struck', 'stock', 'secur market', 'compound secur', 'compound', 'hedg', 'risk', 'futur', 'trader', 'match problem', 'state', 'bid'], ['contract', 'agent', 'optim contract', 'technolog', 'princip', 'agenc', 'transit', 'optim', 'orbit', 'non-strateg case', 'exert effort', 'transit point', 'case', 'effort', 'pou'], ['demand', 'demand function', 'forecast', 'function', 'util', 'bundl', 'util function', 'afriat', 'price', 'rationaliz', 'observ', 'budget', 'prefer', 'concav', 'varian'], ['auction', 'approxim scheme', 'approxim', 'seller', 'revers auction', 'scheme', 'vcg', 'bid', 'vcg mechan', 'buyer', 'alloc', 'alloc problem', 'multi-unit alloc problem', 'forward auction', 'm unit'], ['bid', 'keyword', 'click', 'budget', 'advertis', 'strategi', 'queri', 'landscap', 'uniform strategi', 'uniform', 'costq', 'budget optim', 'optim', 'clicksq', 'auction'], ['player', 'action', 'mechan', 'function', 'optim', 'social-choic function', 'multilinear', 'k-action', 'strategi', 'social-valu function', 'social valu', 'altern', 'optim mechan', 'b b b b', 'type'], ['player', 'strategi', 'leader', 'commit', 'game', 'play', 'pure strategi', 'mix strategi', 'pure', 'optim', 'bayesian', 'follow', 'optim strategi', 'util', 'bayesian game'], ['breakpoint', 'polici', 'breakpoint polici', 'best respons polici', 'best respons', 'b w v', 'nash', 'play', 'v v', 'graphic game', 'respons', 'nash equilibrium', 'vertex', 'payoff', 'game'], ['bidder', 'bid', 'equilibrium', 'symmetr equilibrium', 'advertis', 'revenu', 'keyword auction', 'auction', 'click', 'keyword', 'click-through rate', 'rank', 'wsv', 'posit', 'varian'], ['epidem', 'technolog', 'payoff', 'game', 'strategi', 'zab', 'node', 'strategi b', 'adopt', 'compat', 'region', 'diffus', 'best-respons', 'block structur', 'contagion game'], ['player', 'strong equilibrium', 'connect game', 'game', 'equilibrium', 'cost', 'fair connect game', 'connect', 'sink', 'graph', 'edg', 'fair', 'player j', 'sourc', 'singl sourc'], ['market', 'secur', 'inform', 'converg', 'trader', 'threshold secur', 'price', 'inform market', 'distribut', 'threshold', 'distribut inform', 'payoff', 'threshold function', 'market price', 'equilibrium']]\n"
     ]
    }
   ],
   "source": [
    "#tdidf value for noun phrases version\n",
    "voc_nounphrase=vocabulary_nounphrases(train_data)\n",
    "candidates_nounphrase=calculate_nounphrase_tfidf(train_data, voc_nounphrase)\n",
    "top_keyphrases_nounphrase=get_topcandidates(candidates_nounphrase, 15)\n",
    "fmeasure_nounphrase=calculate_fmeasure(top_keyphrases_nounphrase, gold_data)\n",
    "#print(\"fmeasure testing noun phrase:\", fmeasure_nounphrase)\n",
    "print(top_keyphrases_nounphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
