{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file contains noun phrase and n-gram filters on Semeval dataset (XML version)\n",
    "#only evaluate the model on combined label\n",
    "\n",
    "import glob, utils, preprocessing, generate_candidate \n",
    "import feature_extraction, generate_keyphrase\n",
    "\n",
    "#this is the default number\n",
    "number_keyphrase = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if these files are exist on pickle, please skip into next step\n",
    "\n",
    "#create gold keyphrase\n",
    "train_label_directory = open('./data/se_txt/train/train.combined.stem.final', \n",
    "                        encoding='utf-8').read()\n",
    "train_label = preprocessing.extract_keyphrase(train_label_directory)\n",
    "pickle_train_label = utils.create_pickle(train_label, './pickle/semeval/train label')\n",
    "\n",
    "test_label_directory = open('./data/se_txt/test_answer/test.combined.stem.final', \n",
    "                            encoding='utf-8').read()\n",
    "test_label = preprocessing.extract_keyphrase(test_label_directory)\n",
    "pickle_test_label = utils.create_pickle(test_label, './pickle/semeval/test label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run one time, if pickles have been available, please skip this step\n",
    "#this section is intended to create candidates, supervised keyphraseness\n",
    "\n",
    "#load and create training data\n",
    "train_directory = glob.glob('./data/se_txt/train/*.txt.final')\n",
    "train_raw = preprocessing.load_files(train_directory)\n",
    "pickle_train_raw = utils.create_pickle(train_raw,'./pickle/semeval/txt train raw')\n",
    "train_data = preprocessing.create_corpus(train_raw)\n",
    "pickle_train_data = utils.create_pickle(train_data,'./pickle/semeval/txt train data')\n",
    "train_tf_corpus = feature_extraction.calculate_tf(train_data, vocab = None, \n",
    "                    type = 'ngram')\n",
    "pickle_train_tf_corpus = utils.create_pickle(train_tf_corpus,\n",
    "                        './pickle/semeval/txt train tf corpus')\n",
    "\n",
    "#load and create testing data\n",
    "test_directory = glob.glob('./data/se_txt/test/*.txt.final')\n",
    "test_raw = preprocessing.load_files(test_directory)\n",
    "pickle_test_raw = utils.create_pickle(test_raw,'./pickle/semeval/txt test raw')\n",
    "test_data = preprocessing.create_corpus(test_raw)\n",
    "pickle_test_data = utils.create_pickle(test_data,'./pickle/semeval/txt test data')\n",
    "test_tf_corpus = feature_extraction.calculate_tf(test_data, vocab = None, \n",
    "                    type = 'ngram')\n",
    "pickle_test_tf_corpus = utils.create_pickle(test_tf_corpus,\n",
    "                    './pickle/semeval/txt test tf corpus')\n",
    "\n",
    "\n",
    "#create candidates based on n-gram and store into pickle of training data\n",
    "print(\"Generating n-gram candidates..\")\n",
    "ngram_candidates = generate_candidate.calculate_tfidf(train_data, vocab=None, \n",
    "                        type='ngram') \n",
    "pickle_ngram_candidates = utils.create_pickle(ngram_candidates,\n",
    "                            './pickle/semeval/txt ngram candidates')\n",
    "\n",
    "#create candidates based on n-gram and store into pickle of testing data\n",
    "test_ngram_candidates = generate_candidate.calculate_tfidf(test_data, vocab=None, \n",
    "                            type='ngram')\n",
    "pickle_test_ngram_candidates = utils.create_pickle(test_ngram_candidates, \n",
    "                                './pickle/semeval/txt test ngram candidates')\n",
    "\n",
    "\n",
    "#create candidates based on noun phrase and store into pickle of training data\n",
    "print(\"Generating noun phrase candidates..\")\n",
    "nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(train_data)\n",
    "train_tf_nounphrase_corpus = feature_extraction.calculate_tf(train_data, \n",
    "                                vocab = nounphrase_vocabulary, type = 'np')\n",
    "pickle_train_tf_nounphrase_corpus = utils.create_pickle(train_tf_nounphrase_corpus,\n",
    "                                    './pickle/semeval/txt train tf nounphrase corpus')\n",
    "nounphrase_candidates = generate_candidate.calculate_tfidf(train_data, \n",
    "                        nounphrase_vocabulary, type='np')\n",
    "pickle_nounphrase_candidates = utils.create_pickle(nounphrase_candidates, \n",
    "                                './pickle/semeval/txt nounphrase candidates')\n",
    "\n",
    "#create candidates based on noun phrase and store into pickle of testing data\n",
    "test_nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(test_data)\n",
    "test_tf_nounphrase_corpus = feature_extraction.calculate_tf(test_data, \n",
    "                            vocab = test_nounphrase_vocabulary, type = 'np')\n",
    "pickle_test_tf_nounphrase_corpus = utils.create_pickle(test_tf_nounphrase_corpus,\n",
    "                                    './pickle/semeval/txt test tf nounphrase corpus')\n",
    "test_nounphrase_candidates = generate_candidate.calculate_tfidf(test_data, \n",
    "                                test_nounphrase_vocabulary, type='np')\n",
    "pickle_test_nounphrase_candidates = utils.create_pickle(test_nounphrase_candidates, \n",
    "                                        './pickle/semeval/txt test nounphrase candidates')\n",
    "\n",
    "#create a dictionary supervised keyphraseness on ngram filter by combined label\n",
    "supervised_key = feature_extraction.create_supervised_list(train_label, train_tf_corpus)\n",
    "supervised_corpus = utils.create_pickle(supervised_key, './pickle/semeval/txt ngram supervised keyphraseness')\n",
    "\n",
    "#create a dictionary supervised keyphraseness on noun phrase filter by combined label\n",
    "np_supervised_key = feature_extraction.create_supervised_list(train_label, train_tf_nounphrase_corpus)\n",
    "np_supervised_corpus = utils.create_pickle(np_supervised_key, './pickle/semeval/txt np supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening all pickles\n"
     ]
    }
   ],
   "source": [
    "#open all relevant pickles\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('./pickle/semeval/txt train raw')\n",
    "train_data = utils.open_pickle('./pickle/semeval/txt train data')\n",
    "\n",
    "train_label = utils.open_pickle('./pickle/semeval/train label')\n",
    "train_tf_corpus = utils.open_pickle('./pickle/semeval/txt train tf corpus')\n",
    "train_tf_nounphrase_corpus = utils.open_pickle('./pickle/semeval/txt train tf nounphrase corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('./pickle/semeval/txt test raw')\n",
    "test_data = utils.open_pickle('./pickle/semeval/txt test data')\n",
    "\n",
    "test_label = utils.open_pickle('./pickle/semeval/test label')\n",
    "test_tf_corpus = utils.open_pickle('./pickle/semeval/txt test tf corpus')\n",
    "test_tf_nounphrase_corpus = utils.open_pickle('./pickle/semeval/txt test tf nounphrase corpus')\n",
    "\n",
    "train_topics = utils.open_pickle('./pickle/semeval/txt train topics')\n",
    "test_topics = utils.open_pickle('./pickle/semeval/txt test topics')\n",
    "\n",
    "ngram_candidates = utils.open_pickle('./pickle/semeval/txt ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('./pickle/semeval/txt test ngram candidates')\n",
    "\n",
    "nounphrase_candidates = utils.open_pickle('./pickle/semeval/txt nounphrase candidates')\n",
    "test_nounphrase_candidates = utils.open_pickle('./pickle/semeval/txt test nounphrase candidates')\n",
    "\n",
    "supervised_key = utils.open_pickle('./pickle/semeval/txt ngram supervised keyphraseness')\n",
    "np_supervised_key = utils.open_pickle('./pickle/semeval/txt np supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features in training and testing data, \n",
    "#if those csv have been available, please skip to the next step\n",
    "\n",
    "#create examples on training and testing data\n",
    "print(\"Creating examples of n-gram on combined label..\")\n",
    "ngram_train = feature_extraction.create_features(train_data, \n",
    "                                                 ngram_candidates, \n",
    "                                                 train_label,\n",
    "                                                 supervised_key,\n",
    "                                                 train_tf_corpus, \n",
    "                                                 train_topics, \n",
    "                                                 name='./csv/semeval/txt_train_ngram', \n",
    "                                                 n_keyphrase = number_keyphrase\n",
    "                                                 )\n",
    "\n",
    "ngram_test = feature_extraction.create_features(test_data, \n",
    "                                                test_ngram_candidates, \n",
    "                                                test_label, \n",
    "                                                supervised_key,\n",
    "                                                test_tf_corpus, \n",
    "                                                test_topics, \n",
    "                                                name='./csv/semeval/txt_test_ngram',\n",
    "                                                n_keyphrase = number_keyphrase\n",
    "                                                )\n",
    "\n",
    "print(\"Creating examples of noun phrase on combined label..\")\n",
    "nounphrase_train = feature_extraction.create_features( \n",
    "                                                train_data, \n",
    "                                                nounphrase_candidates, \n",
    "                                                train_label, \n",
    "                                                np_supervised_key,\n",
    "                                                train_tf_nounphrase_corpus, \n",
    "                                                train_topics,\n",
    "                                                name='./csv/semeval/txt_train_nounphrase',\n",
    "                                                n_keyphrase = number_keyphrase\n",
    "                                                )\n",
    "\n",
    "nounphrase_test = feature_extraction.create_features(\n",
    "                                                test_data, \n",
    "                                                test_nounphrase_candidates, \n",
    "                                                test_label,\n",
    "                                                np_supervised_key, \n",
    "                                                test_tf_nounphrase_corpus, \n",
    "                                                test_topics,\n",
    "                                                name='./csv/semeval/txt_test_nounphrase',\n",
    "                                                n_keyphrase = number_keyphrase\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on ngram filter:\n",
      "Precision, recall, f-measure on top 15 candidates: [('LR', (18.73, 18.58, 18.65)), ('NB', (5.67, 5.62, 5.64)), ('RF', (12.53, 12.43, 12.48)), ('AdaBoost', (11.67, 11.57, 11.62)), ('Bagging', (10.93, 10.85, 10.89))]\n",
      "Evaluation on nounphrase filter:\n",
      "Precision, recall, f-measur on top 15 candidates: [('LR', (19.87, 19.71, 19.79)), ('NB', (15.2, 15.08, 15.14)), ('RF', (12.73, 12.63, 12.68)), ('AdaBoost', (10.93, 10.85, 10.89)), ('Bagging', (10.27, 10.19, 10.23))]\n"
     ]
    }
   ],
   "source": [
    "#evaluation part\n",
    "\n",
    "print('Evaluation on ngram filter:')\n",
    "ngram_prediction = generate_keyphrase.predict_data(test_ngram_candidates, \n",
    "                                                test_label, \n",
    "                                                train_data='./csv/semeval/txt_train_ngram', \n",
    "                                                test_data='./csv/semeval/txt_test_ngram',\n",
    "                                                n_keyphrase = number_keyphrase)\n",
    "print('Precision, recall, f-measure on top 15 candidates:', ngram_prediction)\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates, \n",
    "                                        train_data='./csv/semeval/txt_train_ngram', \n",
    "                                        test_data='./csv/semeval/txt_test_ngram', \n",
    "                                        csv_name='./csv/semeval/txt predicted ngram keyphrases',\n",
    "                                        n_keyphrase = number_keyphrase)\n",
    "\n",
    "print('Evaluation on nounphrase filter:')\n",
    "nounphrase_prediction = generate_keyphrase.predict_data(test_nounphrase_candidates, \n",
    "                                                test_label,\n",
    "                                                train_data='./csv/semeval/txt_train_nounphrase', \n",
    "                                                test_data='./csv/semeval/txt_test_nounphrase', \n",
    "                                                n_keyphrase = number_keyphrase)\n",
    "print('Precision, recall, f-measure on top 15 candidates:', nounphrase_prediction)\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "nounphrase_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(\n",
    "                                        test_nounphrase_candidates, \n",
    "                                        train_data='./csv/semeval/txt_train_nounphrase', \n",
    "                                        test_data='./csv/semeval/txt_test_nounphrase', \n",
    "                                        csv_name='./csv/semeval/txt predicted nounphrase keyphrases',\n",
    "                                        n_keyphrase = number_keyphrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
