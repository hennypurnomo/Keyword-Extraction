{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'doc_id': 'C-45', 'full_text': ['StarDust: A Flexible Architecture for Passive Localization in Wireless Sensor Networks', 'The problem of localization in wireless sensor networks\\n', 'where nodes do not use ranging hardware, remains a \\n', 'challenging problem, when considering the required location \\n', 'accuracy, energy expenditure and the duration of the \\n', 'localization phase. In this paper we propose a framework, called\\n', 'StarDust, for wireless sensor network localization based on\\n', 'passive optical components. In the StarDust framework,\\n', 'sensor nodes are equipped with optical retro-reflectors. An\\n', 'aerial device projects light towards the deployed sensor \\n', 'network, and records an image of the reflected light. An image\\n', 'processing algorithm is developed for obtaining the locations\\n', 'of sensor nodes. For matching a node ID to a location we\\n', 'propose a constraint-based label relaxation algorithm. We\\n', 'propose and develop localization techniques based on four\\n', 'types of constraints: node color, neighbor information, \\n', 'deployment time for a node and deployment location for a\\n', 'node. We evaluate the performance of a localization system\\n', 'based on our framework by localizing a network of 26 \\n', 'sensor nodes deployed in a 120 × 60 ft2 area. The localization\\n', 'accuracy ranges from 2 ft to 5 ft while the localization time\\n', 'ranges from 10 milliseconds to 2 minutes.\\n', 'Wireless Sensor Networks (WSN) have been envisioned\\n', 'to revolutionize the way humans perceive and interact with\\n', 'the surrounding environment. One vision is to embed tiny\\n', 'sensor devices in outdoor environments, by aerial \\n', 'deployments from unmanned air vehicles. The sensor nodes form\\n', 'a network and collaborate (to compensate for the extremely\\n', 'scarce resources available to each of them: computational\\n', 'power, memory size, communication capabilities) to \\n', 'accomplish the mission. Through collaboration, redundancy and\\n', 'fault tolerance, the WSN is then able to achieve \\n', 'unprecedented sensing capabilities.\\n', 'A major step forward has been accomplished by \\n', 'developing systems for several domains: military surveillance [1]\\n', '[2] [3], habitat monitoring [4] and structural monitoring [5].\\n', 'Even after these successes, several research problems remain\\n', 'open. Among these open problems is sensor node \\n', 'localization, i.e., how to find the physical position of each sensor\\n', 'node. Despite the attention the localization problem in WSN\\n', 'has received, no universally acceptable solution has been \\n', 'developed. There are several reasons for this. On one hand,\\n', 'localization schemes that use ranging are typically high end\\n', 'solutions. GPS ranging hardware consumes energy, it is \\n', 'relatively expensive (if high accuracy is required) and poses\\n', 'form factor challenges that move us away from the vision\\n', 'of dust size sensor nodes. Ultrasound has a short range and\\n', 'is highly directional. Solutions that use the radio transceiver\\n', 'for ranging either have not produced encouraging results (if\\n', 'the received signal strength indicator is used) or are sensitive\\n', 'to environment (e.g., multipath). On the other hand, \\n', 'localization schemes that only use the connectivity information\\n', 'for inferring location information are characterized by low\\n', 'accuracies: ≈ 10 ft in controlled environments, 40−50 ft in\\n', 'realistic ones.\\n', 'To address these challenges, we propose a framework for\\n', 'WSN localization, called StarDust, in which the \\n', 'complexity associated with the node localization is completely \\n', 'removed from the sensor node. The basic principle of the\\n', 'framework is localization through passivity: each sensor\\n', 'node is equipped with a corner-cube retro-reflector and \\n', 'possibly an optical filter (a coloring device). An aerial \\n', 'vehicle projects light onto the deployment area and records \\n', 'images containing retro-reflected light beams (they appear as\\n', 'luminous spots). Through image processing techniques, the\\n', 'locations of the retro-reflectors (i.e., sensor nodes) is \\n', 'deter57\\n', 'mined. For inferring the identity of the sensor node present\\n', 'at a particular location, the StarDust framework develops a\\n', 'constraint-based node ID relaxation algorithm.\\n', 'The main contributions of our work are the following. We\\n', 'propose a novel framework for node localization in WSNs\\n', 'that is very promising and allows for many future extensions\\n', 'and more accurate results. We propose a constraint-based\\n', 'label relaxation algorithm for mapping node IDs to the \\n', 'locations, and four constraints (node, connectivity, time and\\n', 'space), which are building blocks for very accurate and very\\n', 'fast localization systems. We develop a sensor node \\n', 'hardware prototype, called a SensorBall. We evaluate the \\n', 'performance of a localization system for which we obtain location\\n', 'accuracies of 2 − 5 ft with a localization duration ranging\\n', 'from 10 milliseconds to 2 minutes. We investigate the range\\n', 'of a system built on our framework by considering realities\\n', 'of physical phenomena that occurs during light propagation\\n', 'through the atmosphere.\\n', 'The rest of the paper is structured as follows. Section 2\\n', 'is an overview of the state of art. The design of the \\n', 'StarDust framework is presented in Section 3. One \\n', 'implementation and its performance evaluation are in Sections 4 and\\n', '5, followed by a suite of system optimization techniques, in\\n', 'Section 6. In Section 7 we present our conclusions.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'StarDust: A Flexible Architecture for Passive Localization in Wireless Sensor Networks'}, {'doc_id': 'C-77', 'full_text': ['Tracking Immediate Predecessors in Distributed Computations', 'A distributed computation is usually modeled as a partially\\n', 'ordered set of relevant events (the relevant events are a \\n', 'subset of the primitive events produced by the computation).\\n', 'An important causality-related distributed computing \\n', 'problem, that we call the Immediate Predecessors Tracking (IPT)\\n', 'problem, consists in associating with each relevant event, on\\n', 'the fly and without using additional control messages, the\\n', 'set of relevant events that are its immediate predecessors in\\n', 'the partial order. So, IPT is the on-the-fly computation of\\n', 'the transitive reduction (i.e., Hasse diagram) of the causality\\n', 'relation defined by a distributed computation. This paper\\n', 'addresses the IPT problem: it presents a family of \\n', 'protocols that provides each relevant event with a timestamp that\\n', 'exactly identifies its immediate predecessors. The family is\\n', 'defined by a general condition that allows application \\n', 'messages to piggyback control information whose size can be\\n', 'smaller than n (the number of processes). In that sense,\\n', 'this family defines message size-efficient IPT protocols. \\n', 'According to the way the general condition is implemented,\\n', 'different IPT protocols can be obtained. Two of them are\\n', 'exhibited.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Tracking Immediate Predecessors in Distributed Computations'}, {'doc_id': 'C-83', 'full_text': ['Concept and Architecture of a Pervasive Document Editing and Managing System', 'Collaborative document processing has been addressed by many\\n', 'approaches so far, most of which focus on document versioning\\n', 'and collaborative editing. We address this issue from a different\\n', 'angle and describe the concept and architecture of a pervasive\\n', 'document editing and managing system. It exploits database\\n', 'techniques and real-time updating for sophisticated collaboration\\n', 'scenarios on multiple devices. Each user is always served with \\n', 'upto-date documents and can organize his work based on document\\n', 'meta data. For this, we present our conceptual architecture for\\n', 'such a system and discuss it with an example.\\n', 'Text documents are a valuable resource for virtually any enterprise\\n', 'and organization. Documents like papers, reports and general\\n', 'business documentations contain a large part of today\"s (business)\\n', 'knowledge. Documents are mostly stored in a hierarchical folder\\n', 'structure on file servers and it is difficult to organize them in regard\\n', 'to classification, versioning etc., although it is of utmost importance\\n', 'that users can find, retrieve and edit up-to-date versions of\\n', 'documents whenever they want and, in a user-friendly way.\\n', '1.1 Problem Description\\n', 'With most of the commonly used word-processing applications\\n', 'documents can be manipulated by only one user at a time: tools for\\n', 'pervasive collaborative document editing and management, are\\n', 'rarely deployed in today\"s world. Despite the fact, that people strive\\n', 'for location- and time- independence, the importance of pervasive\\n', 'collaborative work, i.e. collaborative document editing and\\n', 'management is totally neglected. Documents could therefore be\\n', 'seen as a vulnerable source in today\"s world, which demands for an\\n', 'appropriate solution: The need to store, retrieve and edit these\\n', 'documents collaboratively anytime, everywhere and with almost\\n', 'every suitable device and with guaranteed mechanisms for security,\\n', 'consistency, availability and access control, is obvious.\\n', 'In addition, word processing systems ignore the fact that the history\\n', 'of a text document contains crucial information for its management.\\n', 'Such meta data includes creation date, creator, authors, version,\\n', 'location-based information such as time and place when/where a\\n', 'user reads/edits a document and so on. Such meta data can be\\n', 'gathered during the documents creation process and can be used\\n', 'versatilely. Especially in the field of pervasive document\\n', 'management, meta data is of crucial importance since it offers\\n', 'totally new ways of organizing and classifying documents: On the\\n', 'one hand, the user\"s actual situation influences the user\"s objectives.\\n', 'Meta data could be used to give the user the best possible view on\\n', 'the documents, dependent of his actual information. On the other\\n', 'hand, as soon as the user starts to work, i.e. reads or edits a\\n', 'document, new meta data can be gathered in order to make the\\n', 'system more adaptable and in a sense to the users situation and, to\\n', 'offer future users a better view on the documents.\\n', 'As far as we know, no system exists, that satisfies the\\n', 'aforementioned requirements. A very good overview about \\n', 'realtime communication and collaboration system is described in [7].\\n', 'We therefore strive for a pervasive document editing and\\n', 'management system, which enables pervasive (and collaborative)\\n', 'document editing and management: users should be able to read and\\n', 'edit documents whenever, wherever, with whomever and with\\n', 'whatever device.\\n', 'In this paper, we present collaborative database-based real-time\\n', 'word processing, which provides pervasive document editing and\\n', 'management functionality. It enables the user to work on\\n', 'documents collaboratively and offers sophisticated document\\n', 'management facility: the user is always served with up-to-date\\n', 'documents and can organize and manage documents on the base of\\n', 'meta data. Additionally document data is treated as ‘first class\\n', 'citizen\" of the database as demanded in [1].\\n', '1.2 Underlying Concepts\\n', 'The concept of our pervasive document editing and management\\n', 'system requires an appropriate architectural foundation. Our\\n', 'concept and implementation are based on the TeNDaX [3]\\n', 'collaborative database-based document editing and management\\n', 'system, which enables pervasive document editing and managing.\\n', 'TeNDaX is a Text Native Database eXtension. It enables the\\n', 'storage of text in databases in a native form so that editing text is\\n', 'finally represented as real-time transactions. Under the term ‘text\\n', 'editing\" we understand the following: writing and deleting text\\n', '(characters), copying & pasting text, defining text layout &\\n', 'structure, inserting notes, setting access rights, defining business\\n', 'processes, inserting tables, pictures, and so on i.e. all the actions\\n', 'regularly carried out by word processing users. With ‘real-time\\n', 'transaction\" we mean that editing text (e.g. writing a\\n', 'character/word) invokes one or several database transactions so that\\n', 'everything, which is typed appears within the editor as soon as these\\n', 'objects are stored persistently. Instead of creating files and storing\\n', 'them in a file system, the content and all of the meta data belonging\\n', 'to the documents is stored in a special way in the database, which\\n', 'enables very fast real-time transactions for all editing tasks [2].\\n', 'The database schema and the above-mentioned transactions are\\n', 'created in such a way that everything can be done within a \\n', 'multiuser environment, as is usual done by database technology. As a\\n', 'consequence, many of the achievements (with respect to data\\n', 'organization and querying, recovery, integrity and security\\n', 'enforcement, multi-user operation, distribution management,\\n', 'uniform tool access, etc.) are now, by means of this approach, also\\n', 'available for word processing.\\n', '2. APPROACH\\n', 'Our pervasive editing and management system is based on the\\n', 'above-mentioned database-based TeNDaX approach, where\\n', 'document data is stored natively in the database and supports\\n', 'pervasive collaborative text editing and document management.\\n', 'We define the pervasive document editing and management system,\\n', 'as a system, where documents can easily be accessed and\\n', 'manipulated everywhere (within the network), anytime\\n', '(independently of the number of users working on the same\\n', 'document) and with any device (desktop, notebook, PDA, mobile\\n', 'phone etc.).\\n', 'DB 3\\n', 'RTSC 4\\n', 'RTSC 1\\n', 'RTSC 2\\n', 'RTSC 3\\n', 'AS 1\\n', 'AS 3\\n', 'DB 1\\n', 'DB 2\\n', 'AS 2\\n', 'AS 4\\n', 'DB 4\\n', 'A\\n', 'B\\n', 'C\\n', 'D\\n', 'E\\n', 'F\\n', 'G\\n', 'Figure 1. TeNDaX Application Architecture\\n', 'In contrast to documents stored locally on the hard drive or on a file\\n', 'server, our system automatically serves the user with the up-to-date\\n', 'version of a document and changes done on the document are stored\\n', 'persistently in the database and immediately propagated to all\\n', 'clients who are working on the same document. Additionally, meta\\n', 'data gathered during the whole document creation process enables\\n', 'sophisticated document management. With the TeXt SQL API as\\n', 'abstract interface, this approach can be used by any tool and for any\\n', 'device.\\n', 'The system is built on the following components (see Figure 1): An\\n', 'editor in Java implements the presentation layer (A-G in Figure 1).\\n', 'The aim of this layer is the integration in a well-known \\n', 'wordprocessing application such as OpenOffice.\\n', 'The business logic layer represents the interface between the\\n', 'database and the word-processing application. It consists of the\\n', 'following three components: The application server (marked as AS\\n', '1-4 in Figure 1) enables text editing within the database\\n', 'environment and takes care of awareness, security, document\\n', 'management etc., all within a collaborative, real-time and multi-user\\n', 'environment. The real-time server component (marked as RTSC \\n', '14 in Figure 1) is responsible for the propagation of information, i.e.\\n', 'updates between all of the connected editors.\\n', 'The storage engine (data layer) primarily stores the content of\\n', 'documents as well as all related meta data within the database\\n', 'Databases can be distributed in a peer-to-peer network (DB 1-4 in\\n', 'Figure 1)..\\n', 'In the following, we will briefly present the database schema, the\\n', 'editor and the real-time server component as well as the concept of\\n', 'dynamic folders, which enables sophisticated document\\n', 'management on the basis of meta data.\\n', '2.1 Application Architecture\\n', 'A database-based real-time collaborative editor allows the same\\n', 'document to be opened and edited simultaneously on the same\\n', 'computer or over a network of several computers and mobile\\n', 'devices. All concurrency issues, as well as message propagation, are\\n', 'solved within this approach, while multiple instances of the same\\n', 'document are being opened [3]. Each insert or delete action is a\\n', 'database transaction and as such, is immediately stored persistently\\n', 'in the database and propagated to all clients working on the same\\n', 'document.\\n', '2.1.1 Database Schema\\n', 'As it was mentioned earlier that text is stored in a native way. Each\\n', 'character of a text document is stored as a single object in the\\n', 'database [3]. When storing text in such a native form, the\\n', 'performance of the employed database system is of crucial\\n', 'importance. The concept and performance issues of such a text\\n', 'database are described in [3], collaborative layouting in [2],\\n', 'dynamic collaborative business processes within documents in [5],\\n', 'the text editing creation time meta data model in [6] and the relation\\n', 'to XML databases in [7].\\n', 'Figure 2 depicts the core database schema. By connecting a client to\\n', 'the database, a Session instance is created. One important attribute\\n', 'of the Session is the DocumentSession. This attribute refers to\\n', 'DocumentSession instances, which administrates all opened\\n', 'documents. For each opened document, a DocumentSession\\n', 'instance is created. The DocumentSession is important for the \\n', 'realtime server component, which, in case of a\\n', '42\\n', 'is beforeis after\\n', 'Char\\n', '(ID)\\n', 'has\\n', 'TextElement\\n', '(ID)\\n', 'starts\\n', 'with\\n', 'is used\\n', 'by\\n', 'InternalFile\\n', '(ID)\\n', 'is in includes\\n', 'created\\n', 'at\\n', 'has\\n', 'inserted\\n', 'by\\n', 'inserted\\n', 'is active\\n', 'ir\\n', 'ir\\n', 'CharacterValue\\n', '(Unicode)\\n', 'has\\n', 'List\\n', '(ID)\\n', 'starts\\n', 'starts\\n', 'with\\n', 'ends ends with\\n', 'FileSize\\n', 'has\\n', 'User\\n', '(ID)\\n', 'last read by\\n', 'last written by\\n', 'created\\n', 'at\\n', 'created by\\n', 'Style\\n', 'DTD\\n', '(ID)\\n', 'is used\\n', 'by\\n', 'uses\\n', 'uses\\n', 'is used\\n', 'by\\n', 'Authors\\n', 'arehas\\n', 'Description\\n', 'Password\\n', 'Picture\\n', 'UserColors\\n', 'UserListSecurity\\n', 'has\\n', 'has\\n', 'has\\n', 'has\\n', 'has\\n', 'has\\n', 'FileNode\\n', '(ID)\\n', 'references/isreferencedby\\n', 'is dynamic DynStructure\\n', 'NodeDetails\\n', 'has\\n', 'has is NodeType\\n', 'is parent\\n', 'of\\n', 'has\\n', 'parent\\n', 'has\\n', 'Role\\n', '(ID)\\n', 'created\\n', 'at\\n', 'created\\n', 'created\\n', 'by\\n', 'Name\\n', 'has\\n', 'Description\\n', 'is user\\n', 'Name\\n', 'has\\n', 'has\\n', 'main role\\n', 'FileNodeAccessMatrix\\n', '(ID)\\n', 'has\\n', 'is\\n', 'AccessMatrix\\n', 'read option\\n', 'grand option\\n', 'write option\\n', 'contains\\n', 'has\\n', 'access\\n', 'Times\\n', 'opened … times with … by\\n', 'contains/ispartof\\n', 'ir\\n', 'ir\\n', 'is...andincludes\\n', 'Lineage\\n', '(ID)\\n', 'references\\n', 'is after\\n', 'is before\\n', 'CopyPaste\\n', '(ID)\\n', 'references\\n', 'is in\\n', 'is copy\\n', 'of\\n', 'is a copy\\n', 'from\\n', 'hasCopyPaste\\n', '(ID)\\n', 'is activeLength has\\n', 'Str (Stream)\\n', 'has\\n', 'inserted by / inserted\\n', 'RegularChar\\n', 'StartChar EndChar\\n', 'File\\n', 'ExternalFile\\n', 'is from\\n', 'URL\\n', 'Type\\n', '(extension)\\n', 'is of\\n', 'Title\\n', 'has\\n', 'DocumentSession\\n', '(ID)\\n', 'is opened\\n', 'by\\n', 'has\\n', 'opened\\n', 'has\\n', 'opened\\n', 'Session\\n', '(ID)\\n', 'isconnectedwith\\n', 'launched by\\n', 'VersionNumber\\n', 'uses\\n', 'has\\n', 'read option\\n', 'grand option\\n', 'write option\\n', 'ends with\\n', 'is used\\n', 'by\\n', 'is in has\\n', 'is unique\\n', 'DTD (Stream)\\n', 'has\\n', 'has\\n', 'Name\\n', 'Column\\n', '(ID)\\n', 'has set on\\n', 'On/off\\n', 'isvisible…for\\n', 'false\\n', 'LanguageProfile\\n', '(ID)\\n', 'has\\n', 'contains\\n', 'Name\\n', 'Profile\\n', 'Marking\\n', '(ID)\\n', 'has\\n', 'parent\\n', 'internal\\n', 'is copy\\n', 'from\\n', 'hasRank\\n', 'is onPosition\\n', 'starts\\n', 'with\\n', 'ends with\\n', 'is logical style\\n', 'is itemized\\n', 'is italic\\n', 'is enumerated\\n', 'is underline\\n', 'is\\n', 'is part of\\n', 'Alignment\\n', 'Size has\\n', 'Font has\\n', 'hasColor\\n', 'is bold\\n', 'has\\n', 'uses\\n', 'ElementName\\n', 'StylesheetName\\n', 'isused\\n', 'by\\n', 'Process\\n', '(ID)\\n', 'is running by OS\\n', 'is web session\\n', 'MainRoles\\n', 'Roles has\\n', 'has\\n', 'Timestamp\\n', '(Date, Time)\\n', 'created\\n', 'at\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)created\\n', 'at\\n', 'Type\\n', 'has\\n', 'Port\\n', 'IP\\n', 'has\\n', 'has\\n', 'MessagePropagator\\n', '(ID)\\n', 'Picture\\n', '(Stream)\\n', 'Name\\n', 'Picture\\n', '(ID)\\n', 'has\\n', 'contains\\n', 'LayoutBlock WorkflowBlockLogicalBlock\\n', 'contains\\n', 'BlockDataType\\n', 'has\\n', 'property\\n', 'BlockData is of\\n', 'WorkflowInstance\\n', '(ID)\\n', 'isin\\n', 'TaskInstance\\n', '(ID)\\n', 'has\\n', 'parent\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'last modified at\\n', 'completed at\\n', 'started at\\n', 'created\\n', 'at\\n', 'is on\\n', 'has\\n', 'Name\\n', 'created by\\n', 'has\\n', 'attached\\n', 'Comment\\n', 'Typeis of\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'created\\n', 'at\\n', 'started at\\n', '<< last modified at\\n', 'is\\n', 'Category\\n', 'Editors\\n', 'has\\n', 'Status\\n', 'has\\n', 'Timestamp\\n', '(Date, Time)\\n', '<< status last modified\\n', 'Timestamp\\n', '(Date, Time)\\n', 'is due at\\n', 'DueType\\n', 'has\\n', 'Timezone\\n', 'has\\n', 'Notes\\n', 'has\\n', 'SecurityLevel\\n', 'hasset\\n', 'Timestamp\\n', '(Date, Time)\\n', '<< is completed at\\n', 'isfollowedby\\n', 'Task\\n', '(Code)\\n', 'Description\\n', 'has\\n', 'Indent\\n', 'references\\n', 'hasbeenopenedat...by\\n', 'Timestamp\\n', 'RedoHistory\\n', 'is before\\n', 'is after\\n', 'references\\n', 'hasCharCounter\\n', 'is inhas\\n', 'has\\n', 'Offset\\n', 'ActionID\\n', '(Code)\\n', 'Timestamp\\n', '(Date, Time)\\n', 'invoked\\n', 'at\\n', 'invoked\\n', 'by\\n', 'Version\\n', '(ID)\\n', 'isbuild\\n', 'from\\n', 'has\\n', 'created\\n', 'byarchived\\n', 'has\\n', 'Comment\\n', 'Timestamp\\n', '(Date, Time)\\n', '<<createdat\\n', 'UndoHistory\\n', '(ID)\\n', 'starts\\n', 'ends\\n', 'has\\n', 'Name\\n', 'created\\n', 'by\\n', 'Name\\n', 'has\\n', 'is before\\n', 'is after\\n', '<< references\\n', 'CharCounter\\n', 'has\\n', 'is in\\n', 'created\\n', 'at\\n', 'Timestamp\\n', 'is active\\n', 'created\\n', 'by\\n', 'is used\\n', 'by\\n', 'Offset\\n', 'has\\n', 'created\\n', 'at\\n', 'Timestamp\\n', 'Index\\n', '(ID)\\n', 'lastmodifiedby\\n', 'Lexicon\\n', '(ID)\\n', 'isof\\n', 'Frequency\\n', 'is\\n', 'occurring\\n', 'is stop word\\n', 'Term\\n', 'is\\n', 'is in\\n', 'ends with\\n', 'starts\\n', 'with\\n', '<< original starts with\\n', 'WordNumber\\n', 'SentenceNumber\\n', 'ParagraphNumber\\n', 'Citatons\\n', 'has\\n', 'is in\\n', 'is\\n', 'is in\\n', 'istemporary\\n', 'is in\\n', 'has\\n', 'Structure\\n', 'has\\n', 'ElementPath\\n', 'createdat\\n', 'Timestamp\\n', '<< describes\\n', 'SpiderBuild\\n', '(ID)\\n', 'is updated\\n', 'is deleted\\n', 'Timestamp\\n', '(Date, Time)\\n', '<<lastupdatedat\\n', 'has validated structure\\n', '<<neededtoindex\\n', 'Time\\n', '(ms)\\n', 'IndexUpdate\\n', 'nextupdatein\\n', 'hasindexed\\n', 'isrunningbyOS\\n', 'lastupdate\\n', 'enabled\\n', 'Timestamp\\n', 'Time\\n', '(s)\\n', 'Documents\\n', 'StopCharacter\\n', 'Description\\n', 'Character\\n', 'Value\\n', '(ASCII)\\n', 'is sentence stop\\n', 'is paragraph stop\\n', 'Name\\n', 'has\\n', 'is\\n', 'is\\n', 'OptionsSettings\\n', 'show information show warningsshow exceptions\\n', 'do lineage recording\\n', 'do internal lineage recording\\n', 'ask for unknown source\\n', 'show intra document\\n', 'lineage information\\n', 'are set\\n', 'for\\n', 'X\\n', 'X\\n', 'X\\n', 'VirtualBorder\\n', '(ID)\\n', 'isonhas\\n', '{1, 2}\\n', '{1, 2}\\n', 'ir\\n', 'ir\\n', 'UserMode\\n', '(Code)\\n', 'UserMode\\n', '(Code)\\n', 'Figure 2. TeNDaX Database Schema (Object Role Modeling Diagram)\\n', 'change on a document done by a client, is responsible for sending\\n', 'update information to all the clients working on the same\\n', 'document. The DocumentId in the class DocumentSession points\\n', 'to a FileNode instance, and corresponds to the ID of the opened\\n', 'document. Instances of the class FileNode either represent a\\n', 'folder node or a document node. The folder node corresponds to a\\n', 'folder of a file system and the document node to that of a file.\\n', 'Instances of the class Char represent the characters of a\\n', 'document. The value of a character is stored in the attribute\\n', 'CharacterValue. The sequence is defined by the attributes After\\n', 'and Before of the class Char. Particular instances of Char mark\\n', 'the beginning and the end of a document. The methods\\n', 'InsertChars and RemoveChars are used to add and delete\\n', 'characters.\\n', '2.1.2 Editor\\n', 'As seen above, each document is natively stored in the database.\\n', 'Our editor does not have a replica of one part of the native text\\n', 'database in the sense of database replicas. Instead, it has a so-called\\n', 'image as its replica. Even if several authors edit the same text at the\\n', 'same time, they work on one unique document at all times. The\\n', 'system guarantees this unique view.\\n', 'Editing a document involves a number of steps: first, getting the\\n', 'required information out of the image, secondly, invoking the\\n', 'corresponding methods within the database, thirdly, changing the\\n', 'image, and fourthly, informing all other clients about the changes.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Concept and Architecture of a Pervasive Document Editing and Managing System'}, {'doc_id': 'H-37', 'full_text': ['Relaxed Online SVMs for Spam Filtering', 'Spam is a key problem in electronic communication, \\n', 'including large-scale email systems and the growing number of\\n', 'blogs. Content-based filtering is one reliable method of \\n', 'combating this threat in its various forms, but some academic\\n', 'researchers and industrial practitioners disagree on how best\\n', 'to filter spam. The former have advocated the use of \\n', 'Support Vector Machines (SVMs) for content-based filtering,\\n', 'as this machine learning methodology gives state-of-the-art\\n', 'performance for text classification. However, similar \\n', 'performance gains have yet to be demonstrated for online spam\\n', 'filtering. Additionally, practitioners cite the high cost of\\n', 'SVMs as reason to prefer faster (if less statistically robust)\\n', 'Bayesian methods. In this paper, we offer a resolution to this\\n', 'controversy. First, we show that online SVMs indeed give\\n', 'state-of-the-art classification performance on online spam\\n', 'filtering on large benchmark data sets. Second, we show\\n', 'that nearly equivalent performance may be achieved by a\\n', 'Relaxed Online SVM (ROSVM) at greatly reduced \\n', 'computational cost. Our results are experimentally verified on\\n', 'email spam, blog spam, and splog detection tasks.\\n', 'Electronic communication is increasingly plagued by \\n', 'unwanted or harmful content known as spam. The most well\\n', 'known form of spam is email spam, which remains a major\\n', 'problem for large email systems. Other forms of spam are\\n', 'also becoming problematic, including blog spam, in which\\n', 'spammers post unwanted comments in blogs [21], and splogs,\\n', 'which are fake blogs constructed to enable link spam with\\n', 'the hope of boosting the measured importance of a given\\n', 'webpage in the eyes of automated search engines [17]. There\\n', 'are a variety of methods for identifying these many forms\\n', 'of spam, including compiling blacklists of known spammers,\\n', 'and conducting link analysis.\\n', 'The approach of content analysis has shown particular\\n', 'promise and generality for combating spam. In content \\n', 'analysis, the actual message text (often including hyper-text and\\n', 'meta-text, such as HTML and headers) is analyzed using\\n', 'machine learning techniques for text classification to \\n', 'determine if the given content is spam. Content analysis has\\n', 'been widely applied in detecting email spam [11], and has\\n', 'also been used for identifying blog spam [21] and splogs [17].\\n', 'In this paper, we do not explore the related problem of link\\n', 'spam, which is currently best combated by link analysis [13].\\n', '1.1 An Anti-Spam Controversy\\n', 'The anti-spam community has been divided on the choice\\n', 'of the best machine learning method for content-based spam\\n', 'detection. Academic researchers have tended to favor the\\n', 'use of Support Vector Machines (SVMs), a statistically \\n', 'robust machine learning method [7] which yields \\n', 'state-of-theart performance on general text classification [14]. However,\\n', 'SVMs typically require training time that is quadratic in the\\n', 'number of training examples, and are impractical for \\n', 'largescale email systems. Practitioners requiring content-based\\n', 'spam filtering have typically chosen to use the faster (if\\n', 'less statistically robust) machine learning method of Naive\\n', 'Bayes text classification [11, 12, 20]. This Bayesian method\\n', 'requires only linear training time, and is easily implemented\\n', 'in an online setting with incremental updates. This allows a\\n', 'deployed system to easily adapt to a changing environment\\n', 'over time. Other fast methods for spam filtering include\\n', 'compression models [1] and logistic regression [10]. It has\\n', 'not yet been empirically demonstrated that SVMs give \\n', 'improved performance over these methods in an online spam\\n', 'detection setting [4].\\n', '1.2 Contributions\\n', 'In this paper, we address the anti-spam controversy and\\n', 'offer a potential resolution. We first demonstrate that \\n', 'online SVMs do indeed provide state-of-the-art spam detection\\n', 'through empirical tests on several large benchmark data sets\\n', 'of email spam. We then analyze the effect of the tradeoff\\n', 'parameter in the SVM objective function, which shows that\\n', 'the expensive SVM methodology may, in fact, be overkill for\\n', 'spam detection. We reduce the computational cost of SVM\\n', 'learning by relaxing this requirement on the maximum \\n', 'margin in online settings, and create a Relaxed Online SVM,\\n', 'ROSVM, appropriate for high performance content-based\\n', 'spam filtering in large-scale settings.\\n', '2. SPAM AND ONLINE SVMS\\n', 'The controversy between academics and practitioners in\\n', 'spam filtering centers on the use of SVMs. The former \\n', 'advocate their use, but have yet to demonstrate strong \\n', 'performance with SVMs on online spam filtering. Indeed, the\\n', 'results of [4] show that, when used with default parameters,\\n', 'SVMs actually perform worse than other methods. In this\\n', 'section, we review the basic workings of SVMs and describe\\n', 'a simple Online SVM algorithm. We then show that Online\\n', 'SVMs indeed achieve state-of-the-art performance on \\n', 'filtering email spam, blog comment spam, and splogs, so long as\\n', 'the tradeoff parameter C is set to a high value. However, the\\n', 'cost of Online SVMs turns out to be prohibitive for \\n', 'largescale applications. These findings motivate our proposal of\\n', 'Relaxed Online SVMs in the following section.\\n', '2.1 Background: SVMs\\n', 'SVMs are a robust machine learning methodology which\\n', 'has been shown to yield state-of-the-art performance on text\\n', 'classification [14]. by finding a hyperplane that separates\\n', 'two classes of data in data space while maximizing the \\n', 'margin between them.\\n', 'We use the following notation to describe SVMs, which\\n', 'draws from [23]. A data set X contains n labeled example\\n', 'vectors {(x1, y1) . . . (xn, yn)}, where each xi is a vector \\n', 'containing features describing example i, and each yi is the class\\n', 'label for that example. In spam detection, the classes spam\\n', 'and ham (i.e., not spam) are assigned the numerical class\\n', 'labels +1 and −1, respectively. The linear SVMs we employ\\n', 'in this paper use a hypothesis vector w and bias term b to\\n', 'classify a new example x, by generating a predicted class\\n', 'label f(x):\\n', 'f(x) = sign(< w, x > +b)\\n', 'SVMs find the hypothesis w, which defines the separating\\n', 'hyperplane, by minimizing the following objective function\\n', 'over all n training examples:\\n', 'τ(w, ξ) =\\n', '1\\n', '2\\n', '||w||2\\n', '+ C\\n', 'nX\\n', 'i=i\\n', 'ξi\\n', 'under the constraints that\\n', '∀i = {1..n} : yi(< w, xi > +b) ≥ 1 − ξi, ξi ≥ 0\\n', 'In this objective function, each slack variable ξi shows the\\n', 'amount of error that the classifier makes on a given example\\n', 'xi. Minimizing the sum of the slack variables corresponds\\n', 'to minimizing the loss function on the training data, while\\n', 'minimizing the term 1\\n', '2\\n', '||w||2\\n', 'corresponds to maximizing the\\n', 'margin between the two classes [23]. These two optimization\\n', 'goals are often in conflict; the tradeoff parameter C \\n', 'determines how much importance to give each of these tasks.\\n', 'Linear SVMs exploit data sparsity to classify a new \\n', 'instance in O(s) time, where s is the number of non-zero \\n', 'features. This is the same classification time as other linear\\n', 'Given: data set X = (x1, y1), . . . , (xn, yn), C, m:\\n', 'Initialize w := 0, b := 0, seenData := { }\\n', 'For Each xi ∈ X do:\\n', 'Classify xi using f(xi) = sign(< w, xi > +b)\\n', 'IF yif(xi) < 1\\n', 'Find w , b using SMO on seenData,\\n', 'using w, b as seed hypothesis.\\n', 'Add xi to seenData\\n', 'done\\n', 'Figure 1: Pseudo code for Online SVM.\\n', 'classifiers, and as Naive Bayesian classification. Training\\n', 'SVMs, however, typically takes O(n2\\n', ') time, for n training\\n', 'examples. A variant for linear SVMs was recently proposed\\n', 'which trains in O(ns) time [15], but because this method\\n', 'has a high constant, we do not explore it here.\\n', '2.2 Online SVMs\\n', 'In many traditional machine learning applications, SVMs\\n', 'are applied in batch mode. That is, an SVM is trained on\\n', 'an entire set of training data, and is then tested on a \\n', 'separate set of testing data. Spam filtering is typically tested\\n', 'and deployed in an online setting, which proceeds \\n', 'incrementally. Here, the learner classifies a new example, is told if\\n', 'its prediction is correct, updates its hypothesis accordingly,\\n', 'and then awaits a new example. Online learning allows a\\n', 'deployed system to adapt itself in a changing environment.\\n', 'Re-training an SVM from scratch on the entire set of \\n', 'previously seen data for each new example is cost prohibitive.\\n', 'However, using an old hypothesis as the starting point for\\n', 're-training reduces this cost considerably. One method of \\n', 'incremental and decremental SVM learning was proposed in\\n', '[2]. Because we are only concerned with incremental \\n', 'learning, we apply a simpler algorithm for converting a batch\\n', 'SVM learner into an online SVM (see Figure 1 for \\n', 'pseudocode), which is similar to the approach of [16].\\n', 'Each time the Online SVM encounters an example that\\n', 'was poorly classified, it retrains using the old hypothesis as\\n', 'a starting point. Note that due to the Karush-Kuhn-Tucker\\n', '(KKT) conditions, it is not necessary to re-train on \\n', 'wellclassified examples that are outside the margins [23].\\n', 'We used Platt\"s SMO algorithm [22] as a core SVM solver,\\n', 'because it is an iterative method that is well suited to \\n', 'converge quickly from a good initial hypothesis. Because \\n', 'previous work (and our own initial testing) indicates that binary\\n', 'feature values give the best results for spam filtering [20,\\n', '9], we optimized our implementation of the Online SMO to\\n', 'exploit fast inner-products with binary vectors. 1\\n', '2.3 Feature Mapping Spam Content\\n', 'Extracting machine learning features from text may be\\n', 'done in a variety of ways, especially when that text may\\n', 'include hyper-content and meta-content such as HTML and\\n', 'header information. However, previous research has shown\\n', 'that simple methods from text classification, such as bag\\n', 'of words vectors, and overlapping character-level n-grams,\\n', 'can achieve strong results [9]. Formally, a bag of words \\n', 'vector is a vector x with a unique dimension for each possible\\n', '1\\n', 'Our source code is freely available at\\n', 'www.cs.tufts.edu/∼dsculley/onlineSMO.\\n', '1\\n', '0.999\\n', '0.995\\n', '0.99\\n', '0.985\\n', '0.98\\n', '0.1 1 10 100 1000\\n', 'ROCArea\\n', 'C\\n', '2-grams\\n', '3-grams\\n', '4-grams\\n', 'words\\n', 'Figure 2: Tuning the Tradeoff Parameter C. Tests\\n', 'were conducted with Online SMO, using binary \\n', 'feature vectors, on the spamassassin data set of 6034\\n', 'examples. Graph plots C versus Area under the\\n', 'ROC curve.\\n', 'word, defined as a contiguous substring of non-whitespace\\n', 'characters. An n-gram vector is a vector x with a unique\\n', 'dimension for each possible substring of n total characters.\\n', 'Note that n-grams may include whitespace, and are \\n', 'overlapping. We use binary feature scoring, which has been shown\\n', 'to be most effective for a variety of spam detection \\n', 'methods [20, 9]. We normalize the vectors with the Euclidean\\n', 'norm. Furthermore, with email data, we reduce the impact\\n', 'of long messages (for example, with attachments) by \\n', 'considering only the first 3,000 characters of each string. For blog\\n', 'comments and splogs, we consider the whole text, \\n', 'including any meta-data such as HTML tags, as given. No other\\n', 'feature selection or domain knowledge was used.\\n', '2.4 Tuning the Tradeoff Parameter, C\\n', 'The SVM tradeoff parameter C must be tuned to balance\\n', 'the (potentially conflicting) goals of maximizing the \\n', 'margin and minimizing the training error. Early work on SVM\\n', 'based spam detection [9] showed that high values of C give\\n', 'best performance with binary features. Later work has not\\n', 'always followed this lead: a (low) default setting of C was\\n', 'used on splog detection [17], and also on email spam [4].\\n', 'Following standard machine learning practice, we tuned C\\n', 'on separate tuning data not used for later testing. We used\\n', 'the publicly available spamassassin email spam data set,\\n', 'and created an online learning task by randomly interleaving\\n', 'all 6034 labeled messages to create a single ordered set.\\n', 'For tuning, we performed a coarse parameter search for C\\n', 'using powers of ten from .0001 to 10000. We used the Online\\n', 'SVM described above, and tested both binary bag of words\\n', 'vectors and n-gram vectors with n = {2, 3, 4}. We used the\\n', 'first 3000 characters of each message, which included header\\n', 'information, body of the email, and possibly attachments.\\n', 'Following the recommendation of [6], we use Area under\\n', 'the ROC curve as our evaluation measure. The results (see\\n', 'Figure 2) agree with [9]: there is a plateau of high \\n', 'performance achieved with all values of C ≥ 10, and performance\\n', 'degrades sharply with C < 1. For the remainder of our \\n', 'experiments with SVMs in this paper, we set C = 100. We\\n', 'will return to the observation that very high values of C do\\n', 'not degrade performance as support for the intuition that\\n', 'relaxed SVMs should perform well on spam.\\n', 'Table 1: Results for Email Spam filtering with \\n', 'Online SVM on benchmark data sets. Score reported\\n', 'is (1-ROCA)%, where 0 is optimal.\\n', 'trec05p-1 trec06p\\n', 'OnSVM: words 0.015 (.011-.022) 0.034 (.025-.046)\\n', '3-grams 0.011 (.009-.015) 0.025 (.017-.035)\\n', '4-grams 0.008 (.007-.011) 0.023 (.017-.032)\\n', 'SpamProbe 0.059 (.049-.071) 0.092 (.078-.110)\\n', 'BogoFilter 0.048 (.038-.062) 0.077 (.056-.105)\\n', 'TREC Winners 0.019 (.015-.023) 0.054 (.034-.085)\\n', '53-Ensemble 0.007 (.005-.008) 0.020 (.007-.050)\\n', 'Table 2: Results for Blog Comment Spam Detection\\n', 'using SVMs and Leave One Out Cross Validation.\\n', 'We report the same performance measures as in the\\n', 'prior work for meaningful comparison.\\n', 'accuracy precision recall\\n', 'SVM C = 100: words 0.931 0.946 0.954\\n', '3-grams 0.951 0.963 0.965\\n', '4-grams 0.949 0.967 0.956\\n', 'Prior best method 0.83 0.874 0.874\\n', '2.5 Email Spam and Online SVMs\\n', 'With C tuned on a separate tuning set, we then tested the\\n', 'performance of Online SVMs in spam detection. We used\\n', 'two large benchmark data sets of email spam as our test\\n', 'corpora. These data sets are the 2005 TREC public data set\\n', 'trec05p-1 of 92,189 messages, and the 2006 TREC public\\n', 'data sets, trec06p, containing 37,822 messages in English.\\n', '(We do not report our strong results on the trec06c corpus\\n', 'of Chinese messages as there have been questions raised over\\n', 'the validity of this test set.) We used the canonical ordering\\n', 'provided with each of these data sets for fair comparison.\\n', 'Results for these experiments, with bag of words vectors\\n', 'and and n-gram vectors appear in Table 1. To compare our\\n', 'results with previous scores on these data sets, we use the\\n', 'same (1-ROCA)% measure described in [6], which is one \\n', 'minus the area under the ROC curve, expressed as a percent.\\n', 'This measure shows the percent chance of error made by\\n', 'a classifier asserting that one message is more likely to be\\n', 'spam than another. These results show that Online SVMs\\n', 'do give state of the art performance on email spam. The\\n', 'only known system that out-performs the Online SVMs on\\n', 'the trec05p-1 data set is a recent ensemble classifier which\\n', 'combines the results of 53 unique spam filters [19]. To\\n', 'our knowledge, the Online SVM has out-performed every\\n', 'other single filter on these data sets, including those using\\n', 'Bayesian methods [5, 3], compression models [5, 3], logistic\\n', 'regression [10], and perceptron variants [3], the TREC \\n', 'competition winners [5, 3], and open source email spam filters\\n', 'BogoFilter v1.1.5 and SpamProbe v1.4d.\\n', '2.6 Blog Comment Spam and SVMs\\n', 'Blog comment spam is similar to email spam in many \\n', 'regards, and content-based methods have been proposed for\\n', 'detecting these spam comments [21]. However, large \\n', 'benchmark data sets of labeled blog comment spam do not yet \\n', 'exist. Thus, we run experiments on the only publicly available\\n', 'data set we know of, which was used in content-based blog\\n', 'Table 3: Results for Splog vs. Blog Detection using\\n', 'SVMs and Leave One Out Cross Validation. We\\n', 'report the same evaluation measures as in the prior\\n', 'work for meaningful comparison.\\n', 'features precision recall F1\\n', 'SVM C = 100: words 0.921 0.870 0.895\\n', '3-grams 0.904 0.866 0.885\\n', '4-grams 0.928 0.876 0.901\\n', 'Prior SVM with: words 0.887 0.864 0.875\\n', '4-grams 0.867 0.844 0.855\\n', 'words+urls 0.893 0.869 0.881\\n', 'comment spam detection experiments by [21]. Because of\\n', 'the small size of the data set, and because prior researchers\\n', 'did not conduct their experiments in an on-line setting, we\\n', 'test the performance of linear SVMs using leave-one-out\\n', 'cross validation, with SVM-Light, a standard open-source\\n', 'SVM implementation [14]. We use the parameter setting\\n', 'C = 100, with the same feature space mappings as above.\\n', 'We report accuracy, precision, and recall to compare these to\\n', 'the results given on the same data set by [21]. These results\\n', '(see Table 2) show that SVMs give superior performance on\\n', 'this data set to the prior methodology.\\n', '2.7 Splogs and SVMs\\n', 'As with blog comment spam, there is not yet a large, \\n', 'publicly available benchmark corpus of labeled splog detection\\n', 'test data. However, the authors of [17] kindly provided us\\n', 'with the labeled data set of 1,389 blogs and splogs that they\\n', 'used to test content-based splog detection using SVMs. The\\n', 'only difference between our methodology and that of [17] is\\n', 'that they used default parameters for C, which SVM-Light\\n', 'sets to 1\\n', 'avg||x||2\\n', '. (For normalized vectors, this default value\\n', 'sets C = 1.) They also tested several domain-informed \\n', 'feature mappings, such as giving special features to url tags.\\n', 'For our experiments, we used the same feature mappings\\n', 'as above, and tested the effect of setting C = 100. As with\\n', 'the methodology of [17], we performed leave one out cross\\n', 'validation for apples-to-apples comparison on this data. The\\n', 'results (see Table 3) show that a high value of C produces\\n', 'higher performance for the same feature space mappings,\\n', 'and even enables the simple 4-gram mapping to out-perform\\n', 'the previous best mapping which incorporated domain \\n', 'knowledge by using words and urls.\\n', '2.8 Computational Cost\\n', 'The results presented in this section demonstrate that \\n', 'linfeatures trec06p trec05p-1\\n', 'words 12196s 66478s\\n', '3-grams 44605s 128924s\\n', '4-grams 87519s 242160s\\n', 'corpus size 32822 92189\\n', 'Table 4: Execution time for Online SVMs with email\\n', 'spam detection, in CPU seconds. These times do\\n', 'not include the time spent mapping strings to \\n', 'feature vectors. The number of examples in each data\\n', 'set is given in the last row as corpus size.\\n', 'A\\n', 'B\\n', 'Figure 3: Visualizing the effect of C. \\n', 'Hyperplane A maximizes the margin while accepting a\\n', 'small amount of training error. This corresponds\\n', 'to setting C to a low value. Hyperplane B \\n', 'accepts a smaller margin in order to reduce \\n', 'training error. This corresponds to setting C to a high\\n', 'value. Content-based spam filtering appears to do\\n', 'best with high values of C.\\n', 'ear SVMs give state of the art performance on content-based\\n', 'spam filtering. However, this performance comes at a price.\\n', 'Although the blog comment spam and splog data sets are\\n', 'too small for the quadratic training time of SVMs to \\n', 'appear problematic, the email data sets are large enough to\\n', 'illustrate the problems of quadratic training cost.\\n', 'Table 4 shows computation time versus data set size for\\n', 'each of the online learning tasks (on same system). The\\n', 'training cost of SVMs are prohibitive for large-scale content\\n', 'based spam detection, or a large blog host. In the \\n', 'following section, we reduce this cost by relaxing the expensive\\n', 'requirements of SVMs.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Relaxed Online SVMs for Spam Filtering'}, {'doc_id': 'H-64', 'full_text': ['Machine Learning for Information Architecture in a Large Governmental Website ∗', 'This paper describes ongoing research into the application\\n', 'of machine learning techniques for improving access to \\n', 'governmental information in complex digital libraries. Under\\n', 'the auspices of the GovStat Project, our goal is to identify a\\n', 'small number of semantically valid concepts that adequately\\n', 'spans the intellectual domain of a collection. The goal of this\\n', 'discovery is twofold. First we desire a practical aid for \\n', 'information architects. Second, automatically derived \\n', 'documentconcept relationships are a necessary precondition for \\n', 'realworld deployment of many dynamic interfaces. The current\\n', 'study compares concept learning strategies based on three\\n', 'document representations: keywords, titles, and full-text. In\\n', 'statistical and user-based studies, human-created keywords\\n', 'provide significant improvements in concept learning over\\n', 'both title-only and full-text representations.\\n', 'The GovStat Project is a joint effort of the University\\n', 'of North Carolina Interaction Design Lab and the \\n', 'University of Maryland Human-Computer Interaction Lab1\\n', '. \\n', 'Citing end-user difficulty in finding governmental information\\n', '(especially statistical data) online, the project seeks to \\n', 'create an integrated model of user access to US government\\n', 'statistical information that is rooted in realistic data \\n', 'models and innovative user interfaces. To enable such models\\n', 'and interfaces, we propose a data-driven approach, based\\n', 'on data mining and machine learning techniques. In \\n', 'particular, our work analyzes a particular digital library-the\\n', 'website of the Bureau of Labor Statistics2\\n', '(BLS)-in efforts\\n', 'to discover a small number of linguistically meaningful \\n', 'concepts, or bins, that collectively summarize the semantic\\n', 'domain of the site.\\n', 'The project goal is to classify the site\"s web content \\n', 'according to these inferred concepts as an initial step towards\\n', 'data filtering via active user interfaces (cf. [13]). Many\\n', 'digital libraries already make use of content classification,\\n', 'both explicitly and implicitly; they divide their resources\\n', 'manually by topical relation; they organize content into \\n', 'hierarchically oriented file systems. The goal of the present\\n', '1\\n', 'http://www.ils.unc.edu/govstat\\n', '2\\n', 'http://www.bls.gov\\n', '151\\n', 'research is to develop another means of browsing the content\\n', 'of these collections. By analyzing the distribution of terms\\n', 'across documents, our goal is to supplement the agency\"s\\n', 'pre-existing information structures. Statistical learning \\n', 'technologies are appealing in this context insofar as they stand\\n', 'to define a data-driven-as opposed to an \\n', 'agency-drivennavigational structure for a site.\\n', 'Our approach combines supervised and unsupervised \\n', 'learning techniques. A pure document clustering [12] approach\\n', 'to such a large, diverse collection as BLS led to poor results\\n', 'in early tests [6]. But strictly supervised techniques [5] are\\n', 'inappropriate, too. Although BLS designers have defined\\n', 'high-level subject headings for their collections, as we \\n', 'discuss in Section 2, this scheme is less than optimal. Thus we\\n', 'hope to learn an additional set of concepts by letting the\\n', 'data speak for themselves.\\n', 'The remainder of this paper describes the details of our\\n', 'concept discovery efforts and subsequent evaluation. In \\n', 'Section 2 we describe the previously existing, human-created\\n', 'conceptual structure of the BLS website. This section also\\n', 'describes evidence that this structure leaves room for \\n', 'improvement. Next (Sections 3-5), we turn to a description\\n', 'of the concepts derived via content clustering under three\\n', 'document representations: keyword, title only, and full-text.\\n', 'Section 6 describes a two-part evaluation of the derived \\n', 'conceptual structures. Finally, we conclude in Section 7 by \\n', 'outlining upcoming work on the project.\\n', '2. STRUCTURING ACCESS TO THE BLS\\n', 'WEBSITE\\n', 'The Bureau of Labor Statistics is a federal government\\n', 'agency charged with compiling and publishing statistics \\n', 'pertaining to labor and production in the US and abroad. Given\\n', 'this broad mandate, the BLS publishes a wide array of \\n', 'information, intended for diverse audiences. The agency\"s\\n', 'website acts as a clearinghouse for this process. With over\\n', '15,000 text/html documents (and many more documents if\\n', 'spreadsheets and typeset reports are included), providing\\n', 'access to the collection provides a steep challenge to \\n', 'information architects.\\n', '2.1 The Relation Browser\\n', 'The starting point of this work is the notion that access\\n', 'to information in the BLS website could be improved by\\n', 'the addition of a dynamic interface such as the relation\\n', 'browser described by Marchionini and Brunk [13]. The \\n', 'relation browser allows users to traverse complex data sets by\\n', 'iteratively slicing the data along several topics. In Figure\\n', '1 we see a prototype instantiation of the relation browser,\\n', 'applied to the FedStats website3\\n', '.\\n', 'The relation browser supports information seeking by \\n', 'allowing users to form queries in a stepwise fashion, slicing and\\n', 're-slicing the data as their interests dictate. Its motivation\\n', 'is in keeping with Shneiderman\"s suggestion that queries\\n', 'and their results should be tightly coupled [2]. Thus in \\n', 'Fig3\\n', 'http://www.fedstats.gov\\n', 'Figure 1: Relation Browser Prototype\\n', 'ure 1, users might limit their search set to those documents\\n', 'about energy. Within this subset of the collection, they\\n', 'might further eliminate documents published more than a\\n', 'year ago. Finally, they might request to see only documents\\n', 'published in PDF format.\\n', 'As Marchionini and Brunk discuss, capturing the \\n', 'publication date and format of documents is trivial. But successful\\n', 'implementations of the relation browser also rely on topical\\n', 'classification. This presents two stumbling blocks for system\\n', 'designers:\\n', '• Information architects must define the appropriate set\\n', 'of topics for their collection\\n', '• Site maintainers must classify each document into its\\n', 'appropriate categories\\n', 'These tasks parallel common problems in the metadata\\n', 'community: defining appropriate elements and marking up\\n', 'documents to support metadata-aware information access.\\n', 'Given a collection of over 15,000 documents, these \\n', 'hurdles are especially daunting, and automatic methods of \\n', 'approaching them are highly desirable.\\n', '2.2 A Pre-Existing Structure\\n', 'Prior to our involvement with the project, designers at\\n', 'BLS created a shallow classificatory structure for the most\\n', 'important documents in their website. As seen in Figure 2,\\n', 'the BLS home page organizes 65 top-level documents into\\n', '15 categories. These include topics such as Employment and\\n', 'Unemployment, Productivity, and Inflation and Spending.\\n', '152\\n', 'Figure 2: The BLS Home Page\\n', 'We hoped initially that these pre-defined categories could\\n', 'be used to train a 15-way document classifier, thus \\n', 'automating the process of populating the relation browser altogether.\\n', 'However, this approach proved unsatisfactory. In personal\\n', 'meetings, BLS officials voiced dissatisfaction with the \\n', 'existing topics. Their form, it was argued, owed as much to\\n', 'the institutional structure of BLS as it did to the inherent\\n', 'topology of the website\"s information space. In other words,\\n', 'the topics reflected official divisions rather than semantic\\n', 'clusters. The BLS agents suggested that re-designing this\\n', 'classification structure would be desirable.\\n', 'The agents\" misgivings were borne out in subsequent \\n', 'analysis. The BLS topics comprise a shallow classificatory \\n', 'structure; each of the 15 top-level categories is linked to a small\\n', 'number of related pages. Thus there are 7 pages associated\\n', 'with Inflation. Altogether, the link structure of this \\n', 'classificatory system contains 65 documents; that is, excluding\\n', 'navigational links, there are 65 documents linked from the\\n', 'BLS home page, where each hyperlink connects a document\\n', 'to a topic (pages can be linked to multiple topics). Based on\\n', 'this hyperlink structure, we defined M, a symmetric 65×65\\n', 'matrix, where mij counts the number of topics in which \\n', 'documents i and j are both classified on the BLS home page. To\\n', 'analyze the redundancy inherent in the pre-existing \\n', 'structure, we derived the principal components of M (cf. [11]).\\n', 'Figure 3 shows the resultant scree plot4\\n', '.\\n', 'Because all 65 documents belong to at least one BLS topic,\\n', '4\\n', 'A scree plot shows the magnitude of the kth\\n', 'eigenvalue\\n', 'versus its rank. During principal component analysis scree\\n', 'plots visualize the amount of variance captured by each \\n', 'component.\\n', 'm00M0M\\n', '0\\n', '1010M10M\\n', '10\\n', '2020M20M\\n', '20\\n', '3030M30M\\n', '30\\n', '4040M40M\\n', '40\\n', '5050M50M\\n', '50\\n', '6060M60M\\n', '60\\n', 'm00M0M\\n', '0\\n', '22M2M\\n', '2\\n', '44M4M\\n', '4\\n', '66M6M\\n', '6\\n', '88M8M\\n', '8\\n', '1010M10M\\n', '10\\n', '1212M12M\\n', '12\\n', '1414M14M\\n', '14\\n', 'Eigenvalue RankMEigenvalue RankM\\n', 'Eigenvalue Rank\\n', 'Eigenvlue MagnitudeMEigenvlue MagnitudeM\\n', 'EigenvlueMagnitude\\n', 'Figure 3: Scree Plot of BLS Categories\\n', 'the rank of M is guaranteed to be less than or equal to\\n', '15 (hence, eigenvalues 16 . . . 65 = 0). What is surprising\\n', 'about Figure 3, however, is the precipitous decline in \\n', 'magnitude among the first four eigenvalues. The four largest\\n', 'eigenvlaues account for 62.2% of the total variance in the\\n', 'data. This fact suggests a high degree of redundancy among\\n', 'the topics. Topical redundancy is not in itself problematic.\\n', 'However, the documents in this very shallow classificatory\\n', 'structure are almost all gateways to more specific \\n', 'information. Thus the listing of the Producer Price Index under\\n', 'three categories could be confusing to the site\"s users. In\\n', 'light of this potential for confusion and the agency\"s own \\n', 'request for redesign, we undertook the task of topic discovery\\n', 'described in the following sections.\\n', '3. A HYBRID APPROACH TO TOPIC\\n', 'DISCOVERY\\n', 'To aid in the discovery of a new set of high-level topics for\\n', 'the BLS website, we turned to unsupervised machine \\n', 'learning methods. In efforts to let the data speak for themselves,\\n', 'we desired a means of concept discovery that would be based\\n', 'not on the structure of the agency, but on the content of the\\n', 'material. To begin this process, we crawled the BLS \\n', 'website, downloading all documents of MIME type text/html.\\n', 'This led to a corpus of 15,165 documents. Based on this\\n', 'corpus, we hoped to derive k ≈ 10 topical categories, such\\n', 'that each document di is assigned to one or more classes.\\n', '153\\n', 'Document clustering (cf. [16]) provided an obvious, but\\n', 'only partial solution to the problem of automating this type\\n', 'of high-level information architecture discovery. The \\n', 'problems with standard clustering are threefold.\\n', '1. Mutually exclusive clusters are inappropriate for \\n', 'identifying the topical content of documents, since \\n', 'documents may be about many subjects.\\n', '2. Due to the heterogeneity of the data housed in the\\n', 'BLS collection (tables, lists, surveys, etc.), many \\n', 'documents\" terms provide noisy topical information.\\n', '3. For application to the relation browser, we require a\\n', 'small number (k ≈ 10) of topics. Without significant\\n', 'data reduction, term-based clustering tends to deliver\\n', 'clusters at too fine a level of granularity.\\n', 'In light of these problems, we take a hybrid approach to\\n', 'topic discovery. First, we limit the clustering process to\\n', 'a sample of the entire collection, described in Section 4.\\n', 'Working on a focused subset of the data helps to overcome\\n', 'problems two and three, listed above. To address the \\n', 'problem of mutual exclusivity, we combine unsupervised with\\n', 'supervised learning methods, as described in Section 5.\\n', '4. FOCUSING ON CONTENT-RICH\\n', 'DOCUMENTS\\n', 'To derive empirically evidenced topics we initially turned\\n', 'to cluster analysis. Let A be the n×p data matrix with n \\n', 'observations in p variables. Thus aij shows the measurement\\n', 'for the ith\\n', 'observation on the jth\\n', 'variable. As described\\n', 'in [12], the goal of cluster analysis is to assign each of the\\n', 'n observations to one of a small number k groups, each of\\n', 'which is characterized by high intra-cluster correlation and\\n', 'low inter-cluster correlation. Though the algorithms for \\n', 'accomplishing such an arrangement are legion, our analysis\\n', 'focuses on k-means clustering5\\n', ', during which, each \\n', 'observation oi is assigned to the cluster Ck whose centroid is closest\\n', 'to it, in terms of Euclidean distance. Readers interested in\\n', 'the details of the algorithm are referred to [12] for a \\n', 'thorough treatment of the subject.\\n', 'Clustering by k-means is well-studied in the statistical\\n', 'literature, and has shown good results for text analysis (cf.\\n', '[8, 16]). However, k-means clustering requires that the \\n', 'researcher specify k, the number of clusters to define. When\\n', 'applying k-means to our 15,000 document collection, \\n', 'indicators such as the gap statistic [17] and an analysis of\\n', 'the mean-squared distance across values of k suggested that\\n', 'k ≈ 80 was optimal. This paramterization led to \\n', 'semantically intelligible clusters. However, 80 clusters are far too\\n', 'many for application to an interface such as the relation\\n', '5\\n', 'We have focused on k-means as opposed to other clustering\\n', 'algorithms for several reasons. Chief among these is the\\n', 'computational efficiency enjoyed by the k-means approach.\\n', 'Because we need only a flat clustering there is little to be\\n', 'gained by the more expensive hierarchical algorithms. In\\n', 'future work we will turn to model-based clustering [7] as a\\n', 'more principled method of selecting the number of clusters\\n', 'and of representing clusters.\\n', 'browser. Moreover, the granularity of these clusters was \\n', 'unsuitably fine. For instance, the 80-cluster solution derived\\n', 'a cluster whose most highly associated words (in terms of\\n', 'log-odds ratio [1]) were drug, pharmacy, and chemist. These\\n', 'words are certainly related, but they are related at a level\\n', 'of specificity far below what we sought.\\n', 'To remedy the high dimensionality of the data, we \\n', 'resolved to limit the algorithm to a subset of the collection.\\n', 'In consultation with employees of the BLS, we continued\\n', 'our analysis on documents that form a series titled From\\n', 'the Editor\"s Desk6\\n', '. These are brief articles, written by BLS\\n', 'employees. BLS agents suggested that we focus on the \\n', 'Editor\"s Desk because it is intended to span the intellectual\\n', 'domain of the agency. The column is published daily, and\\n', 'each entry describes an important current issue in the BLS\\n', 'domain. The Editor\"s Desk column has been written daily\\n', '(five times per week) since 1998. As such, we operated on a\\n', 'set of N = 1279 documents.\\n', 'Limiting attention to these 1279 documents not only \\n', 'reduced the dimensionality of the problem. It also allowed\\n', 'the clustering process to learn on a relatively clean data set.\\n', 'While the entire BLS collection contains a great deal of \\n', 'nonprose text (i.e. tables, lists, etc.), the Editor\"s Desk \\n', 'documents are all written in clear, journalistic prose. Each \\n', 'document is highly topical, further aiding the discovery of \\n', 'termtopic relations. Finally, the Editor\"s Desk column provided\\n', 'an ideal learning environment because it is well-supplied\\n', 'with topical metadata. Each of the 1279 documents \\n', 'contains a list of one or more keywords. Additionally, a subset\\n', 'of the documents (1112) contained a subject heading. This\\n', 'metadata informed our learning and evaluation, as described\\n', 'in Section 6.1.\\n', '5. COMBINING SUPERVISED AND\\n', 'UNSUPERVISED LEARNING FORTOPIC\\n', 'DISCOVERY\\n', 'To derive suitably general topics for the application of a\\n', 'dynamic interface to the BLS collection, we combined \\n', 'document clustering with text classification techniques. \\n', 'Specifically, using k-means, we clustered each of the 1279 \\n', 'documents into one of k clusters, with the number of clusters\\n', 'chosen by analyzing the within-cluster mean squared \\n', 'distance at different values of k (see Section 6.1). \\n', 'Constructing mutually exclusive clusters violates our assumption that\\n', 'documents may belong to multiple classes. However, these\\n', 'clusters mark only the first step in a two-phase process of\\n', 'topic identification. At the end of the process, \\n', 'documentcluster affinity is measured by a real-valued number.\\n', 'Once the Editor\"s Desk documents were assigned to \\n', 'clusters, we constructed a k-way classifier that estimates the\\n', 'strength of evidence that a new document di is a member\\n', 'of class Ck. We tested three statistical classification \\n', 'techniques: probabilistic Rocchio (prind), naive Bayes, and \\n', 'support vector machines (SVMs). All were implemented using\\n', 'McCallum\"s BOW text classification library [14]. Prind is a\\n', 'probabilistic version of the Rocchio classification algorithm\\n', '[9]. Interested readers are referred to Joachims\" article for\\n', '6\\n', 'http://www.bls.gov/opub/ted\\n', '154\\n', 'further details of the classification method. Like prind, naive\\n', 'Bayes attempts to classify documents into the most \\n', 'probable class. It is described in detail in [15]. Finally, support\\n', 'vector machines were thoroughly explicated by Vapnik [18],\\n', 'and applied specifically to text in [10]. They define a \\n', 'decision boundary by finding the maximally separating \\n', 'hyperplane in a high-dimensional vector space in which document\\n', 'classes become linearly separable.\\n', 'Having clustered the documents and trained a suitable\\n', 'classifier, the remaining 14,000 documents in the collection\\n', 'are labeled by means of automatic classification. That is, for\\n', 'each document di we derive a k-dimensional vector, \\n', 'quantifying the association between di and each class C1 . . . Ck.\\n', 'Deriving topic scores via naive Bayes for the entire \\n', '15,000document collection required less than two hours of CPU\\n', 'time. The output of this process is a score for every \\n', 'document in the collection on each of the automatically \\n', 'discovered topics. These scores may then be used to populate a\\n', 'relation browser interface, or they may be added to a \\n', 'traditional information retrieval system. To use these weights in\\n', 'the relation browser we currently assign to each document\\n', 'the two topics on which it scored highest. In future work we\\n', 'will adopt a more rigorous method of deriving \\n', 'documenttopic weight thresholds. Also, evaluation of the utility of\\n', 'the learned topics for users will be undertaken.\\n', '6. EVALUATION OF CONCEPT\\n', 'DISCOVERY\\n', 'Prior to implementing a relation browser interface and\\n', 'undertaking the attendant user studies, it is of course \\n', 'important to evaluate the quality of the inferred concepts, and\\n', 'the ability of the automatic classifier to assign documents\\n', 'to the appropriate subjects. To evaluate the success of the\\n', 'two-stage approach described in Section 5, we undertook\\n', 'two experiments. During the first experiment we compared\\n', 'three methods of document representation for the \\n', 'clustering task. The goal here was to compare the quality of \\n', 'document clusters derived by analysis of full-text documents,\\n', 'documents represented only by their titles, and documents\\n', 'represented by human-created keyword metadata. During\\n', 'the second experiment, we analyzed the ability of the \\n', 'statistical classifiers to discern the subject matter of documents\\n', 'from portions of the database in addition to the Editor\"s\\n', 'Desk.\\n', '6.1 Comparing Document Representations\\n', 'Documents from The Editor\"s Desk column came \\n', 'supplied with human-generated keyword metadata. \\n', 'Additionally, The titles of the Editor\"s Desk documents tend to be\\n', 'germane to the topic of their respective articles. With such\\n', 'an array of distilled evidence of each document\"s subject\\n', 'matter, we undertook a comparison of document \\n', 'representations for topic discovery by clustering. We hypothesized\\n', 'that keyword-based clustering would provide a useful model.\\n', 'But we hoped to see whether comparable performance could\\n', 'be attained by methods that did not require extensive \\n', 'human indexing, such as the title-only or full-text \\n', 'representations. To test this hypothesis, we defined three modes of\\n', 'document representation-full-text, title-only, and keyword\\n', 'only-we generated three sets of topics, Tfull, Ttitle, and\\n', 'Tkw, respectively.\\n', 'Topics based on full-text documents were derived by \\n', 'application of k-means clustering to the 1279 Editor\"s Desk \\n', 'documents, where each document was represented by a \\n', '1908dimensional vector. These 1908 dimensions captured the\\n', 'TF.IDF weights [3] of each term ti in document dj, for all\\n', 'terms that occurred at least three times in the data. To \\n', 'arrive at the appropriate number of clusters for these data, we\\n', 'inspected the within-cluster mean-squared distance for each\\n', 'value of k = 1 . . . 20. As k approached 10 the reduction in\\n', 'error with the addition of more clusters declined notably,\\n', 'suggesting that k ≈ 10 would yield good divisions. To \\n', 'select a single integer value, we calculated which value of k led\\n', 'to the least variation in cluster size. This metric stemmed\\n', 'from a desire to suppress the common result where one large\\n', 'cluster emerges from the k-means algorithm, accompanied\\n', 'by several accordingly small clusters. Without reason to\\n', 'believe that any single topic should have dramatically high\\n', 'prior odds of document membership, this heuristic led to\\n', 'kfull = 10.\\n', 'Clusters based on document titles were constructed \\n', 'similarly. However, in this case, each document was represented\\n', 'in the vector space spanned by the 397 terms that occur\\n', 'at least twice in document titles. Using the same method\\n', 'of minimizing the variance in cluster membership ktitle-the\\n', 'number of clusters in the title-based representation-was also\\n', 'set to 10.\\n', 'The dimensionality of the keyword-based clustering was\\n', 'very similar to that of the title-based approach. There were\\n', '299 keywords in the data, all of which were retained. The\\n', 'median number of keywords per document was 7, where a\\n', 'keyword is understood to be either a single word, or a \\n', 'multiword term such as consumer price index. It is worth noting\\n', 'that the keywords were not drawn from any controlled \\n', 'vocabulary; they were assigned to documents by publishers at\\n', 'the BLS. Using the keywords, the documents were clustered\\n', 'into 10 classes.\\n', 'To evaluate the clusters derived by each method of \\n', 'document representation, we used the subject headings that were\\n', 'included with 1112 of the Editor\"s Desk documents. Each\\n', 'of these 1112 documents was assigned one or more subject\\n', 'headings, which were withheld from all of the cluster \\n', 'applications. Like the keywords, subject headings were assigned\\n', 'to documents by BLS publishers. Unlike the keywords, \\n', 'however, subject headings were drawn from a controlled \\n', 'vocabulary. Our analysis began with the assumption that \\n', 'documents with the same subject headings should cluster \\n', 'together. To facilitate this analysis, we took a conservative\\n', 'approach; we considered multi-subject classifications to be\\n', 'unique. Thus if document di was assigned to a single \\n', 'subject prices, while document dj was assigned to two subjects,\\n', 'international comparisons, prices, documents di and dj are\\n', 'not considered to come from the same class.\\n', 'Table 1 shows all Editor\"s Desk subject headings that were\\n', 'assigned to at least 10 documents. As noted in the table,\\n', '155\\n', 'Table 1: Top Editor\"s Desk Subject Headings\\n', 'Subject Count\\n', 'prices 92\\n', 'unemployment 55\\n', 'occupational safety & health 53\\n', 'international comparisons, prices 48\\n', 'manufacturing, prices 45\\n', 'employment 44\\n', 'productivity 40\\n', 'consumer expenditures 36\\n', 'earnings & wages 27\\n', 'employment & unemployment 27\\n', 'compensation costs 25\\n', 'earnings & wages, metro. areas 18\\n', 'benefits, compensation costs 18\\n', 'earnings & wages, occupations 17\\n', 'employment, occupations 14\\n', 'benefits 14\\n', 'earnings & wage, regions 13\\n', 'work stoppages 12\\n', 'earnings & wages, industries 11\\n', 'Total 609\\n', 'Table 2: Contingecy Table for Three Document\\n', 'Representations\\n', 'Representation Right Wrong Accuracy\\n', 'Full-text 392 217 0.64\\n', 'Title 441 168 0.72\\n', 'Keyword 601 8 0.98\\n', 'there were 19 such subject headings, which altogether \\n', 'covered 609 (54%) of the documents with subjects assigned.\\n', 'These document-subject pairings formed the basis of our\\n', 'analysis. Limiting analysis to subjects with N > 10 kept\\n', 'the resultant χ2\\n', 'tests suitably robust.\\n', 'The clustering derived by each document representation\\n', 'was tested by its ability to collocate documents with the\\n', 'same subjects. Thus for each of the 19 subject headings\\n', 'in Table 1, Si, we calculated the proportion of documents\\n', 'assigned to Si that each clustering co-classified. Further,\\n', 'we assumed that whichever cluster captured the majority of\\n', 'documents for a given class constituted the right answer\\n', 'for that class. For instance, There were 92 documents whose\\n', 'subject heading was prices. Taking the BLS editors\" \\n', 'classifications as ground truth, all 92 of these documents should\\n', 'have ended up in the same cluster. Under the full-text \\n', 'representation 52 of these documents were clustered into category\\n', '5, while 35 were in category 3, and 5 documents were in \\n', 'category 6. Taking the majority cluster as the putative right\\n', 'home for these documents, we consider the accuracy of this\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Machine Learning for Information Architecture in a Large Governmental Website ∗'}, {'doc_id': 'H-97', 'full_text': ['Feature Representation for Effective Action-Item Detection Paul N. Bennett', 'E-mail users face an ever-growing challenge in managing their \\n', 'inboxes due to the growing centrality of email in the workplace for\\n', 'task assignment, action requests, and other roles beyond \\n', 'information dissemination. Whereas Information Retrieval and Machine\\n', 'Learning techniques are gaining initial acceptance in spam filtering\\n', 'and automated folder assignment, this paper reports on a new task:\\n', 'automated action-item detection, in order to flag emails that require\\n', 'responses, and to highlight the specific passage(s) indicating the \\n', 'request(s) for action. Unlike standard topic-driven text classification,\\n', 'action-item detection requires inferring the sender\"s intent, and as\\n', 'such responds less well to pure bag-of-words classification. \\n', 'However, using enriched feature sets, such as n-grams (up to n=4) with\\n', 'chi-squared feature selection, and contextual cues for action-item\\n', 'location improve performance by up to 10% over unigrams, using\\n', 'in both cases state of the art classifiers such as SVMs with \\n', 'automated model selection via embedded cross-validation.\\n', 'E-mail users are facing an increasingly difficult task of \\n', 'managing their inboxes in the face of mounting challenges that result from\\n', 'rising e-mail usage. This includes prioritizing e-mails over a range\\n', 'of sources from business partners to family members, filtering and\\n', 'reducing junk e-mail, and quickly managing requests that demand\\n', 'From: Henry Hutchins <hhutchins@innovative.company.com>\\n', 'To: Sara Smith; Joe Johnson; William Woolings\\n', 'Subject: meeting with prospective customers\\n', 'Sent: Fri 12/10/2005 8:08 AM\\n', 'Hi All,\\n', 'I\"d like to remind all of you that the group from GRTY will be visiting us\\n', 'next Friday at 4:30 p.m. The current schedule looks like this:\\n', '+ 9:30 a.m. Informal Breakfast and Discussion in Cafeteria\\n', '+ 10:30 a.m. Company Overview\\n', '+ 11:00 a.m. Individual Meetings (Continue Over Lunch)\\n', '+ 2:00 p.m. Tour of Facilities\\n', '+ 3:00 p.m. Sales Pitch\\n', 'In order to have this go off smoothly, I would like to practice the \\n', 'presentation well in advance. As a result, I will need each of your parts by\\n', 'Wednesday.\\n', 'Keep up the good work!\\n', '-Henry\\n', 'Figure 1: An E-mail with emphasized Action-Item, an explicit\\n', 'request that requires the recipient\"s attention or action.\\n', 'the receiver\"s attention or action. Automated action-item detection\\n', 'targets the third of these problems by attempting to detect which\\n', 'e-mails require an action or response with information, and within\\n', 'those e-mails, attempting to highlight the sentence (or other \\n', 'passage length) that directly indicates the action request.\\n', 'Such a detection system can be used as one part of an e-mail\\n', 'agent which would assist a user in processing important e-mails\\n', 'quicker than would have been possible without the agent. We view\\n', 'action-item detection as one necessary component of a successful\\n', 'e-mail agent which would perform spam detection, action-item \\n', 'detection, topic classification and priority ranking, among other \\n', 'functions. The utility of such a detector can manifest as a method of\\n', 'prioritizing e-mails according to task-oriented criteria other than\\n', 'the standard ones of topic and sender or as a means of ensuring that\\n', 'the email user hasn\"t dropped the proverbial ball by forgetting to\\n', 'address an action request.\\n', 'Action-item detection differs from standard text classification in\\n', 'two important ways. First, the user is interested both in \\n', 'detecting whether an email contains action items and in locating exactly\\n', 'where these action item requests are contained within the email\\n', 'body. In contrast, standard text categorization merely assigns a\\n', 'topic label to each text, whether that label corresponds to an e-mail\\n', 'folder or a controlled indexing vocabulary [12, 15, 22]. Second,\\n', 'action-item detection attempts to recover the email sender\"s intent\\n', '- whether she means to elicit response or action on the part of the\\n', 'receiver; note that for this task, classifiers using only unigrams as\\n', 'features do not perform optimally, as evidenced in our results \\n', 'below. Instead we find that we need more information-laden features\\n', 'such as higher-order n-grams. Text categorization by topic, on the\\n', 'other hand, works very well using just individual words as features\\n', '[2, 9, 13, 17]. In fact, genre-classification, which one would think\\n', 'may require more than a bag-of-words approach, also works quite\\n', 'well using just unigram features [14]. Topic detection and \\n', 'tracking (TDT), also works well with unigram feature sets [1, 20]. We\\n', 'believe that action-item detection is one of the first clear instances\\n', 'of an IR-related task where we must move beyond bag-of-words\\n', 'to achieve high performance, albeit not too far, as bag-of-n-grams\\n', 'seem to suffice.\\n', 'We first review related work for similar text classification \\n', 'problems such as e-mail priority ranking and speech act identification.\\n', 'Then we more formally define the action-item detection problem,\\n', 'discuss the aspects that distinguish it from more common problems\\n', 'like topic classification, and highlight the challenges in \\n', 'constructing systems that can perform well at the sentence and document\\n', 'level. From there, we move to a discussion of feature \\n', 'representation and selection techniques appropriate for this problem and how\\n', 'standard text classification approaches can be adapted to smoothly\\n', 'move from the sentence-level detection problem to the \\n', 'documentlevel classification problem. We then conduct an empirical analysis\\n', 'that helps us determine the effectiveness of our feature extraction\\n', 'procedures as well as establish baselines for a number of \\n', 'classification algorithms on this task. Finally, we summarize this paper\"s\\n', 'contributions and consider interesting directions for future work.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Feature Representation for Effective Action-Item Detection Paul N. Bennett'}, {'doc_id': 'I-68', 'full_text': ['On Opportunistic Techniques for Solving Decentralized Markov Decision Processes with Temporal Constraints', 'Decentralized Markov Decision Processes (DEC-MDPs) are a \\n', 'popular model of agent-coordination problems in domains with \\n', 'uncertainty and time constraints but very difficult to solve. In this\\n', 'paper, we improve a state-of-the-art heuristic solution method for\\n', 'DEC-MDPs, called OC-DEC-MDP, that has recently been shown\\n', 'to scale up to larger DEC-MDPs. Our heuristic solution method,\\n', 'called Value Function Propagation (VFP), combines two \\n', 'orthogonal improvements of OC-DEC-MDP. First, it speeds up \\n', 'OC-DECMDP by an order of magnitude by maintaining and manipulating\\n', 'a value function for each state (as a function of time) rather than a\\n', 'separate value for each pair of sate and time interval. Furthermore,\\n', 'it achieves better solution qualities than OC-DEC-MDP because,\\n', 'as our analytical results show, it does not overestimate the expected\\n', 'total reward like OC-DEC- MDP. We test both improvements \\n', 'independently in a crisis-management domain as well as for other\\n', 'types of domains. Our experimental results demonstrate a \\n', 'significant speedup of VFP over OC-DEC-MDP as well as higher solution\\n', 'qualities in a variety of situations.\\n', 'The development of algorithms for effective coordination of \\n', 'multiple agents acting as a team in uncertain and time critical domains\\n', 'has recently become a very active research field with potential \\n', 'applications ranging from coordination of agents during a hostage \\n', 'rescue mission [11] to the coordination of Autonomous Mars \\n', 'Exploration Rovers [2]. Because of the uncertain and dynamic \\n', 'characteristics of such domains, decision-theoretic models have received\\n', 'a lot of attention in recent years, mainly thanks to their \\n', 'expressiveness and the ability to reason about the utility of actions over\\n', 'time.\\n', 'Key decision-theoretic models that have become popular in the \\n', 'literature include Decentralized Markov Decision Processes \\n', '(DECMDPs) and Decentralized, Partially Observable Markov Decision\\n', 'Processes (DEC-POMDPs). Unfortunately, solving these models\\n', 'optimally has been proven to be NEXP-complete [3], hence more\\n', 'tractable subclasses of these models have been the subject of \\n', 'intensive research. In particular, Network Distributed POMDP [13]\\n', 'which assume that not all the agents interact with each other, \\n', 'Transition Independent DEC-MDP [2] which assume that transition \\n', 'function is decomposable into local transition functions or DEC-MDP\\n', 'with Event Driven Interactions [1] which assume that interactions\\n', 'between agents happen at fixed time points constitute good \\n', 'examples of such subclasses. Although globally optimal algorithms for\\n', 'these subclasses have demonstrated promising results, domains on\\n', 'which these algorithms run are still small and time horizons are\\n', 'limited to only a few time ticks.\\n', 'To remedy that, locally optimal algorithms have been proposed\\n', '[12] [4] [5]. In particular, Opportunity Cost DEC-MDP [4] [5],\\n', 'referred to as OC-DEC-MDP, is particularly notable, as it has been\\n', 'shown to scale up to domains with hundreds of tasks and double\\n', 'digit time horizons. Additionally, OC-DEC-MDP is unique in its\\n', 'ability to address both temporal constraints and uncertain method\\n', 'execution durations, which is an important factor for real-world \\n', 'domains. OC-DEC-MDP is able to scale up to such domains mainly\\n', 'because instead of searching for the globally optimal solution, it\\n', 'carries out a series of policy iterations; in each iteration it performs\\n', 'a value iteration that reuses the data computed during the previous\\n', 'policy iteration. However, OC-DEC-MDP is still slow, especially\\n', 'as the time horizon and the number of methods approach large \\n', 'values. The reason for high runtimes of OC-DEC-MDP for such \\n', 'domains is a consequence of its huge state space, i.e., OC-DEC-MDP\\n', 'introduces a separate state for each possible pair of method and\\n', 'method execution interval. Furthermore, OC-DEC-MDP \\n', 'overestimates the reward that a method expects to receive for enabling\\n', 'the execution of future methods. This reward, also referred to as\\n', 'the opportunity cost, plays a crucial role in agent decision making,\\n', 'and as we show later, its overestimation leads to highly suboptimal\\n', 'policies.\\n', 'In this context, we present VFP (= Value Function P ropagation),\\n', 'an efficient solution technique for the DEC-MDP model with \\n', 'temporal constraints and uncertain method execution durations, that\\n', 'builds on the success of OC-DEC-MDP. VFP introduces our two\\n', 'orthogonal ideas: First, similarly to [7] [9] and [10], we maintain\\n', '830\\n', '978-81-904262-7-5 (RPS) c 2007 IFAAMAS\\n', 'and manipulate a value function over time for each method rather\\n', 'than a separate value for each pair of method and time interval.\\n', 'Such representation allows us to group the time points for which\\n', 'the value function changes at the same rate (= its slope is \\n', 'constant), which results in fast, functional propagation of value \\n', 'functions. Second, we prove (both theoretically and empirically) that\\n', 'OC-DEC- MDP overestimates the opportunity cost, and to remedy\\n', 'that, we introduce a set of heuristics, that correct the opportunity\\n', 'cost overestimation problem.\\n', 'This paper is organized as follows: In section 2 we motivate this\\n', 'research by introducing a civilian rescue domain where a team of\\n', 'fire- brigades must coordinate in order to rescue civilians trapped in\\n', 'a burning building. In section 3 we provide a detailed description of\\n', 'our DEC-MDP model with Temporal Constraints and in section 4\\n', 'we discuss how one could solve the problems encoded in our model\\n', 'using globally optimal and locally optimal solvers. Sections 5 and\\n', '6 discuss the two orthogonal improvements to the state-of-the-art\\n', 'OC-DEC-MDP algorithm that our VFP algorithm implements. \\n', 'Finally, in section 7 we demonstrate empirically the impact of our two\\n', 'orthogonal improvements, i.e., we show that: (i) The new \\n', 'heuristics correct the opportunity cost overestimation problem leading to\\n', 'higher quality policies, and (ii) By allowing for a systematic \\n', 'tradeoff of solution quality for time, the VFP algorithm runs much faster\\n', 'than the OC-DEC-MDP algorithm\\n', '2. MOTIVATING EXAMPLE\\n', 'We are interested in domains where multiple agents must \\n', 'coordinate their plans over time, despite uncertainty in plan execution\\n', 'duration and outcome. One example domain is large-scale disaster,\\n', 'like a fire in a skyscraper. Because there can be hundreds of \\n', 'civilians scattered across numerous floors, multiple rescue teams have\\n', 'to be dispatched, and radio communication channels can quickly\\n', 'get saturated and useless. In particular, small teams of fire-brigades\\n', 'must be sent on separate missions to rescue the civilians trapped in\\n', 'dozens of different locations.\\n', 'Picture a small mission plan from Figure (1), where three \\n', 'firebrigades have been assigned a task to rescue the civilians trapped\\n', 'at site B, accessed from site A (e.g. an office accessed from the\\n', 'floor)1\\n', '. General fire fighting procedures involve both: (i) putting\\n', 'out the flames, and (ii) ventilating the site to let the toxic, high \\n', 'temperature gases escape, with the restriction that ventilation should\\n', 'not be performed too fast in order to prevent the fire from spreading.\\n', 'The team estimates that the civilians have 20 minutes before the fire\\n', 'at site B becomes unbearable, and that the fire at site A has to be\\n', 'put out in order to open the access to site B. As has happened in\\n', 'the past in large scale disasters, communication often breaks down;\\n', 'and hence we assume in this domain that there is no \\n', 'communication between the fire-brigades 1,2 and 3 (denoted as FB1, FB2 and\\n', 'FB3). Consequently, FB2 does not know if it is already safe to \\n', 'ventilate site A, FB1 does not know if it is already safe to enter site A\\n', 'and start fighting fire at site B, etc. We assign the reward 50 for\\n', 'evacuating the civilians from site B, and a smaller reward 20 for\\n', 'the successful ventilation of site A, since the civilians themselves\\n', 'might succeed in breaking out from site B.\\n', 'One can clearly see the dilemma, that FB2 faces: It can only \\n', 'estimate the durations of the Fight fire at site A methods to be \\n', 'executed by FB1 and FB3, and at the same time FB2 knows that time\\n', 'is running out for civilians. If FB2 ventilates site A too early, the\\n', 'fire will spread out of control, whereas if FB2 waits with the \\n', 'ventilation method for too long, fire at site B will become unbearable for\\n', 'the civilians. In general, agents have to perform a sequence of such\\n', '1\\n', 'We explain the EST and LET notation in section 3\\n', 'Figure 1: Civilian rescue domain and a mission plan. Dotted \\n', 'arrows represent implicit precedence constraints within an agent.\\n', 'difficult decisions; in particular, decision process of FB2 involves\\n', 'first choosing when to start ventilating site A, and then \\n', '(depending on the time it took to ventilate site A), choosing when to start\\n', 'evacuating the civilians from site B. Such sequence of decisions\\n', 'constitutes the policy of an agent, and it must be found fast because\\n', 'time is running out.\\n', '3. MODEL DESCRIPTION\\n', 'We encode our decision problems in a model which we refer to as\\n', 'Decentralized MDP with Temporal Constraints 2\\n', '. Each instance of\\n', 'our decision problems can be described as a tuple M, A, C, P, R\\n', 'where M = {mi}\\n', '|M|\\n', 'i=1 is the set of methods, and A = {Ak}\\n', '|A|\\n', 'k=1\\n', 'is the set of agents. Agents cannot communicate during mission\\n', 'execution. Each agent Ak is assigned to a set Mk of methods,\\n', 'such that\\n', 'S|A|\\n', 'k=1 Mk = M and ∀i,j;i=jMi ∩ Mj = ø. Also, each\\n', 'method of agent Ak can be executed only once, and agent Ak can\\n', 'execute only one method at a time. Method execution times are\\n', 'uncertain and P = {pi}\\n', '|M|\\n', 'i=1 is the set of distributions of method\\n', 'execution durations. In particular, pi(t) is the probability that the\\n', 'execution of method mi consumes time t. C is a set of \\n', 'temporal constraints in the system. Methods are partially ordered and\\n', 'each method has fixed time windows inside which it can be \\n', 'executed, i.e., C = C≺ ∪ C[ ] where C≺ is the set of predecessor\\n', 'constraints and C[ ] is the set of time window constraints. For\\n', 'c ∈ C≺, c = mi, mj means that method mi precedes method\\n', 'mj i.e., execution of mj cannot start before mi terminates. In \\n', 'particular, for an agent Ak, all its methods form a chain linked by\\n', 'predecessor constraints. We assume, that the graph G = M, C≺\\n', 'is acyclic, does not have disconnected nodes (the problem cannot\\n', 'be decomposed into independent subproblems), and its source and\\n', 'sink vertices identify the source and sink methods of the system.\\n', 'For c ∈ C[ ], c = mi, EST, LET means that execution of mi\\n', 'can only start after the Earliest Starting Time EST and must \\n', 'finish before the Latest End Time LET; we allow methods to have\\n', 'multiple disjoint time window constraints. Although distributions\\n', 'pi can extend to infinite time horizons, given the time window \\n', 'constraints, the planning horizon Δ = max m,τ,τ ∈C[ ] τ is \\n', 'considered as the mission deadline. Finally, R = {ri}\\n', '|M|\\n', 'i=1 is the set of\\n', 'non-negative rewards, i.e., ri is obtained upon successful \\n', 'execution of mi.\\n', 'Since there is no communication allowed, an agent can only \\n', 'estimate the probabilities that its methods have already been enabled\\n', '2\\n', 'One could also use the OC-DEC-MDP framework, which models\\n', 'both time and resource constraints\\n', 'The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 831\\n', 'by other agents. Consequently, if mj ∈ Mk is the next method\\n', 'to be executed by the agent Ak and the current time is t ∈ [0, Δ],\\n', 'the agent has to make a decision whether to Execute the method\\n', 'mj (denoted as E), or to Wait (denoted as W). In case agent Ak\\n', 'decides to wait, it remains idle for an arbitrary small time , and \\n', 'resumes operation at the same place (= about to execute method mj)\\n', 'at time t + . In case agent Ak decides to Execute the next method,\\n', 'two outcomes are possible:\\n', 'Success: The agent Ak receives reward rj and moves on to its\\n', 'next method (if such method exists) so long as the following \\n', 'conditions hold: (i) All the methods {mi| mi, mj ∈ C≺} that \\n', 'directly enable method mj have already been completed, (ii) \\n', 'Execution of method mj started in some time window of method mj, i.e.,\\n', '∃ mj ,τ,τ ∈C[ ]\\n', 'such that t ∈ [τ, τ ], and (iii) Execution of method\\n', 'mj finished inside the same time window, i.e., agent Ak completed\\n', 'method mj in time less than or equal to τ − t.\\n', 'Failure: If any of the above-mentioned conditions does not hold,\\n', 'agent Ak stops its execution. Other agents may continue their \\n', 'execution, but methods mk ∈ {m| mj, m ∈ C≺} will never become\\n', 'enabled.\\n', 'The policy πk of an agent Ak is a function πk : Mk × [0, Δ] →\\n', '{W, E}, and πk( m, t ) = a means, that if Ak is at method m\\n', 'at time t, it will choose to perform the action a. A joint policy\\n', 'π = [πk]\\n', '|A|\\n', 'k=1 is considered to be optimal (denoted as π∗\\n', '), if it\\n', 'maximizes the sum of expected rewards for all the agents.\\n', '4. SOLUTION TECHNIQUES\\n', '4.1 Optimal Algorithms\\n', 'Optimal joint policy π∗\\n', 'is usually found by using the Bellman \\n', 'update principle, i.e., in order to determine the optimal policy for\\n', 'method mj, optimal policies for methods mk ∈ {m| mj, m ∈\\n', 'C≺} are used. Unfortunately, for our model, the optimal \\n', 'policy for method mj also depends on policies for methods mi ∈\\n', '{m| m, mj ∈ C≺}. This double dependency results from the\\n', 'fact, that the expected reward for starting the execution of method\\n', 'mj at time t also depends on the probability that method mj will be\\n', 'enabled by time t. Consequently, if time is discretized, one needs to\\n', 'consider Δ|M|\\n', 'candidate policies in order to find π∗\\n', '. Thus, \\n', 'globally optimal algorithms used for solving real-world problems are\\n', 'unlikely to terminate in reasonable time [11]. The complexity of\\n', 'our model could be reduced if we considered its more restricted\\n', 'version; in particular, if each method mj was allowed to be \\n', 'enabled at time points t ∈ Tj ⊂ [0, Δ], the Coverage Set Algorithm\\n', '(CSA) [1] could be used. However, CSA complexity is double \\n', 'exponential in the size of Ti, and for our domains Tj can store all\\n', 'values ranging from 0 to Δ.\\n', '4.2 Locally Optimal Algorithms\\n', 'Following the limited applicability of globally optimal algorithms\\n', 'for DEC-MDPs with Temporal Constraints, locally optimal \\n', 'algorithms appear more promising. Specially, the OC-DEC-MDP \\n', 'algorithm [4] is particularly significant, as it has shown to easily scale\\n', 'up to domains with hundreds of methods. The idea of the \\n', 'OC-DECMDP algorithm is to start with the earliest starting time policy π0\\n', '(according to which an agent will start executing the method m as\\n', 'soon as m has a non-zero chance of being already enabled), and\\n', 'then improve it iteratively, until no further improvement is \\n', 'possible. At each iteration, the algorithm starts with some policy π,\\n', 'which uniquely determines the probabilities Pi,[τ,τ ] that method\\n', 'mi will be performed in the time interval [τ, τ ]. It then performs\\n', 'two steps:\\n', 'Step 1: It propagates from sink methods to source methods the\\n', 'values Vi,[τ,τ ], that represent the expected utility for executing\\n', 'method mi in the time interval [τ, τ ]. This propagation uses the\\n', 'probabilities Pi,[τ,τ ] from previous algorithm iteration. We call\\n', 'this step a value propagation phase.\\n', 'Step 2: Given the values Vi,[τ,τ ] from Step 1, the algorithm chooses\\n', 'the most profitable method execution intervals which are stored in\\n', 'a new policy π . It then propagates the new probabilities Pi,[τ,τ ]\\n', 'from source methods to sink methods. We call this step a \\n', 'probability propagation phase. If policy π does not improve π, the\\n', 'algorithm terminates.\\n', 'There are two shortcomings of the OC-DEC-MDP algorithm that\\n', 'we address in this paper. First, each of OC-DEC-MDP states is a\\n', 'pair mj, [τ, τ ] , where [τ, τ ] is a time interval in which method\\n', 'mj can be executed. While such state representation is beneficial,\\n', 'in that the problem can be solved with a standard value iteration \\n', 'algorithm, it blurs the intuitive mapping from time t to the expected\\n', 'total reward for starting the execution of mj at time t. \\n', 'Consequently, if some method mi enables method mj, and the values\\n', 'Vj,[τ,τ ]∀τ,τ ∈[0,Δ] are known, the operation that calculates the \\n', 'values Vi,[τ,τ ]∀τ, τ ∈ [0, Δ] (during the value propagation phase),\\n', 'runs in time O(I2\\n', '), where I is the number of time intervals 3\\n', '. Since\\n', 'the runtime of the whole algorithm is proportional to the runtime of\\n', 'this operation, especially for big time horizons Δ, the OC- \\n', 'DECMDP algorithm runs slow.\\n', 'Second, while OC-DEC-MDP emphasizes on precise calculation\\n', 'of values Vj,[τ,τ ], it fails to address a critical issue that determines\\n', 'how the values Vj,[τ,τ ] are split given that the method mj has \\n', 'multiple enabling methods. As we show later, OC-DEC-MDP splits\\n', 'Vj,[τ,τ ] into parts that may overestimate Vj,[τ,τ ] when summed up\\n', 'again. As a result, methods that precede the method mj \\n', 'overestimate the value for enabling mj which, as we show later, can have\\n', 'disastrous consequences. In the next two sections, we address both\\n', 'of these shortcomings.\\n', '5. VALUE FUNCTION PROPAGATION (VFP)\\n', 'The general scheme of the VFP algorithm is identical to the \\n', 'OCDEC-MDP algorithm, in that it performs a series of policy \\n', 'improvement iterations, each one involving a Value and Probability\\n', 'Propagation Phase. However, instead of propagating separate \\n', 'values, VFP maintains and propagates the whole functions, we \\n', 'therefore refer to these phases as the value function propagation phase\\n', 'and the probability function propagation phase. To this end, for\\n', 'each method mi ∈ M, we define three new functions:\\n', 'Value Function, denoted as vi(t), that maps time t ∈ [0, Δ] to the\\n', 'expected total reward for starting the execution of method mi at\\n', 'time t.\\n', 'Opportunity Cost Function, denoted as Vi(t), that maps time\\n', 't ∈ [0, Δ] to the expected total reward for starting the execution\\n', 'of method mi at time t assuming that mi is enabled.\\n', 'Probability Function, denoted as Pi(t), that maps time t ∈ [0, Δ]\\n', 'to the probability that method mi will be completed before time\\n', 't.\\n', 'Such functional representation allows us to easily read the current\\n', 'policy, i.e., if an agent Ak is at method mi at time t, then it will\\n', 'wait as long as value function vi(t) will be greater in the future.\\n', 'Formally:\\n', 'πk( mi, t ) =\\n', 'j\\n', 'W if ∃t >t such that vi(t) < vi(t )\\n', 'E otherwise.\\n', 'We now develop an analytical technique for performing the value\\n', 'function and probability function propagation phases.\\n', '3\\n', 'Similarly for the probability propagation phase\\n', '832 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)\\n', '5.1 Value Function Propagation Phase\\n', 'Suppose, that we are performing a value function propagation phase\\n', 'during which the value functions are propagated from the sink \\n', 'methods to the source methods. At any time during this phase we \\n', 'encounter a situation shown in Figure 2, where opportunity cost \\n', 'functions [Vjn ]N\\n', 'n=0 of methods [mjn ]N\\n', 'n=0 are known, and the \\n', 'opportunity cost Vi0 of method mi0 is to be derived. Let pi0 be the\\n', 'probability distribution function of method mi0 execution \\n', 'duration, and ri0 be the immediate reward for starting and \\n', 'completing the execution of method mi0 inside a time interval [τ, τ ] such\\n', 'that mi0 τ, τ ∈ C[ ]. The function Vi0 is then derived from ri0\\n', 'and opportunity costs Vjn,i0 (t) n = 1, ..., N from future methods.\\n', 'Formally:\\n', 'Vi0 (t) =\\n', '8\\n', '>><\\n', '>>:\\n', 'R τ −t\\n', '0\\n', 'pi0 (t )(ri0 +\\n', 'PN\\n', 'n=0 Vjn,i0 (t + t ))dt\\n', 'if ∃ mi0\\n', 'τ,τ ∈C[ ]\\n', 'such that t ∈ [τ, τ ]\\n', '0 otherwise\\n', '(1)\\n', 'Note, that for t ∈ [τ, τ ], if h(t) := ri0 +\\n', 'PN\\n', 'n=0 Vjn,i0 (τ −t) then\\n', 'Vi0 is a convolution of p and h: vi0 (t) = (pi0 ∗h)(τ −t).\\n', 'Assume for now, that Vjn,i0 represents a full opportunity cost, \\n', 'postponing the discussion on different techniques for splitting the \\n', 'opportunity cost Vj0 into [Vj0,ik ]K\\n', 'k=0 until section 6. We now show\\n', 'how to derive Vj0,i0 (derivation of Vjn,i0 for n = 0 follows the\\n', 'same scheme).\\n', 'Figure 2: Fragment of an MDP of agent Ak. Probability \\n', 'functions propagate forward (left to right) whereas value functions\\n', 'propagate backward (right to left).\\n', 'Let V j0,i0 (t) be the opportunity cost of starting the execution of\\n', 'method mj0 at time t given that method mi0 has been completed.\\n', 'It is derived by multiplying Vi0 by the probability functions of all\\n', 'methods other than mi0 that enable mj0 . Formally:\\n', 'V j0,i0 (t) = Vj0 (t) ·\\n', 'KY\\n', 'k=1\\n', 'Pik (t).\\n', 'Where similarly to [4] and [5] we ignored the dependency of [Plk ]K\\n', 'k=1.\\n', 'Observe that V j0,i0 does not have to be monotonically \\n', 'decreasing, i.e., delaying the execution of the method mi0 can sometimes\\n', 'be profitable. Therefore the opportunity cost Vj0,i0 (t) of enabling\\n', 'method mi0 at time t must be greater than or equal to V j0,i0 . \\n', 'Furthermore, Vj0,i0 should be non-increasing. Formally:\\n', 'Vj0,i0 = min\\n', 'f∈F\\n', 'f (2)\\n', 'Where F = {f | f ≥ V j0,i0 and f(t) ≥ f(t ) ∀t<t }.\\n', 'Knowing the opportunity cost Vi0 , we can then easily derive the\\n', 'value function vi0 . Let Ak be an agent assigned to the method mi0 .\\n', 'If Ak is about to start the execution of mi0 it means, that Ak must\\n', 'have completed its part of the mission plan up to the method mi0 .\\n', 'Since Ak does not know if other agents have completed methods\\n', '[mlk ]k=K\\n', 'k=1 , in order to derive vi0 , it has to multiply Vi0 by the \\n', 'probability functions of all methods of other agents that enable mi0 .\\n', 'Formally:\\n', 'vi0 (t) = Vi0 (t) ·\\n', 'KY\\n', 'k=1\\n', 'Plk (t)\\n', 'Where the dependency of [Plk ]K\\n', 'k=1 is also ignored.\\n', 'We have consequently shown a general scheme how to propagate\\n', 'the value functions: Knowing [vjn ]N\\n', 'n=0 and [Vjn ]N\\n', 'n=0 of methods\\n', '[mjn ]N\\n', 'n=0 we can derive vi0 and Vi0 of method mi0 . In general, the\\n', 'value function propagation scheme starts with sink nodes. It then\\n', 'visits at each time a method m, such that all the methods that m\\n', 'enables have already been marked as visited. The value function\\n', 'propagation phase terminates when all the source methods have\\n', 'been marked as visited.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'On Opportunistic Techniques for Solving Decentralized Markov Decision Processes with Temporal Constraints'}, {'doc_id': 'J-36', 'full_text': ['Playing Games in Many Possible Worlds', 'In traditional game theory, players are typically endowed\\n', 'with exogenously given knowledge of the structure of the\\n', 'game-either full omniscient knowledge or partial but fixed\\n', 'information. In real life, however, people are often unaware\\n', 'of the utility of taking a particular action until they perform\\n', 'research into its consequences. In this paper, we model this\\n', 'phenomenon. We imagine a player engaged in a \\n', 'questionand-answer session, asking questions both about his or her\\n', 'own preferences and about the state of reality; thus we call\\n', 'this setting Socratic game theory. In a Socratic game,\\n', 'players begin with an a priori probability distribution over\\n', 'many possible worlds, with a different utility function for\\n', 'each world. Players can make queries, at some cost, to learn\\n', 'partial information about which of the possible worlds is the\\n', 'actual world, before choosing an action. We consider two\\n', 'query models: (1) an unobservable-query model, in which\\n', 'players learn only the response to their own queries, and\\n', '(2) an observable-query model, in which players also learn\\n', 'which queries their opponents made.\\n', 'The results in this paper consider cases in which the \\n', 'underlying worlds of a two-player Socratic game are either\\n', 'constant-sum games or strategically zero-sum games, a class\\n', 'that generalizes constant-sum games to include all games in\\n', 'which the sum of payoffs depends linearly on the interaction\\n', 'between the players. When the underlying worlds are \\n', 'constant sum, we give polynomial-time algorithms to find Nash\\n', 'equilibria in both the observable- and unobservable-query\\n', 'models. When the worlds are strategically zero sum, we give\\n', 'efficient algorithms to find Nash equilibria in \\n', 'unobservablequery Socratic games and correlated equilibria in \\n', 'observablequery Socratic games.\\n', 'Late October 1960. A smoky room. Democratic Party\\n', 'strategists huddle around a map. How should the Kennedy\\n', 'campaign allocate its remaining advertising budget? Should\\n', 'it focus on, say, California or New York? The Nixon \\n', 'campaign faces the same dilemma. Of course, neither campaign\\n', 'knows the effectiveness of its advertising in each state. \\n', 'Perhaps Californians are susceptible to Nixon\"s advertising, but\\n', 'are unresponsive to Kennedy\"s. In light of this uncertainty,\\n', 'the Kennedy campaign may conduct a survey, at some cost,\\n', 'to estimate the effectiveness of its advertising. Moreover, the\\n', 'larger-and more expensive-the survey, the more accurate\\n', 'it will be. Is the cost of a survey worth the information that\\n', 'it provides? How should one balance the cost of acquiring\\n', 'more information against the risk of playing a game with\\n', 'higher uncertainty?\\n', 'In this paper, we model situations of this type as Socratic\\n', 'games. As in traditional game theory, the players in a \\n', 'Socratic game choose actions to maximize their payoffs, but we\\n', 'model players with incomplete information who can make\\n', 'costly queries to reduce their uncertainty about the state of\\n', 'the world before they choose their actions. This approach\\n', 'contrasts with traditional game theory, in which players are\\n', 'usually modeled as having fixed, exogenously given \\n', 'information about the structure of the game and its payoffs. (In\\n', 'traditional games of incomplete and imperfect information,\\n', 'there is information that the players do not have; in Socratic\\n', 'games, unlike in these games, the players have a chance to\\n', 'acquire the missing information, at some cost.) A number of\\n', 'related models have been explored by economists and \\n', 'computer scientists motivated by similar situations, often with\\n', 'a focus on mechanism design and auctions; a sampling of\\n', 'this research includes the work of Larson and Sandholm [41,\\n', '42, 43, 44], Parkes [59], Fong [22], Compte and Jehiel [12],\\n', 'Rezende [63], Persico and Matthews [48, 60], Cr´emer and\\n', 'Khalil [15], Rasmusen [62], and Bergemann and V¨alim¨aki [4,\\n', '5]. The model of Bergemann and V¨alim¨aki is similar in\\n', 'many regards to the one that we explore here; see Section 7\\n', 'for some discussion.\\n', 'A Socratic game proceeds as follows. A real world is \\n', 'cho150\\n', 'sen randomly from a set of possible worlds according to a\\n', 'common prior distribution. Each player then selects an \\n', 'arbitrary query from a set of available costly queries and \\n', 'receives a corresponding piece of information about the real\\n', 'world. Finally each player selects an action and receives a\\n', 'payoff-a function of the players\" selected actions and the\\n', 'identity of the real world-less the cost of the query that\\n', 'he or she made. Compared to traditional game theory, the\\n', 'distinguishing feature of our model is the introduction of\\n', 'explicit costs to the players for learning arbitrary partial \\n', 'information about which of the many possible worlds is the\\n', 'real world.\\n', 'Our research was initially inspired by recent results in \\n', 'psychology on decision making, but it soon became clear that\\n', 'Socratic game theory is also a general tool for understanding\\n', 'the exploitation versus exploration tradeoff, well studied\\n', 'in machine learning, in a strategic multiplayer environment.\\n', 'This tension between the risk arising from uncertainty and\\n', 'the cost of acquiring information is ubiquitous in economics,\\n', 'political science, and beyond.\\n', 'Our results. We consider Socratic games under two \\n', 'models: an unobservable-query model where players learn only\\n', 'the response to their own queries and an observable-query\\n', 'model where players also learn which queries their opponents\\n', 'made. We give efficient algorithms to find Nash \\n', 'equilibriai.e., tuples of strategies from which no player has unilateral\\n', 'incentive to deviate-in broad classes of two-player Socratic\\n', 'games in both models. Our first result is an efficient \\n', 'algorithm to find Nash equilibria in unobservable-query \\n', 'Socratic games with constant-sum worlds, in which the sum\\n', 'of the players\" payoffs is independent of their actions. Our\\n', 'techniques also yield Nash equilibria in unobservable-query\\n', 'Socratic games with strategically zero-sum worlds. \\n', 'Strategically zero-sum games generalize constant-sum games by\\n', 'allowing the sum of the players\" payoffs to depend on \\n', 'individual players\" choices of strategy, but not on any interaction\\n', 'of their choices. Our second result is an efficient algorithm\\n', 'to find Nash equilibria in observable-query Socratic games\\n', 'with constant-sum worlds. Finally, we give an efficient \\n', 'algorithm to find correlated equilibria-a weaker but \\n', 'increasingly well-studied solution concept for games [2, 3, 32, 56,\\n', '57]-in observable-query Socratic games with strategically\\n', 'zero-sum worlds.\\n', 'Like all games, Socratic games can be viewed as a \\n', 'special case of extensive-form games, which represent games\\n', 'by trees in which internal nodes represent choices made by\\n', 'chance or by the players, and the leaves represent outcomes\\n', 'that correspond to a vector of payoffs to the players. \\n', 'Algorithmically, the generality of extensive-form games makes\\n', 'them difficult to solve efficiently, and the special cases that\\n', 'are known to be efficiently solvable do not include even \\n', 'simple Socratic games. Every (complete-information) classical\\n', 'game is a trivial Socratic game (with a single possible world\\n', 'and a single trivial query), and efficiently finding Nash \\n', 'equilibria in classical games has been shown to be hard [10, 11,\\n', '13, 16, 17, 27, 54, 55]. Therefore we would not expect to\\n', 'find a straightforward polynomial-time algorithm to \\n', 'compute Nash equilibria in general Socratic games. However, it\\n', 'is well known that Nash equilibria can be found efficiently\\n', 'via an LP for two-player constant-sum games [49, 71] (and\\n', 'strategically zero-sum games [51]). A Socratic game is itself\\n', 'a classical game, so one might hope that these results can\\n', 'be applied to Socratic games with constant-sum (or \\n', 'strategically zero-sum) worlds.\\n', 'We face two major obstacles in extending these \\n', 'classical results to Socratic games. First, a Socratic game with\\n', 'constant-sum worlds is not itself a constant-sum classical\\n', 'game-rather, the resulting classical game is only \\n', 'strategically zero sum. Worse yet, a Socratic game with \\n', 'strategically zero-sum worlds is not itself classically strategically\\n', 'zero sum-indeed, there are no known efficient \\n', 'algorithmic techniques to compute Nash equilibria in the resulting\\n', 'class of classical games. (Exponential-time algorithms like\\n', 'Lemke/Howson, of course, can be used [45].) Thus even\\n', 'when it is easy to find Nash equilibria in each of the worlds\\n', 'of a Socratic game, we require new techniques to solve the\\n', 'Socratic game itself. Second, even when the Socratic game\\n', 'itself is strategically zero sum, the number of possible \\n', 'strategies available to each player is exponential in the natural\\n', 'representation of the game. As a result, the standard linear\\n', 'programs for computing equilibria have an exponential \\n', 'number of variables and an exponential number of constraints.\\n', 'For unobservable-query Socratic games with strategically\\n', 'zero-sum worlds, we address these obstacles by \\n', 'formulating a new LP that uses only polynomially many variables\\n', '(though still an exponential number of constraints) and then\\n', 'use ellipsoid-based techniques to solve it. For \\n', 'observablequery Socratic games, we handle the exponentiality by \\n', 'decomposing the game into stages, solving the stages \\n', 'separately, and showing how to reassemble the solutions \\n', 'efficiently. To solve the stages, it is necessary to find Nash\\n', 'equilibria in Bayesian strategically zero-sum games, and we\\n', 'give an explicit polynomial-time algorithm to do so.\\n', '2. GAMES AND SOCRATIC GAMES\\n', 'In this section, we review background on game theory and\\n', 'formally introduce Socratic games. We present these \\n', 'models in the context of two-player games, but the multiplayer\\n', 'case is a natural extension. Throughout the paper, \\n', 'boldface variables will be used to denote a pair of variables (e.g.,\\n', 'a = ai, aii ). Let Pr[x ← π] denote the probability that a\\n', 'particular value x is drawn from the distribution π, and let\\n', 'Ex∼π[g(x)] denote the expectation of g(x) when x is drawn\\n', 'from π.\\n', '2.1 Background on Game Theory\\n', 'Consider two players, Player I and Player II, each of whom\\n', 'is attempting to maximize his or her utility (or payoff). A\\n', '(two-player) game is a pair A, u , where, for i ∈ {i,ii},\\n', '• Ai is the set of pure strategies for Player i, and A =\\n', 'Ai, Aii ; and\\n', '• ui : A → R is the utility function for Player i, and\\n', 'u = ui, uii .\\n', 'We require that A and u be common knowledge. If each\\n', 'Player i chooses strategy ai ∈ Ai, then the payoffs to \\n', 'Players I and II are ui(a) and uii(a), respectively. A game is \\n', 'constant sum if, for all a ∈ A, we have that ui(a) + uii(a) = c\\n', 'for some fixed c independent of a.\\n', 'Player i can also play a mixed strategy αi ∈ Ai, where Ai\\n', 'denotes the space of probability measures over the set Ai.\\n', 'Payoff functions are generalized as ui (α) = ui (αi, αii) :=\\n', 'Ea∼α[ui (a)] =\\n', 'P\\n', 'a∈A α(a)ui (a), where the quantity α(a) =\\n', '151\\n', 'αi(ai) · αii(aii) denotes the joint probability of the \\n', 'independent events that each Player i chooses action ai from the\\n', 'distribution αi. This generalization to mixed strategies is\\n', 'known as von Neumann/Morgenstern utility [70], in which\\n', 'players are indifferent between a guaranteed payoff x and an\\n', 'expected payoff of x.\\n', 'A Nash equilibrium is a pair α of mixed strategies so that\\n', 'neither player has an incentive to change his or her strategy\\n', 'unilaterally. Formally, the strategy pair α is a Nash \\n', 'equilibrium if and only if both ui(αi, αii) = maxαi∈Ai ui(αi, αii)\\n', 'and uii(αi, αii) = maxαii∈Aii uii(αi, αii); that is, the \\n', 'strategies αi and αii are mutual best responses.\\n', 'A correlated equilibrium is a distribution ψ over A that\\n', 'obeys the following: if a ∈ A is drawn randomly according\\n', 'to ψ and Player i learns ai, then no Player i has incentive to\\n', 'deviate unilaterally from playing ai. (A Nash equilibrium is\\n', 'a correlated equilibrium in which ψ(a) = αi(ai) · αii(aii) is a\\n', 'product distribution.) Formally, in a correlated equilibrium,\\n', 'for every a ∈ A we must have that ai is a best response to\\n', 'a randomly chosen ˆaii ∈ Aii drawn according to ψ(ai, ˆaii),\\n', 'and the analogous condition must hold for Player II.\\n', '2.2 Socratic Games\\n', 'In this section, we formally define Socratic games. A\\n', 'Socratic game is a 7-tuple A, W, u, S, Q, p, δ , where, for\\n', 'i ∈ {i,ii}:\\n', '• Ai is, as before, the set of pure strategies for Player i.\\n', '• W is a set of possible worlds, one of which is the real\\n', 'world wreal.\\n', '• ui = {uw\\n', 'i : A → R | w ∈ W} is a set of payoff functions\\n', 'for Player i, one for each possible world.\\n', '• S is a set of signals.\\n', '• Qi is a set of available queries for Player i. When\\n', 'Player i makes query qi : W → S, he or she receives the\\n', 'signal qi(wreal). When Player i receives signal qi(wreal)\\n', 'in response to query qi, he or she can infer that wreal ∈\\n', '{w : qi(w) = qi(wreal)}, i.e., the set of possible worlds\\n', 'from which query qi cannot distinguish wreal.\\n', '• p : W → [0, 1] is a probability distribution over the\\n', 'possible worlds.\\n', '• δi : Qi → R≥0\\n', 'gives the query cost for each available\\n', 'query for Player i.\\n', 'Initially, the world wreal is chosen according to the \\n', 'probability distribution p, but the identity of wreal remains \\n', 'unknown to the players. That is, it is as if the players are\\n', 'playing the game A, uwreal but do not know wreal. The\\n', 'players make queries q ∈ Q, and Player i receives the signal\\n', 'qi(wreal). We consider both observable queries and \\n', 'unobservable queries. When queries are observable, each player\\n', 'learns which query was made by the other player, and the\\n', 'results of his or her own query-that is, each Player i learns\\n', 'qi, qii, and qi(wreal). For unobservable queries, Player i learns\\n', 'only qi and qi(wreal). After learning the results of the queries,\\n', 'the players select strategies a ∈ A and receive as payoffs\\n', 'u\\n', 'wreal\\n', 'i (a) − δi(qi).\\n', 'In the Socratic game, a pure strategy for Player i consists\\n', 'of a query qi ∈ Qi and a response function mapping any \\n', 'result of the query qi to a strategy ai ∈ Ai to play. A player\"s\\n', 'state of knowledge after a query is a point in R := Q × S\\n', 'or Ri := Qi × S for observable or unobservable queries, \\n', 'respectively. Thus Player i\"s response function maps R or\\n', 'Ri to Ai. Note that the number of pure strategies is \\n', 'exponential, as there are exponentially many response \\n', 'functions. A mixed strategy involves both randomly choosing\\n', 'a query qi ∈ Qi and randomly choosing an action ai ∈ Ai\\n', 'in response to the results of the query. Formally, we will\\n', 'consider a mixed-strategy-function profile f = fquery\\n', ', fresp\\n', 'to have two parts:\\n', '• a function fquery\\n', 'i : Qi → [0, 1], where fquery\\n', 'i (qi) is the\\n', 'probability that Player i makes query qi.\\n', '• a function fresp\\n', 'i that maps R or Ri to a \\n', 'probability distribution over actions. Player i chooses an \\n', 'action ai ∈ Ai according to the probability distribution\\n', 'fresp\\n', 'i (q, qi(w)) for observable queries, and according to\\n', 'fresp\\n', 'i (qi, qi(w)) for unobservable queries. (With \\n', 'unobservable queries, for example, the probability that\\n', 'Player I plays action ai conditioned on making query\\n', 'qi in world w is given by Pr[ai ← fresp\\n', 'i (qi, qi(w))].)\\n', 'Mixed strategies are typically defined as probability \\n', 'distributions over the pure strategies, but here we represent a\\n', 'mixed strategy by a pair fquery\\n', ', fresp\\n', ', which is commonly\\n', 'referred to as a behavioral strategy in the game-theory\\n', 'literature. As in any game with perfect recall, one can \\n', 'easily map a mixture of pure strategies to a behavioral strategy\\n', 'f = fquery\\n', ', fresp\\n', 'that induces the same probability of \\n', 'making a particular query qi or playing a particular action after\\n', 'making a query qi in a particular world. Thus it suffices to\\n', 'consider only this representation of mixed strategies.\\n', 'For a strategy-function profile f for observable queries, the\\n', '(expected) payoff to Player i is given by\\n', 'X\\n', 'q∈Q,w∈W,a∈A\\n', '2\\n', '6\\n', '6\\n', '4\\n', 'fquery\\n', 'i (qi) · fquery\\n', 'ii (qii) · p(w)\\n', '· Pr[ai ← fresp\\n', 'i (q, qi(w))]\\n', '· Pr[aii ← fresp\\n', 'ii (q, qii(w))]\\n', '· (uw\\n', 'i (a) − δi(qi))\\n', '3\\n', '7\\n', '7\\n', '5 .\\n', 'The payoffs for unobservable queries are analogous, with\\n', 'fresp\\n', 'j (qj, qj(w)) in place of fresp\\n', 'j (q, qj(w)).\\n', '3. STRATEGICALLY ZERO-SUM GAMES\\n', 'We can view a Socratic game G with constant-sum worlds\\n', 'as an exponentially large classical game, with pure \\n', 'strategies make query qi and respond according to fi. \\n', 'However, this classical game is not constant sum. The sum of\\n', 'the players\" payoffs varies depending upon their strategies,\\n', 'because different queries incur different costs. However, this\\n', 'game still has significant structure: the sum of payoffs varies\\n', 'only because of varying query costs. Thus the sum of \\n', 'payoffs does depend on players\" choice of strategies, but not on\\n', 'the interaction of their choices-i.e., for fixed functions gi\\n', 'and gii, we have ui(q, f) + uii(q, f) = gi(qi, fi) + gii(qii, fii)\\n', 'for all strategies q, f . Such games are called strategically\\n', 'zero sum and were introduced by Moulin and Vial [51], who\\n', 'describe a notion of strategic equivalence and define \\n', 'strategically zero-sum games as those strategically equivalent to\\n', 'zero-sum games. It is interesting to note that two Socratic\\n', 'games with the same queries and strategically equivalent\\n', 'worlds are not necessarily strategically equivalent.\\n', 'A game A, u is strategically zero sum if there exist labels\\n', '(i, ai) for every Player i and every pure strategy ai ∈ Ai\\n', '152\\n', 'such that, for all mixed-strategy profiles α, we have that the\\n', 'sum of the utilities satisfies\\n', 'ui(α)+uii(α) =\\n', 'X\\n', 'ai∈Ai\\n', 'αi(ai)· (i, ai)+\\n', 'X\\n', 'aii∈Aii\\n', 'αii(aii)· (ii, aii).\\n', 'Note that any constant-sum game is strategically zero sum\\n', 'as well.\\n', 'It is not immediately obvious that one can efficiently \\n', 'decide if a given game is strategically zero sum. For \\n', 'completeness, we give a characterization of classical strategically\\n', 'zero-sum games in terms of the rank of a simple matrix \\n', 'derived from the game\"s payoffs, allowing us to efficiently \\n', 'decide if a given game is strategically zero sum and, if it is, to\\n', 'compute the labels (i, ai).\\n', 'Theorem 3.1. Consider a game G = A, u with Ai =\\n', '{a1\\n', 'i , . . . , ani\\n', 'i }. Let MG\\n', 'be the ni-by-nii matrix whose i, j th\\n', 'entry MG\\n', '(i,j) satisfies log2 MG\\n', '(i,j) = ui(ai\\n', 'i , aj\\n', 'ii) + uii(ai\\n', 'i , aj\\n', 'ii).\\n', 'Then the following are equivalent:\\n', '(i) G is strategically zero sum;\\n', '(ii) there exist labels (i, ai) for every player i ∈ {i,ii} and\\n', 'every pure strategy ai ∈ Ai such that, for all pure\\n', 'strategies a ∈ A, we have ui(a) + uii(a) = (i, ai) +\\n', '(ii, aii); and\\n', '(iii) rank(MG\\n', ') = 1.\\n', 'Proof Sketch. (i ⇒ ii) is immediate; every pure \\n', 'strategy is a trivially mixed strategy. For (ii ⇒ iii), let ci be the\\n', 'n-element column vector with jth component 2 (i,a\\n', 'j\\n', 'i )\\n', '; then\\n', 'ci · cii\\n', 'T\\n', '= MG\\n', '. For (iii ⇒ i), if rank(MG\\n', ') = 1, then MG\\n', '=\\n', 'u · vT\\n', '. We can prove that G is strategically zero sum by\\n', 'choosing labels (i, aj\\n', 'i ) := log2 uj and (ii, aj\\n', 'ii) := log2 vj.\\n', '4. SOCRATIC GAMES WITH\\n', 'UNOBSERVABLE QUERIES\\n', 'We begin with Socratic games with unobservable queries,\\n', 'where a player\"s choice of query is not revealed to her \\n', 'opponent. We give an efficient algorithm to solve \\n', 'unobservablequery Socratic games with strategically zero-sum worlds.\\n', 'Our algorithm is based upon the LP shown in Figure 1,\\n', 'whose feasible points are Nash equilibria for the game. The\\n', 'LP has polynomially many variables but exponentially many\\n', 'constraints. We give an efficient separation oracle for the LP,\\n', 'implying that the ellipsoid method [28, 38] yields an efficient\\n', 'algorithm. This approach extends the techniques of Koller\\n', 'and Megiddo [39] (see also [40]) to solve constant-sum games\\n', 'represented in extensive form. (Recall that their result does\\n', 'not directly apply in our case; even a Socratic game with\\n', 'constant-sum worlds is not a constant-sum classical game.)\\n', 'Lemma 4.1. Let G = A, W, u, S, Q, p, δ be an arbitrary\\n', 'unobservable-query Socratic game with strategically zero-sum\\n', 'worlds. Any feasible point for the LP in Figure 1 can be \\n', 'efficiently mapped to a Nash equilibrium for G, and any Nash\\n', 'equilibrium for G can be mapped to a feasible point for the\\n', 'program.\\n', 'Proof Sketch. We begin with a description of the \\n', 'correspondence between feasible points for the LP and Nash\\n', 'equilibria for G. First, suppose that strategy profile f =\\n', 'fquery\\n', ', fresp\\n', 'forms a Nash equilibrium for G. Then the \\n', 'following setting for the LP variables is feasible:\\n', 'yi\\n', 'qi\\n', '= fquery\\n', 'i (qi)\\n', 'xi\\n', 'ai,qi,w = Pr[ai ← fresp\\n', 'i (qi, qi(w))] · yi\\n', 'qi\\n', 'ρi =\\n', 'P\\n', 'w,q∈Q,a∈A\\n', 'p(w) · xi\\n', 'ai,qi,w · xii\\n', 'aii,qii,w · [uw\\n', 'i (a) − δi(qi)].\\n', '(We omit the straightforward calculations that verify \\n', 'feasibility.) Next, suppose xi\\n', 'ai,qi,w, yi\\n', 'qi\\n', ', ρi is feasible for the LP.\\n', 'Let f be the strategy-function profile defined as\\n', 'fquery\\n', 'i : qi → yi\\n', 'qi\\n', 'fresp\\n', 'i (qi, qi(w)) : ai → xi\\n', 'ai,qi,w/yi\\n', 'qi\\n', '.\\n', 'Verifying that this strategy profile is a Nash equilibrium\\n', 'requires checking that fresp\\n', 'i (qi, qi(w)) is a well-defined \\n', 'function (from constraint VI), that fquery\\n', 'i and fresp\\n', 'i (qi, qi(w)) are\\n', 'probability distributions (from constraints III and IV), and\\n', 'that each player is playing a best response to his or her \\n', 'opponent\"s strategy (from constraints I and II). Finally, from\\n', 'constraints I and II, the expected payoff to Player i is at most\\n', 'ρi. Because the right-hand side of constraint VII is equal\\n', 'to the expected sum of the payoffs from f and is at most\\n', 'ρi + ρii, the payoffs are correct and imply the lemma.\\n', 'We now give an efficient separation oracle for the LP in\\n', 'Figure 1, thus allowing the ellipsoid method to solve the\\n', 'LP in polynomial time. Recall that a separation oracle is\\n', 'a function that, given a setting for the variables in the LP,\\n', 'either returns feasible or returns a particular constraint\\n', 'of the LP that is violated by that setting of the variables.\\n', 'An efficient, correct separation oracle allows us to solve the\\n', 'LP efficiently via the ellipsoid method.\\n', 'Lemma 4.2. There exists a separation oracle for the LP\\n', 'in Figure 1 that is correct and runs in polynomial time.\\n', 'Proof. Here is a description of the separation oracle SP.\\n', 'On input xi\\n', 'ai,qi,w, yi\\n', 'qi\\n', ', ρi :\\n', '1. Check each of the constraints (III), (IV), (V), (VI),\\n', 'and (VII). If any one of these constraints is violated,\\n', 'then return it.\\n', '2. Define the strategy profile f as follows:\\n', 'fquery\\n', 'i : qi → yi\\n', 'qi\\n', 'fresp\\n', 'i (qi, qi(w)) : ai → xi\\n', 'ai,qi,w/yi\\n', 'qi\\n', 'For each query qi, we will compute a pure best-response\\n', 'function ˆf\\n', 'qi\\n', 'i for Player I to strategy fii after making\\n', 'query qi.\\n', 'More specifically, given fii and the result qi(wreal) of the\\n', 'query qi, it is straightforward to compute the \\n', 'probability that, conditioned on the fact that the result of\\n', 'query qi is qi(w), the world is w and Player II will play\\n', 'action aii ∈ Aii. Therefore, for each query qi and \\n', 'response qi(w), Player I can compute the expected utility\\n', 'of each pure response ai to the induced mixed strategy\\n', 'over Aii for Player II. Player I can then select the ai\\n', 'maximizing this expected payoff.\\n', 'Let ˆfi be the response function such that ˆfi(qi, qi(w)) =\\n', 'ˆf\\n', 'qi\\n', 'i (qi(w)) for every qi ∈ Qi. Similarly, compute ˆfii.\\n', '153\\n', 'Player i does not prefer ‘make query qi, then play according to the function fi\" :\\n', '∀qi ∈ Qi, fi : Ri → Ai : ρi ≥\\n', 'P\\n', 'w∈W,aii∈Aii,qii∈Qii,ai=fi(qi,qi(w))\\n', '`\\n', 'p(w) · xii\\n', 'aii,qii,w · [uw\\n', 'i (a) − δi(qi)]\\n', '´\\n', '(I)\\n', '∀qii ∈ Qii, fii : Rii → Aii : ρii ≥\\n', 'P\\n', 'w∈W,ai∈Ai,qi∈Qi,aii=fii(qii,qii(w))\\n', '`\\n', 'p(w) · xi\\n', 'ai,qi,w · [uw\\n', 'ii (a) − δii(qii)]\\n', '´\\n', '(II)\\n', 'Every player\"s choices form a probability distribution in every world:\\n', '∀i ∈ {i,ii}, w ∈ W : 1 =\\n', 'P\\n', 'ai∈Ai,qi∈Qi\\n', 'xi\\n', 'ai,qi,w (III)\\n', '∀i ∈ {i,ii}, w ∈ W : 0 ≤ xi\\n', 'ai,qi,w (IV)\\n', 'Queries are independent of the world, and actions depend only on query output:\\n', '∀i ∈ {i,ii}, qi ∈ Qi, w ∈ W, w ∈ W such that qi(w) = qi(w ) :\\n', 'yi\\n', 'qi\\n', '=\\n', 'P\\n', 'ai∈Ai\\n', 'xi\\n', 'ai,qi,w (V)\\n', 'xi\\n', 'ai,qi,w = xi\\n', 'ai,qi,w (VI)\\n', 'The payoffs are consistent with the labels (i, ai, w):\\n', 'ρi + ρii =\\n', 'P\\n', 'i∈{i,ii}\\n', 'P\\n', 'w∈W,qi∈Qi,ai∈Ai\\n', '`\\n', 'p(w) · xi\\n', 'ai,qi,w · [ (i, ai, w) − δi(qi)]\\n', '´\\n', '(VII)\\n', 'Figure 1: An LP to find Nash equilibria in unobservable-query Socratic games with strategically zero-sum\\n', 'worlds. The input is a Socratic game A, W, u, S, Q, p, δ so that world w is strategically zero sum with labels\\n', '(i, ai, w). Player i makes query qi ∈ Qi with probability yi\\n', 'qi\\n', 'and, when the actual world is w ∈ W, makes query\\n', 'qi and plays action ai with probability xi\\n', 'ai,qi,w. The expected payoff to Player i is given by ρi.\\n', '3. Let ˆρ\\n', 'qi\\n', 'i be the expected payoff to Player I using the\\n', 'strategy make query qi and play response function\\n', 'ˆfi if Player II plays according to fii.\\n', 'Let ˆρi = maxqi∈Qq ˆρ\\n', 'qi\\n', 'i and let ˆqi = arg maxqi∈Qq ˆρ\\n', 'qi\\n', 'i .\\n', 'Similarly, define ˆρ\\n', 'qii\\n', 'ii , ˆρii, and ˆqii.\\n', '4. For the ˆfi and ˆqi defined in Step 3, return constraint\\n', '(I-ˆqi- ˆfi) or (II-ˆqii- ˆfii) if either is violated. If both are\\n', 'satisfied, then return feasible.\\n', 'We first note that the separation oracle runs in polynomial\\n', 'time and then prove its correctness. Steps 1 and 4 are clearly\\n', 'polynomial. For Step 2, we have described how to compute\\n', 'the relevant response functions by examining every action of\\n', 'Player I, every world, every query, and every action of Player\\n', 'II. There are only polynomially many queries, worlds, query\\n', 'results, and pure actions, so the running time of Steps 2 and\\n', '3 is thus polynomial.\\n', 'We now sketch the proof that the separation oracle works\\n', 'correctly. The main challenge is to show that if any \\n', 'constraint (I-qi-fi ) is violated then (I-ˆqi- ˆfi) is violated in Step 4.\\n', 'First, we observe that, by construction, the function ˆfi \\n', 'computed in Step 3 must be a best response to Player II playing\\n', 'fii, no matter what query Player I makes. Therefore the\\n', 'strategy make query ˆqi, then play response function ˆfi\\n', 'must be a best response to Player II playing fii, by definition\\n', 'of ˆqi. The right-hand side of each constraint (I-qi-fi ) is equal\\n', 'to the expected payoff that Player I receives when playing\\n', 'the pure strategy make query qi and then play response\\n', 'function fi  against Player II\"s strategy of fii. Therefore,\\n', 'because the pure strategy make query ˆqi and then play\\n', 'response function ˆfi is a best response to Player II \\n', 'playing fii, the right-hand side of constraint (I-ˆqi- ˆfi) is at least\\n', 'as large as the right hand side of any constraint (I-ˆqi-fi ).\\n', 'Therefore, if any constraint (I-qi-fi ) is violated, constraint\\n', '(I-ˆqi- ˆfi) is also violated. An analogous argument holds for\\n', 'Player II.\\n', 'These lemmas and the well-known fact that Nash \\n', 'equilibria always exist [52] imply the following theorem:\\n', 'Theorem 4.3. Nash equilibria can be found in \\n', 'polynomial time for any two-player unobservable-query Socratic\\n', 'game with strategically zero-sum worlds.\\n', '5. SOCRATIC GAMES WITH\\n', 'OBSERVABLE QUERIES\\n', 'In this section, we give efficient algorithms to find (1) a\\n', 'Nash equilibrium for observable-query Socratic games with\\n', 'constant-sum worlds and (2) a correlated equilibrium in the\\n', 'broader class of Socratic games with strategically zero-sum\\n', 'worlds. Recall that a Socratic game G = A, W, u, S, Q, p, δ\\n', 'with observable queries proceeds in two stages:\\n', 'Stage 1: The players simultaneously choose queries q ∈ Q.\\n', 'Player i receives as output qi, qii, and qi(wreal).\\n', 'Stage 2: The players simultaneously choose strategies a ∈\\n', 'A. The payoff to Player i is u\\n', 'wreal\\n', 'i (a) − δi(qi).\\n', 'Using backward induction, we first solve Stage 2 and then\\n', 'proceed to the Stage-1 game.\\n', 'For a query q ∈ Q, we would like to analyze the Stage-2\\n', 'game ˆGq resulting from the players making queries q in\\n', 'Stage 1. Technically, however, ˆGq is not actually a game,\\n', 'because at the beginning of Stage 2 the players have different\\n', 'information about the world: Player I knows qi(wreal), and\\n', '154\\n', 'Player II knows qii(wreal). Fortunately, the situation in which\\n', 'players have asymmetric private knowledge has been well\\n', 'studied in the game-theory literature. A Bayesian game is\\n', 'a quadruple A, T, r, u , where:\\n', '• Ai is the set of pure strategies for Player i.\\n', '• Ti is the set of types for Player i.\\n', '• r is a probability distribution over T; r(t) denotes the\\n', 'probability that Player i has type ti for all i.\\n', '• ui : A × T → R is the payoff function for Player i.\\n', 'If the players have types t and play pure strategies a,\\n', 'then ui(a, t) denotes the payoff for Player i.\\n', 'Initially, a type t is drawn randomly from T according to the\\n', 'distribution r. Player i learns his type ti, but does not learn\\n', 'any other player\"s type. Player i then plays a mixed strategy\\n', 'αi ∈ Ai-that is, a probability distribution over Ai-and\\n', 'receives payoff ui(α, t). A strategy function is a function\\n', 'hi : Ti → Ai; Player i plays the mixed strategy hi(ti) ∈ Ai\\n', 'when her type is ti. A strategy-function profile h is a\\n', 'Bayesian Nash equilibrium if and only if no Player i has \\n', 'unilateral incentive to deviate from hi if the other players play\\n', 'according to h. For a two-player Bayesian game, if α = h(t),\\n', 'then the profile h is a Bayesian Nash equilibrium exactly\\n', 'when the following condition and its analogue for Player II\\n', 'hold: Et∼r[ui(α, t)] = maxhi\\n', 'Et∼r[ui( hi(ti), αii , t)]. These\\n', 'conditions hold if and only if, for all ti ∈ Ti occurring with\\n', 'positive probability, Player i\"s expected utility conditioned\\n', 'on his type being ti is maximized by hi(ti). A Bayesian\\n', 'game is constant sum if for all a ∈ A and all t ∈ T, we\\n', 'have ui(a, t) + uii(a, t) = ct, for some constant ct \\n', 'independent of a. A Bayesian game is strategically zero sum if the\\n', 'classical game A, u(·, t) is strategically zero sum for every\\n', 't ∈ T. Whether a Bayesian game is strategically zero sum\\n', 'can be determined as in Theorem 3.1. (For further \\n', 'discussion of Bayesian games, see [25, 31].)\\n', 'We now formally define the Stage-2 game as a Bayesian\\n', 'game. Given a Socratic game G = A, W, u, S, Q, p, δ and\\n', 'a query profile q ∈ Q, we define the Stage-2 Bayesian game\\n', 'Gstage2(q) := A, Tq\\n', ', pstage2(q)\\n', ', ustage2(q)\\n', ', where:\\n', '• Ai, the set of pure strategies for Player i, is the same\\n', 'as in the original Socratic game;\\n', '• Tq\\n', 'i = {qi(w) : w ∈ W}, the set of types for Player i, is\\n', 'the set of signals that can result from query qi;\\n', '• pstage2(q)\\n', '(t) = Pr[q(w) = t | w ← p]; and\\n', '• u\\n', 'stage2(q)\\n', 'i (a, t) =\\n', 'P\\n', 'w∈W Pr[w ← p | q(w) = t] · uw\\n', 'i (a).\\n', 'We now define the Stage-1 game in terms of the payoffs\\n', 'for the Stage-2 games. Fix any algorithm alg that finds a\\n', 'Bayesian Nash equilibrium hq,alg\\n', ':= alg(Gstage2(q)) for each\\n', 'Stage-2 game. Define valuealg\\n', 'i (Gstage2(q)) to be the expected\\n', 'payoff received by Player i in the Bayesian game Gstage2(q)\\n', 'if each player plays according to hq,alg\\n', ', that is,\\n', 'valuealg\\n', 'i (Gstage2(q))\\n', ':=\\n', 'P\\n', 'w∈W p(w) · u\\n', 'stage2(q)\\n', 'i (hq,alg\\n', '(q(w)), q(w)).\\n', 'Define the game Galg\\n', 'stage1 := Astage1\\n', ', ustage1(alg)\\n', ', where:\\n', '• Astage1\\n', ':= Q, the set of available queries in the Socratic\\n', 'game; and\\n', '• u\\n', 'stage1(alg)\\n', 'i (q) := valuealg\\n', 'i (Gstage2(q)) − δi(qi).\\n', 'I.e., players choose queries q and receive payoffs \\n', 'corresponding to valuealg\\n', '(Gstage2(q)), less query costs.\\n', 'Lemma 5.1. Consider an observable-query Socratic game\\n', 'G = A, W, u, S, Q, p, δ . Let Gstage2(q) be the Stage-2 games\\n', 'for all q ∈ Q, let alg be an algorithm finding a Bayesian\\n', 'Nash equilibrium in each Gstage2(q), and let Galg\\n', 'stage1 be the\\n', 'Stage-1 game. Let α be a Nash equilibrium for Galg\\n', 'stage1, and\\n', 'let hq,alg\\n', ':= alg(Gstage2(q)) be a Bayesian Nash equilibrium\\n', 'for each Gstage2(q). Then the following strategy profile is a\\n', 'Nash equilibrium for G:\\n', '• In Stage 1, Player i makes query qi with probability\\n', 'αi(qi). (That is, set fquery\\n', '(q) := α(q).)\\n', '• In Stage 2, if q is the query in Stage 1 and qi(wreal)\\n', 'denotes the response to Player i\"s query, then Player i\\n', 'chooses action ai with probability hq,alg\\n', 'i (qi(wreal)). (In\\n', 'other words, set fresp\\n', 'i (q, qi(w)) := hq,alg\\n', 'i (qi(w)).)\\n', 'We now find equilibria in the stage games for Socratic games\\n', 'with constant- or strategically zero-sum worlds. We first\\n', 'show that the stage games are well structured in this setting:\\n', 'Lemma 5.2. Consider an observable-query Socratic game\\n', 'G = A, W, u, S, Q, p, δ with constant-sum worlds. Then\\n', 'the Stage-1 game Galg\\n', 'stage1 is strategically zero sum for every\\n', 'algorithm alg, and every Stage-2 game Gstage2(q) is Bayesian\\n', 'constant sum. If the worlds of G are strategically zero sum,\\n', 'then every Gstage2(q) is Bayesian strategically zero sum.\\n', 'We now show that we can efficiently compute equilibria for\\n', 'these well-structured stage games.\\n', 'Theorem 5.3. There exists a polynomial-time algorithm\\n', 'BNE finding Bayesian Nash equilibria in strategically \\n', 'zerosum Bayesian (and thus classical strategically zero-sum or\\n', 'Bayesian constant-sum) two-player games.\\n', 'Proof Sketch. Let G = A, T, r, u be a strategically\\n', 'zero-sum Bayesian game. Define an unobservable-query \\n', 'Socratic game G∗\\n', 'with one possible world for each t ∈ T, one\\n', 'available zero-cost query qi for each Player i so that qi \\n', 'reveals ti, and all else as in G. Bayesian Nash equilibria in G\\n', 'correspond directly to Nash equilibria in G∗\\n', ', and the worlds\\n', 'of G∗\\n', 'are strategically zero sum. Thus by Theorem 4.3 we\\n', 'can compute Nash equilibria for G∗\\n', ', and thus we can \\n', 'compute Bayesian Nash equilibria for G.\\n', '(LP\"s for zero-sum two-player Bayesian games have been\\n', 'previously developed and studied [61].)\\n', 'Theorem 5.4. We can compute a Nash equilibrium for\\n', 'an arbitrary two-player observable-query Socratic game G =\\n', 'A, W, u, S, Q, p, δ with constant-sum worlds in polynomial\\n', 'time.\\n', 'Proof. Because each world of G is constant sum, Lemma\\n', '5.2 implies that the induced Stage-2 games Gstage2(q) are\\n', 'all Bayesian constant sum. Thus we can use algorithm\\n', 'BNE to compute a Bayesian Nash equilibrium hq,BNE\\n', ':=\\n', 'BNE(Gstage2(q)) for each q ∈ Q, by Theorem 5.3. \\n', 'Furthermore, again by Lemma 5.2, the induced Stage-1 game\\n', 'GBNE\\n', 'stage1 is classical strategically zero sum. Therefore we can\\n', 'again use algorithm BNE to compute a Nash equilibrium\\n', 'α := BNE(GBNE\\n', 'stage1), again by Theorem 5.3. Therefore, by\\n', 'Lemma 5.1, we can assemble α and the hq,BNE\\n', '\"s into a Nash\\n', 'equilibrium for the Socratic game G.\\n', '155\\n', 'We would like to extend our results on observable-query\\n', 'Socratic games to Socratic games with strategically \\n', 'zerosum worlds. While we can still find Nash equilibria in the\\n', 'Stage-2 games, the resulting Stage-1 game is not in \\n', 'general strategically zero sum. Thus, finding Nash equilibria\\n', 'in observable-query Socratic games with strategically \\n', 'zerosum worlds seems to require substantially new techniques.\\n', 'However, our techniques for decomposing observable-query\\n', 'Socratic games do allow us to find correlated equilibria in\\n', 'this case.\\n', 'Lemma 5.5. Consider an observable-query Socratic game\\n', 'G = A, W, u, S, Q, p, δ . Let alg be an arbitrary algorithm\\n', 'that finds a Bayesian Nash equilibrium in each of the derived\\n', 'Stage-2 games Gstage2(q), and let Galg\\n', 'stage1 be the derived \\n', 'Stage1 game. Let φ be a correlated equilibrium for Galg\\n', 'stage1, and let\\n', 'hq,alg\\n', ':= alg(Gstage2(q)) be a Bayesian Nash equilibrium for\\n', 'each Gstage2(q). Then the following distribution over pure\\n', 'strategies is a correlated equilibrium for G:\\n', 'ψ(q, f) := φ(q)\\n', 'Y\\n', 'i∈{i,ii}\\n', 'Y\\n', 's∈S\\n', 'Pr\\n', 'h\\n', 'fi(q, s) ← hq,alg\\n', 'i (s)\\n', 'i\\n', '.\\n', 'Thus to find a correlated equilibrium in an observable-query\\n', 'Socratic game with strategically zero-sum worlds, we need\\n', 'only algorithm BNE from Theorem 5.3 along with an \\n', 'efficient algorithm for finding a correlated equilibrium in a \\n', 'general game. Such an algorithm exists (the definition of \\n', 'correlated equilibria can be directly translated into an LP [3]),\\n', 'and therefore we have the following theorem:\\n', 'Theorem 5.6. We can provide both efficient oracle \\n', 'access and efficient sampling access to a correlated \\n', 'equilibrium for any observable-query two-player Socratic game with\\n', 'strategically zero-sum worlds.\\n', 'Because the support of the correlated equilibrium may be\\n', 'exponentially large, providing oracle and sampling access is\\n', 'the natural way to represent the correlated equilibrium.\\n', 'By Lemma 5.5, we can also compute correlated equilibria\\n', 'in any observable-query Socratic game for which Nash \\n', 'equilibria are computable in the induced Gstage2(q) games (e.g.,\\n', 'when Gstage2(q) is of constant size).\\n', 'Another potentially interesting model of queries in \\n', 'Socratic games is what one might call public queries, in which\\n', 'both the choice and outcome of a player\"s query is \\n', 'observable by all players in the game. (This model might be most\\n', 'appropriate in the presence of corporate espionage or media\\n', 'leaks, or in a setting in which the queries-and thus their\\n', 'results-are done in plain view.) The techniques that we\\n', 'have developed in this section also yield exactly the same\\n', 'results as for observable queries. The proof is actually \\n', 'simpler: with public queries, the players\" payoffs are common\\n', 'knowledge when Stage 2 begins, and thus Stage 2 really is a\\n', 'complete-information game. (There may still be uncertainty\\n', 'about the real world, but all players use the observed \\n', 'signals to infer exactly the same set of possible worlds in which\\n', 'wreal may lie; thus they are playing a complete-information\\n', 'game against each other.) Thus we have the same results\\n', 'as in Theorems 5.4 and 5.6 more simply, by solving Stage 2\\n', 'using a (non-Bayesian) Nash-equilibrium finder and solving\\n', 'Stage 1 as before.\\n', 'Our results for observable queries are weaker than for \\n', 'unobservable: in Socratic games with worlds that are \\n', 'strategically zero sum but not constant sum, we find only a \\n', 'correlated equilibrium in the observable case, whereas we find a\\n', 'Nash equilibrium in the unobservable case. We might hope\\n', 'to extend our unobservable-query techniques to observable\\n', 'queries, but there is no obvious way to do so. The \\n', 'fundamental obstacle is that the LP\"s payoff constraint becomes\\n', 'nonlinear if there is any dependence on the probability that\\n', 'the other player made a particular query. This dependence\\n', 'arises with observable queries, suggesting that observable\\n', 'Socratic games with strategically zero-sum worlds may be\\n', 'harder to solve.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Playing Games in Many Possible Worlds'}, {'doc_id': 'J-57', 'full_text': ['Marginal Contribution Nets: A Compact Representation', 'We present a new approach to representing coalitional games\\n', 'based on rules that describe the marginal contributions of\\n', 'the agents. This representation scheme captures \\n', 'characteristics of the interactions among the agents in a natural and\\n', 'concise manner. We also develop efficient algorithms for two\\n', 'of the most important solution concepts, the Shapley value\\n', 'and the core, under this representation. The Shapley value\\n', 'can be computed in time linear in the size of the input. The\\n', 'emptiness of the core can be determined in time \\n', 'exponential only in the treewidth of a graphical interpretation of our\\n', 'representation.\\n', 'Agents can often benefit by coordinating their actions.\\n', 'Coalitional games capture these opportunities of \\n', 'coordination by explicitly modeling the ability of the agents to take\\n', 'joint actions as primitives. As an abstraction, coalitional\\n', 'games assign a payoff to each group of agents in the game.\\n', 'This payoff is intended to reflect the payoff the group of\\n', 'agents can secure for themselves regardless of the actions\\n', 'of the agents not in the group. These choices of primitives\\n', 'are in contrast to those of non-cooperative games, of which\\n', 'agents are modeled independently, and their payoffs depend\\n', 'critically on the actions chosen by the other agents.\\n', '1.1 Coalitional Games and E-Commerce\\n', 'Coalitional games have appeared in the context of \\n', 'e-commerce. In [7], Kleinberg et al. use coalitional games to study\\n', 'recommendation systems. In their model, each individual\\n', 'knows about a certain set of items, is interested in learning\\n', 'about all items, and benefits from finding out about them.\\n', 'The payoffs to groups of agents are the total number of \\n', 'distinct items known by its members. Given this coalitional\\n', 'game setting, Kleinberg et al. compute the value of the \\n', 'private information of the agents is worth to the system using\\n', 'the solution concept of the Shapley value (definition can be\\n', 'found in section 2). These values can then be used to \\n', 'determine how much each agent should receive for participating\\n', 'in the system.\\n', 'As another example, consider the economics behind \\n', 'supply chain formation. The increased use of the Internet as a\\n', 'medium for conducting business has decreased the costs for\\n', 'companies to coordinate their actions, and therefore \\n', 'coalitional game is a good model for studying the supply chain\\n', 'problem. Suppose that each manufacturer purchases his raw\\n', 'materials from some set of suppliers, and that the suppliers\\n', 'offer higher discount with more purchases. The decrease in\\n', 'communication costs will let manufacturers find others \\n', 'interested in the same set of suppliers cheaper, and facilitates\\n', 'formation of coalitions to bargain with the suppliers. \\n', 'Depending on the set of suppliers and how much from each\\n', 'supplier each coalition purchases, we can assign payoffs to\\n', 'the coalitions depending on the discount it receives. The\\n', 'resulting game can be analyzed using coalitional game \\n', 'theory, and we can answer questions such as the stability of\\n', 'coalitions, and how to fairly divide the benefits among the\\n', 'participating manufacturers. A similar problem, \\n', 'combinatorial coalition formation, has previously been studied in [8].\\n', '1.2 Evaluation Criteria for Coalitional Game\\n', 'Representation\\n', 'To capture the coalitional games described above and \\n', 'perform computations on them, we must first find a \\n', 'representation for these games. The na¨ıve solution is to enumerate\\n', 'the payoffs to each set of agents, therefore requiring space\\n', '193\\n', 'exponential in the number of agents in the game. For the\\n', 'two applications described, the number of agents in the \\n', 'system can easily exceed a hundred; this na¨ıve approach will\\n', 'not be scalable to such problems. Therefore, it is critical to\\n', 'find good representation schemes for coalitional games.\\n', 'We believe that the quality of a representation scheme\\n', 'should be evaluated by four criteria.\\n', 'Expressivity: the breadth of the class of coalitional games\\n', 'covered by the representation.\\n', 'Conciseness: the space requirement of the representation.\\n', 'Efficiency: the efficiency of the algorithms we can develop\\n', 'for the representation.\\n', 'Simplicity: the ease of use of the representation by users\\n', 'of the system.\\n', 'The ideal representation should be fully expressive, i.e., it\\n', 'should be able to represent any coalitional games, use as\\n', 'little space as possible, have efficient algorithms for \\n', 'computation, and be easy to use. The goal of this paper is to\\n', 'develop a representation scheme that has properties close to\\n', 'the ideal representation.\\n', 'Unfortunately, given that the number of degrees of \\n', 'freedom of coalitional games is O(2n\\n', '), not all games can be \\n', 'represented concisely using a single scheme due to information\\n', 'theoretic constraints. For any given class of games, one may\\n', 'be able to develop a representation scheme that is tailored\\n', 'and more compact than a general scheme. For example, for\\n', 'the recommendation system game, a highly compact \\n', 'representation would be one that simply states which agents know\\n', 'of which products, and let the algorithms that operate on\\n', 'the representation to compute the values of coalitions \\n', 'appropriately. For some problems, however, there may not be\\n', 'efficient algorithms for customized representations. By \\n', 'having a general representation and efficient algorithms that go\\n', 'with it, the representation will be useful as a prototyping\\n', 'tool for studying new economic situations.\\n', '1.3 Previous Work\\n', 'The question of coalitional game representation has only\\n', 'been sparsely explored in the past [2, 3, 4]. In [4], Deng\\n', 'and Papadimitriou focused on the complexity of different\\n', 'solution concepts on coalitional games defined on graphs.\\n', 'While the representation is compact, it is not fully \\n', 'expressive. In [2], Conitzer and Sandholm looked into the problem\\n', 'of determining the emptiness of the core in superadditive\\n', 'games. They developed a compact representation scheme\\n', 'for such games, but again the representation is not fully \\n', 'expressive either. In [3], Conitzer and Sandholm developed a\\n', 'fully expressive representation scheme based on \\n', 'decomposition. Our work extends and generalizes the representation\\n', 'schemes in [3, 4] through decomposing the game into a set of\\n', 'rules that assign marginal contributions to groups of agents.\\n', 'We will give a more detailed review of these papers in section\\n', '2.2 after covering the technical background.\\n', '1.4 Summary of Our Contributions\\n', '• We develop the marginal contribution networks \\n', 'representation, a fully expressive representation scheme\\n', 'whose size scales according to the complexity of the\\n', 'interactions among the agents. We believe that the\\n', 'representation is also simple and intuitive.\\n', '• We develop an algorithm for computing the Shapley\\n', 'value of coalitional games under this representation\\n', 'that runs in time linear in the size of the input.\\n', '• Under the graphical interpretation of the \\n', 'representation, we develop an algorithm for determining the\\n', 'whether a payoff vector is in the core and the emptiness\\n', 'of the core in time exponential only in the treewidth\\n', 'of the graph.\\n', '2. PRELIMINARIES\\n', 'In this section, we will briefly review the basics of \\n', 'coalitional game theory and its two primary solution concepts,\\n', 'the Shapley value and the core.1\\n', 'We will also review \\n', 'previous work on coalitional game representation in more detail.\\n', 'Throughout this paper, we will assume that the payoff to\\n', 'a group of agents can be freely distributed among its \\n', 'members. This assumption is often known as the transferable\\n', 'utility assumption.\\n', '2.1 Technical Background\\n', 'We can represent a coalition game with transferable utility\\n', 'by the pair N, v , where\\n', '• N is the set of agents; and\\n', '• v : 2N\\n', '→ R is a function that maps each group of\\n', 'agents S ⊆ N to a real-valued payoff.\\n', 'This representation is known as the characteristic form. As\\n', 'there are exponentially many subsets, it will take space \\n', 'exponential in the number of agents to describe a coalitional\\n', 'game.\\n', 'An outcome in a coalitional game specifies the utilities\\n', 'the agents receive. A solution concept assigns to each \\n', 'coalitional game a set of reasonable outcomes. Different \\n', 'solution concepts attempt to capture in some way outcomes\\n', 'that are stable and/or fair. Two of the best known solution\\n', 'concepts are the Shapley value and the core.\\n', 'The Shapley value is a normative solution concept. It\\n', 'prescribes a fair way to divide the gains from cooperation\\n', 'when the grand coalition (i.e., N) is formed. The division\\n', 'of payoff to agent i is the average marginal contribution of\\n', 'agent i over all possible permutations of the agents. \\n', 'Formally, let φi(v) denote the Shapley value of i under \\n', 'characteristic function v, then2\\n', 'φi(v) =\\n', 'S⊂N\\n', 's!(n − s − 1)!\\n', 'n!\\n', '(v(S ∪ {i}) − v(S)) (1)\\n', 'The Shapley value is a solution concept that satisfies many\\n', 'nice properties, and has been studied extensively in the \\n', 'economic and game theoretic literature. It has a very useful\\n', 'axiomatic characterization.\\n', 'Efficiency (EFF) A total of v(N) is distributed to the\\n', 'agents, i.e., i∈N φi(v) = v(N).\\n', 'Symmetry (SYM) If agents i and j are interchangeable,\\n', 'then φi(v) = φj(v).\\n', '1\\n', 'The materials and terminology are based on the textbooks\\n', 'by Mas-Colell et al. [9] and Osborne and Rubinstein [11].\\n', '2\\n', 'As a notational convenience, we will use the lower-case \\n', 'letter to represent the cardinality of a set denoted by the \\n', 'corresponding upper-case letter.\\n', '194\\n', 'Dummy (DUM) If agent i is a dummy player, i.e., his\\n', 'marginal contribution to all groups S are the same,\\n', 'φi(v) = v({i}).\\n', 'Additivity (ADD) For any two coalitional games v and\\n', 'w defined over the same set of agents N, φi(v + w) =\\n', 'φi(v) + φi(w) for all i ∈ N, where the game v + w is\\n', 'defined as (v + w)(S) = v(S) + w(S) for all S ⊆ N.\\n', 'We will refer to these axioms later in our proof of correctness\\n', 'of the algorithm for computing the Shapley value under our\\n', 'representation in section 4.\\n', 'The core is another major solution concept for coalitional\\n', 'games. It is a descriptive solution concept that focuses on\\n', 'outcomes that are stable. Stability under core means that\\n', 'no set of players can jointly deviate to improve their payoffs.\\n', 'Formally, let x(S) denote i∈S xi. An outcome x ∈ Rn\\n', 'is\\n', 'in the core if\\n', '∀S ⊆ N x(S) ≥ v(S) (2)\\n', 'The core was one of the first proposed solution concepts\\n', 'for coalitional games, and had been studied in detail. An\\n', 'important question for a given coalitional game is whether\\n', 'the core is empty. In other words, whether there is any\\n', 'outcome that is stable relative to group deviation. For a\\n', 'game to have a non-empty core, it must satisfy the property\\n', 'of balancedness, defined as follows. Let 1S ∈ Rn\\n', 'denote the\\n', 'characteristic vector of S given by\\n', '(1S)i =\\n', '1 if i ∈ S\\n', '0 otherwise\\n', 'Let (λS)S⊆N be a set of weights such that each λS is in the\\n', 'range between 0 and 1. This set of weights, (λS)S⊆N , is a\\n', 'balanced collection if for all i ∈ N,\\n', 'S⊆N\\n', 'λS(1S)i = 1\\n', 'A game is balanced if for all balanced collections of weights,\\n', 'S⊆N\\n', 'λSv(S) ≤ v(N) (3)\\n', 'By the Bondereva-Shapley theorem, the core of a \\n', 'coalitional game is non-empty if and only if the game is \\n', 'balanced. Therefore, we can use linear programming to \\n', 'determine whether the core of a game is empty.\\n', 'maximize\\n', 'λ∈R2n S⊆N λSv(S)\\n', 'subject to S⊆N λS1S = 1 ∀i ∈ N\\n', 'λS ≥ 0 ∀S ⊆ N\\n', '(4)\\n', 'If the optimal value of (4) is greater than the value of the\\n', 'grand coalition, then the core is empty. Unfortunately, this\\n', 'program has an exponential number of variables in the \\n', 'number of players in the game, and hence an algorithm that \\n', 'operates directly on this program would be infeasible in practice.\\n', 'In section 5.4, we will describe an algorithm that answers\\n', 'the question of emptiness of core that works on the dual of\\n', 'this program instead.\\n', '2.2 Previous Work Revisited\\n', 'Deng and Papadimitriou looked into the complexity of\\n', 'various solution concepts on coalitional games played on\\n', 'weighted graphs in [4]. In their representation, the set of\\n', 'agents are the nodes of the graph, and the value of a set of\\n', 'agents S is the sum of the weights of the edges spanned by\\n', 'them. Notice that this representation is concise since the\\n', 'space required to specify such a game is O(n2\\n', '). However,\\n', 'this representation is not general; it will not be able to \\n', 'represent interactions among three or more agents. For example,\\n', 'it will not be able to represent the majority game, where a\\n', 'group of agents S will have value of 1 if and only if s > n/2.\\n', 'On the other hand, there is an efficient algorithm for \\n', 'computing the Shapley value of the game, and for determining\\n', 'whether the core is empty under the restriction of positive\\n', 'edge weights. However, in the unrestricted case, \\n', 'determining whether the core is non-empty is coNP-complete.\\n', 'Conitzer and Sandholm in [2] considered coalitional games\\n', 'that are superadditive. They described a concise \\n', 'representation scheme that only states the value of a coalition if the\\n', 'value is strictly superadditive. More precisely, the semantics\\n', 'of the representation is that for a group of agents S,\\n', 'v(S) = max\\n', '{T1,T2,...,Tn}∈Π\\n', 'i\\n', 'v(Ti)\\n', 'where Π is the set of all possible partitions of S. The value\\n', 'v(S) is only explicitly specified for S if v(S) is greater than\\n', 'all partitioning of S other than the trivial partition ({S}).\\n', 'While this representation can represent all games that are\\n', 'superadditive, there are coalitional games that it cannot \\n', 'represent. For example, it will not be able to represent any\\n', 'games with substitutability among the agents. An \\n', 'example of a game that cannot be represented is the unit game,\\n', 'where v(S) = 1 as long as S = ∅. Under this \\n', 'representation, the authors showed that determining whether the core\\n', 'is non-empty is coNP-complete. In fact, even determining\\n', 'the value of a group of agents is NP-complete.\\n', 'In a more recent paper, Conitzer and Sandholm described\\n', 'a representation that decomposes a coalitional game into a\\n', 'number of subgames whose sum add up to the original game\\n', '[3]. The payoffs in these subgames are then represented by\\n', 'their respective characteristic functions. This scheme is fully\\n', 'general as the characteristic form is a special case of this\\n', 'representation. For any given game, there may be multiple\\n', 'ways to decompose the game, and the decomposition may\\n', 'influence the computational complexity. For computing the\\n', 'Shapley value, the authors showed that the complexity is\\n', 'linear in the input description; in particular, if the largest\\n', 'subgame (as measured by number of agents) is of size n and\\n', 'the number of subgames is m, then their algorithm runs\\n', 'in O(m2n\\n', ') time, where the input size will also be O(m2n\\n', ').\\n', 'On the other hand, the problem of determining whether a\\n', 'certain outcome is in the core is coNP-complete.\\n', '3. MARGINAL CONTRIBUTION NETS\\n', 'In this section, we will describe the Marginal Contribution\\n', 'Networks representation scheme. We will show that the idea\\n', 'is flexible, and we can easily extend it to increase its \\n', 'conciseness. We will also show how we can use this scheme to\\n', 'represent the recommendation game from the introduction.\\n', 'Finally, we will show that this scheme is fully expressive,\\n', 'and generalizes the representation schemes in [3, 4].\\n', '3.1 Rules and MarginalContributionNetworks\\n', 'The basic idea behind marginal contribution networks\\n', '(MC-nets) is to represent coalitional games using sets of\\n', 'rules. The rules in MC-nets have the following syntactic\\n', '195\\n', 'form:\\n', 'Pattern → value\\n', 'A rule is said to apply to a group of agents S if S meets\\n', 'the requirement of the Pattern. In the basic scheme, these\\n', 'patterns are conjunctions of agents, and S meets the \\n', 'requirement of the given pattern if S is a superset of it. The\\n', 'value of a group of agents is defined to be the sum over the\\n', 'values of all rules that apply to the group. For example, if\\n', 'the set of rules are\\n', '{a ∧ b} → 5\\n', '{b} → 2\\n', 'then v({a}) = 0, v({b}) = 2, and v({a, b}) = 5 + 2 = 7.\\n', 'MC-nets is a very flexible representation scheme, and can\\n', 'be extended in different ways. One simple way to extend\\n', 'it and increase its conciseness is to allow a wider class of\\n', 'patterns in the rules. A pattern that we will use throughout\\n', 'the remainder of the paper is one that applies only in the\\n', 'absence of certain agents. This is useful for expressing \\n', 'concepts such as substitutability or default values. Formally,\\n', 'we express such patterns by\\n', '{p1 ∧ p2 ∧ . . . ∧ pm ∧ ¬n1 ∧ ¬n2 ∧ . . . ∧ ¬nn}\\n', 'which has the semantics that such rule will apply to a group\\n', 'S only if {pi}m\\n', 'i=1 ∈ S and {nj}n\\n', 'j=1 /∈ S. We will call\\n', 'the {pi}m\\n', 'i=1 in the above pattern the positive literals, and\\n', '{nj}n\\n', 'j=1 the negative literals. Note that if the pattern of\\n', 'a rule consists solely of negative literals, we will consider\\n', 'that the empty set of agents will also satisfy such pattern,\\n', 'and hence v(∅) may be non-zero in the presence of negative\\n', 'literals.\\n', 'To demonstrate the increase in conciseness of \\n', 'representation, consider the unit game described in section 2.2. To\\n', 'represent such a game without using negative literals, we\\n', 'will need 2n\\n', 'rules for n players: we need a rule of value 1\\n', 'for each individual agent, a rule of value −1 for each pair of\\n', 'agents to counter the double-counting, a rule of value 1 for\\n', 'each triplet of agents, etc., similar to the inclusion-exclusion\\n', 'principle. On the other hand, using negative literals, we\\n', 'only need n rules: value 1 for the first agent, value 1 for the\\n', 'second agent in the absence of the first agent, value 1 for the\\n', 'third agent in the absence of the first two agents, etc. The\\n', 'representational savings can be exponential in the number\\n', 'of agents.\\n', 'Given a game represented as a MC-net, we can interpret\\n', 'the set of rules that make up the game as a graph. We call\\n', 'this graph the agent graph. The nodes in the graph will \\n', 'represent the agents in the game, and for each rule in the \\n', 'MCnet, we connect all the agents in the rule together and assign\\n', 'a value to the clique formed by the set of agents. Notice that\\n', 'to accommodate negative literals, we will need to annotate\\n', 'the clique appropriately. This alternative view of MC-nets\\n', 'will be useful in our algorithm for Core-Membership in\\n', 'section 5.\\n', 'We would like to end our discussion of the representation\\n', 'scheme by mentioning a trade-off between the \\n', 'expressiveness of patterns and the space required to represent them.\\n', 'To represent a coalitional game in characteristic form, one\\n', 'would need to specify all 2n\\n', '− 1 values. There is no \\n', 'overhead on top of that since there is a natural ordering of the\\n', 'groups. For MC-nets, however, specification of the rules\\n', 'requires specifying both the patterns and the values. The\\n', 'patterns, if not represented compactly, may end up \\n', 'overwhelming the savings from having fewer values to specify.\\n', 'The space required for the patterns also leads to a \\n', 'tradeoff between the expressiveness of the allowed patterns and\\n', 'the simplicity of representing them. However, we believe\\n', 'that for most naturally arising games, there should be \\n', 'sufficient structure in the problem such that our representation\\n', 'achieves a net saving over the characteristic form.\\n', '3.2 Example: Recommendation Game\\n', 'As an example, we will use MC-net to represent the \\n', 'recommendation game discussed in the introduction. For each\\n', 'product, as the benefit of knowing about the product will\\n', 'count only once for each group, we need to capture \\n', 'substitutability among the agents. This can be captured by a\\n', 'scaled unit game. Suppose the value of the knowledge about\\n', 'product i is vi, and there are ni agents, denoted by {xj\\n', 'i },\\n', 'who know about the product, the game for product i can\\n', 'then be represented as the following rules:\\n', '{x1\\n', 'i } → vi\\n', '{x2\\n', 'i ∧ ¬x1\\n', 'i } → vi\\n', '...\\n', '{xni\\n', 'i ∧ ¬xni−1\\n', 'i ∧ · · · ∧ ¬x1\\n', 'i } → vi\\n', 'The entire game can then be built up from the sets of rules\\n', 'of each product. The space requirement will be O(mn∗\\n', '),\\n', 'where m is the number of products in the system, and n∗\\n', 'is the maximum number of agents who knows of the same\\n', 'product.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'Marginal Contribution Nets: A Compact Representation'}, {'doc_id': 'J-74', 'full_text': ['On Cheating in Sealed-Bid Auctions', 'Motivated by the rise of online auctions and their relative\\n', 'lack of security, this paper analyzes two forms of cheating in\\n', 'sealed-bid auctions. The first type of cheating we consider\\n', 'occurs when the seller spies on the bids of a second-price\\n', 'auction and then inserts a fake bid in order to increase the\\n', 'payment of the winning bidder. In the second type, a bidder\\n', 'cheats in a first-price auction by examining the competing\\n', 'bids before deciding on his own bid. In both cases, we derive\\n', 'equilibrium strategies when bidders are aware of the \\n', 'possibility of cheating. These results provide insights into \\n', 'sealedbid auctions even in the absence of cheating, including some\\n', 'counterintuitive results on the effects of overbidding in a\\n', 'first-price auction.\\n', 'Among the types of auctions commonly used in practice,\\n', 'sealed-bid auctions are a good practical choice because they\\n', 'require little communication and can be completed almost\\n', 'instantly. Each bidder simply submits a bid, and the winner\\n', 'is immediately determined. However, sealed-bid auctions\\n', 'do require that the bids be kept private until the auction\\n', 'clears. The increasing popularity of online auctions only\\n', 'makes this disadvantage more troublesome. At an auction\\n', 'house, with all participants present, it is difficult to examine\\n', 'a bid that another bidder gave directly to the auctioneer.\\n', 'However, in an online auction the auctioneer is often little\\n', 'more than a server with questionable security; and, since all\\n', 'participants are in different locations, one can anonymously\\n', 'attempt to break into the server. In this paper, we present a\\n', 'game theoretic analysis of how bidders should behave when\\n', 'they are aware of the possibility of cheating that is based on\\n', 'knowledge of the bids.\\n', 'We investigate this type of cheating along two dimensions:\\n', 'whether it is the auctioneer or a bidder who cheats, and\\n', 'which variant (either first or second-price) of the sealed-bid\\n', 'auction is used. Note that two of these cases are trivial.\\n', 'In our setting, there is no incentive for the seller to submit\\n', 'a shill bid in a first price auction, because doing so would\\n', 'either cancel the auction or not affect the payment of the\\n', 'winning bidder. In a second-price auction, knowing the \\n', 'competing bids does not help a bidder because it is dominant\\n', 'strategy to bid truthfully. This leaves us with two cases that\\n', 'we examine in detail.\\n', 'A seller can profitably cheat in a second-price auction by\\n', 'looking at the bids before the auction clears and submitting\\n', 'an extra bid. This possibility was pointed out as early as\\n', 'the seminal paper [12] that introduced this type of auction.\\n', 'For example, if the bidders in an eBay auction each use a\\n', 'proxy bidder (essentially creating a second-price auction),\\n', 'then the seller may be able to break into eBay\"s server, \\n', 'observe the maximum price that a bidder is willing to pay, and\\n', 'then extract this price by submitting a shill bid just below\\n', 'it using a false identity. We assume that there is no chance\\n', 'that the seller will be caught when it cheats. However, not\\n', 'all sellers are willing to use this power (or, not all sellers can\\n', 'successfully cheat). We assume that each bidder knows the\\n', 'probability with which the seller will cheat. Possible \\n', 'motivation for this knowledge could be a recently published expos´e\\n', 'on seller cheating in eBay auctions. In this setting, we derive\\n', 'an equilibrium bidding strategy for the case in which each\\n', 'bidder\"s value for the good is independently drawn from a\\n', 'common distribution (with no further assumptions except\\n', 'for continuity and differentiability). This result shows how\\n', 'first and second-price auctions can be viewed as the \\n', 'endpoints of a spectrum of auctions.\\n', 'But why should the seller have all the fun? In a first-price\\n', 'auction, a bidder must bid below his value for the good (also\\n', 'called shaving his bid) in order to have positive utility if he\\n', '76\\n', 'wins. To decide how much to shave his bid, he must trade off\\n', 'the probability of winning the auction against how much he\\n', 'will pay if he does win. Of course, if he could simply examine\\n', 'the other bids before submitting his own, then his problem\\n', 'is solved: bid the minimum necessary to win the auction.\\n', 'In this setting, our goal is to derive an equilibrium bidding\\n', 'strategy for a non-cheating bidder who is aware of the \\n', 'possibility that he is competing against cheating bidders. When\\n', 'bidder values are drawn from the commonly-analyzed \\n', 'uniform distribution, we show the counterintuitive result that\\n', 'the possibility of other bidders cheating has no effect on\\n', 'the equilibrium strategy of an honest bidder. This result\\n', 'is then extended to show the robustness of the equilibrium\\n', 'of a first-price auction without the possibility of cheating.\\n', 'We conclude this section by exploring other distributions,\\n', 'including some in which the presence of cheating bidders\\n', 'actually induces an honest bidder to lower its bid.\\n', 'The rest of the paper is structured as follows. In Section\\n', '2 we formalize the setting and present our results for the\\n', 'case of a seller cheating in a second price auction. Section\\n', '3 covers the case of bidders cheating in a first-price auction.\\n', 'In Section 4, we quantify the effects that the possibility of\\n', 'cheating has on an honest seller in the two settings. We\\n', 'discuss related work, including other forms of cheating in\\n', 'auctions, in Section 5, before concluding with Section 6. All\\n', 'proofs and derivations are found in the appendix.\\n', '2. SECOND-PRICE AUCTION,\\n', 'CHEATING SELLER\\n', 'In this section, we consider a second-price auction in which\\n', 'the seller may cheat by inserting a shill bid after \\n', 'observing all of the bids. The formulation for this section will be\\n', 'largely reused in the following section on bidders cheating\\n', 'in a first-price auction. While no prior knowledge of game\\n', 'theory or auction theory is assumed, good introductions can\\n', 'be found in [2] and [6], respectively.\\n', '2.1 Formulation\\n', 'The setting consists of N bidders, or agents, (indexed by\\n', 'i = 1, · · · , n) and a seller. Each agent has a type θi ∈\\n', '[0, 1], drawn from a continuous range, which represents the\\n', 'agent\"s value for the good being auctioned.2\\n', 'Each agent\"s\\n', 'type is independently drawn from a cumulative distribution\\n', 'function (cdf ) F over [0, 1], where F(0) = 0 and F(1) = 1.\\n', 'We assume that F(·) is strictly increasing and differentiable\\n', 'over the interval [0, 1]. Call the probability density function\\n', '(pdf ) f(θi) = F (θi), which is the derivative of the cdf.\\n', 'Each agent knows its own type θi, but only the \\n', 'distribution over the possible types of the other agents. A bidding\\n', 'strategy for an agent bi : [0, 1] → [0, 1] maps its type to its\\n', 'bid.3\\n', 'Let θ = (θ1, · · · , θn) be the vector of types for all agents,\\n', 'and θ−i = (θ1, · · · , θi−1, θi+1, · · · θn) be the vector of all\\n', 'types except for that of agent i. We can then combine the\\n', 'vectors so that θ = (θi, θ−i). We also define the vector of\\n', 'bids as b(θ) = (b1(θ1), . . . , bn(θn)), and this vector without\\n', '2\\n', 'We can restrict the types to the range [0, 1] without loss\\n', 'of generality because any distribution over a different range\\n', 'can be normalized to this range.\\n', '3\\n', 'We thus limit agents to deterministic bidding strategies,\\n', 'but, because of our continuity assumption, there always \\n', 'exists a pure strategy equilibrium.\\n', 'the bid of agent i as b−i(θ−i). Let b[1](θ) be the value of the\\n', 'highest bid of the vector b(θ), with a corresponding \\n', 'definition for b[1](θ−i).\\n', 'An agent obviously wins the auction if its bid is greater\\n', 'than all other bids, but ties complicate the formulation. \\n', 'Fortunately, we can ignore the case of ties in this paper because\\n', 'our continuity assumption will make them a zero probability\\n', 'event in equilibrium. We assume that the seller does not set\\n', 'a reserve price.4\\n', 'If the seller does not cheat, then the winning agent pays\\n', 'the highest bid by another agent. On the other hand, if\\n', 'the seller does cheat, then the winning agent will pay its\\n', 'bid, since we assume that a cheating seller would take full\\n', 'advantage of its power. Let the indicator variable µc\\n', 'be 1\\n', 'if the seller cheats, and 0 otherwise. The probability that\\n', 'the seller cheats, Pc\\n', ', is known by all agents.5\\n', 'We can then\\n', 'write the payment of the winning agent as follows.\\n', 'pi(b(θ), µc\\n', ') = µc\\n', '· bi(θi) − (1 − µc\\n', ') · b[1](θ−i) (1)\\n', 'Let µ(·) be an indicator function that takes an inequality\\n', 'as an argument and returns is 1 if it holds, and 0 otherwise.\\n', 'The utility for agent i is zero if it does not win the auction,\\n', 'and the difference between its valuation and its price if it\\n', 'does.\\n', 'ui(b(θ), µc\\n', ', θi) = µ bi(θi) > b[1](θ−i) · θi − pi(b(θ), µc\\n', ')\\n', '(2)\\n', 'We will be concerned with the expected utility of an agent,\\n', 'with the expectation taken over the types of the other agents\\n', 'and over whether or not the seller cheats. By pushing the\\n', 'expectation inward so that it is only over the price \\n', '(conditioned on the agent winning the auction), we can write the\\n', 'expected utility as:\\n', 'Eθ−i,µc [ui(b(θ), µc\\n', ', θi)] = Prob bi(θi) > b[1](θ−i) ·\\n', 'θi − Eθ−i,µc pi(b(θ), µc\\n', ') | bi(θi) > b[1](θ−i) (3)\\n', 'We assume that all agents are rational, expected utility\\n', 'maximizers. Because of the uncertainty over the types of\\n', 'the other agents, we will be looking for a Bayes-Nash \\n', 'equilibrium. A vector of bidding strategies b∗\\n', 'is a Bayes-Nash\\n', 'equilibrium if for each agent i and each possible type θi,\\n', 'agent i cannot increase its expected utility by using an \\n', 'alternate bidding strategy bi, holding the bidding strategies\\n', 'for all other agents fixed. Formally, b∗\\n', 'is a Bayes-Nash \\n', 'equilibrium if:\\n', '∀i, θi, bi Eθ−i,µc ui b∗\\n', 'i (θi), b∗\\n', '−i(θ−i) , µc\\n', ', θi ≥\\n', 'Eθ−i,µc ui bi(θi), b∗\\n', '−i(θ−i) , µc\\n', ', θi (4)\\n', '2.2 Equilibrium\\n', 'We first present the Bayes-Nash equilibrium for an \\n', 'arbitrary distribution F(·).\\n', '4\\n', 'This simplifies the analysis, but all of our results can be\\n', 'applied to the case in which the seller announces a reserve\\n', 'price before the auction begins.\\n', '5\\n', 'Note that common knowledge is not necessary for the \\n', 'existence of an equilibrium.\\n', '77\\n', 'Theorem 1. In a second-price auction in which the seller\\n', 'cheats with probability Pc\\n', ', it is a Bayes-Nash equilibrium for\\n', 'each agent to bid according to the following strategy:\\n', 'bi(θi) = θi −\\n', 'θi\\n', '0\\n', 'F( N−1\\n', 'P c )\\n', '(x)dx\\n', 'F( N−1\\n', 'P c )\\n', '(θi)\\n', '(5)\\n', 'It is useful to consider the extreme points of Pc\\n', '. Setting\\n', 'Pc\\n', '= 1 yields the correct result for a first-price auction (see,\\n', 'e.g., [10]). In the case of Pc\\n', '= 0, this solution is not defined.\\n', 'However, in the limit, bi(θi) approaches θi as Pc\\n', 'approaches\\n', '0, which is what we expect as the auction approaches a\\n', 'standard second-price auction.\\n', 'The position of Pc\\n', 'is perhaps surprising. For example, the\\n', 'linear combination bi(θi) = θi − Pc\\n', '·\\n', 'θi\\n', '0 F (N−1)\\n', '(x)dx\\n', 'F (N−1)(θi)\\n', 'of the\\n', 'equilibrium bidding strategies of first and second-price \\n', 'auctions would have also given us the correct bidding strategies\\n', 'for the cases of Pc\\n', '= 0 and Pc\\n', '= 1.\\n', '2.3 Continuum of Auctions\\n', 'An alternative perspective on the setting is as a \\n', 'continuum between first and second-price auctions. Consider a\\n', 'probabilistic sealed-bid auction in which the seller is \\n', 'honest, but the price paid by the winning agent is determined\\n', 'by a weighted coin flip: with probability Pc\\n', 'it is his bid,\\n', 'and with probability 1 − Pc\\n', 'it is the second-highest bid.\\n', 'By adjusting Pc\\n', ', we can smoothly move between a first\\n', 'and second-price auction. Furthermore, the fact that this\\n', 'probabilistic auction satisfies the properties required for the\\n', 'Revenue Equivalence Theorem (see, e.g., [2]) provides a way\\n', 'to verify that the bidding strategy in Equation 5 is the \\n', 'symmetric equilibrium of this auction (see the alternative proof\\n', 'of Theorem 1 in the appendix).\\n', '2.4 Special Case: Uniform Distribution\\n', 'Another way to try to gain insight into Equation 5 is by\\n', 'instantiating the distribution of types. We now consider the\\n', 'often-studied uniform distribution: F(θi) = θi.\\n', 'Corollary 2. In a second-price auction in which the\\n', 'seller cheats with probability Pc\\n', ', and F(θi) = θi, it is a\\n', 'Bayes-Nash equilibrium for each agent to bid according to\\n', 'the following strategy:\\n', 'bi(θi) =\\n', 'N − 1\\n', 'N − 1 + Pc\\n', 'θi (6)\\n', 'This equilibrium bidding strategy, parameterized by Pc\\n', ',\\n', 'can be viewed as an interpolation between two well-known\\n', 'results. When Pc\\n', '= 0 the bidding strategy is now \\n', 'welldefined (each agent bids its true type), while when Pc\\n', '= 1\\n', 'we get the correct result for a first-price auction: each agent\\n', 'bids according to the strategy bi(θi) = N−1\\n', 'N\\n', 'θi.\\n', '3. FIRST-PRICE AUCTION,\\n', 'CHEATING AGENTS\\n', 'We now consider the case in which the seller is honest,\\n', 'but there is a chance that agents will cheat and examine the\\n', 'other bids before submitting their own (or, alternatively,\\n', 'they will revise their bid before the auction clears). Since\\n', 'this type of cheating is pointless in a second-price auction,\\n', 'we only analyze the case of a first-price auction. After \\n', 'revising the formulation from the previous section, we present a\\n', 'fixed point equation for the equilibrium strategy for an \\n', 'arbitrary distribution F(·). This equation will be useful for the\\n', 'analysis the uniform distribution, in which we show that the\\n', 'possibility of cheating agents does not change the \\n', 'equilibrium strategy of honest agents. This result has implications\\n', 'for the robustness of the symmetric equilibrium to \\n', 'overbidding in a standard first-price auction. Furthermore, we find\\n', 'that for other distributions overbidding actually induces a\\n', 'competing agent to shave more off of its bid.\\n', '3.1 Formulation\\n', 'It is clear that if a single agent is cheating, he will bid\\n', '(up to his valuation) the minimum amount necessary to win\\n', 'the auction. It is less obvious, though, what will happen if\\n', 'multiple agents cheat. One could imagine a scenario similar\\n', 'to an English auction, in which all cheating agents keep\\n', 'revising their bids until all but one cheater wants the good\\n', 'at the current winning bid. However, we are only concerned\\n', 'with how an honest agent should bid given that it is aware\\n', 'of the possibility of cheating. Thus, it suffices for an honest\\n', 'agent to know that it will win the auction if and only if\\n', 'its bid exceeds every other honest agent\"s bid and every\\n', 'cheating agent\"s type.\\n', 'This intuition can be formalized as the following \\n', 'discriminatory auction. In the first stage, each agent\"s payment\\n', 'rule is determined. With probability Pa\\n', ', the agent will pay\\n', 'the second highest bid if it wins the auction (essentially,\\n', 'he is a cheater), and otherwise it will have to pay its bid.\\n', 'These selections are recorded by a vector of indicator \\n', 'variables µa\\n', '= (µa1\\n', ', . . . , µan\\n', '), where µai\\n', '= 1 denotes that agent\\n', 'i pays the second highest bid. Each agent knows the \\n', 'probability Pa\\n', ', but does not know the payment rule for all other\\n', 'agents. Otherwise, this auction is a standard, sealed-bid\\n', 'auction. It is thus a dominant strategy for a cheater to bid\\n', 'its true type, making this formulation strategically \\n', 'equivalent to the setting outlined in the previous paragraph. The\\n', 'expression for the utility of an honest agent in this \\n', 'discriminatory auction is as follows.\\n', 'ui(b(θ), µa\\n', ', θi) = θi − bi(θ) ·\\n', 'j=i\\n', 'µaj\\n', '· µ bi(θi) > θj + (1 − µaj\\n', ') · µ bi(θi) > bj(θj)\\n', '(7)\\n', '3.2 Equilibrium\\n', 'Our goal is to find the equilibrium in which all cheating\\n', 'agents use their dominant strategy of bidding truthfully and\\n', 'honest agents bid according to a symmetric bidding strategy.\\n', 'Since we have left F(·) unspecified, we cannot present a\\n', 'closed form solution for the honest agent\"s bidding strategy,\\n', 'and instead give a fixed point equation for it.\\n', 'Theorem 3. In a first-price auction in which each agent\\n', 'cheats with probability Pa\\n', ', it is a Bayes-Nash equilibrium\\n', 'for each non-cheating agent i to bid according to the strategy\\n', 'that is a fixed point of the following equation:\\n', 'bi(θi) = θi −\\n', 'θi\\n', '0 Pa · F(bi(x)) + (1 − Pa) · F(x)\\n', '(N−1)\\n', 'dx\\n', 'Pa · F(bi(θi)) + (1 − Pa) · F(θi)\\n', '(N−1)\\n', '(8)\\n', '78\\n', '3.3 Special Case: Uniform Distribution\\n', 'Since we could not solve Equation 8 in the general case,\\n', 'we can only see how the possibility of cheating affects the\\n', 'equilibrium bidding strategy for particular instances of F(·).\\n', 'A natural place to start is uniform distribution: F(θi) = θi.\\n', 'Recall the logic behind the symmetric equilibrium strategy\\n', 'in a first-price auction without cheating: bi(θi) = N−1\\n', 'N\\n', 'θi is\\n', 'the optimal tradeoff between increasing the probability of\\n', 'winning and decreasing the price paid upon winning, given\\n', 'that the other agents are bidding according to the same\\n', 'strategy. Since in the current setting the cheating agents\\n', 'do not shave their bid at all and thus decrease an honest\\n', 'agent\"s probability of winning (while obviously not affecting\\n', 'the price that an honest agent pays if he wins), it is \\n', 'natural to expect that an honest agent should compensate by\\n', 'increasing his bid. The idea is that sacrificing some \\n', 'potential profit in order to regain some of the lost probability of\\n', 'winning would bring the two sides of the tradeoff back into\\n', 'balance. However, it turns out that the equilibrium bidding\\n', 'strategy is unchanged.\\n', 'Corollary 4. In a first-price auction in which each agent\\n', 'cheats with probability Pa\\n', ', and F(θi) = θi, it is a \\n', 'BayesNash equilibrium for each non-cheating agent to bid \\n', 'according to the strategy bi(θi) = N−1\\n', 'N\\n', 'θi.\\n', 'This result suggests that the equilibrium of a first-price\\n', 'auction is particularly robust when types are drawn from the\\n', 'uniform distribution, since the best response is unaffected\\n', 'by deviations of the other agents to the strategy of always\\n', 'bidding their type. In fact, as long as all other agents shave\\n', 'their bid by a fraction (which can differ across the agents) no\\n', 'greater than 1\\n', 'N\\n', ', it is still a best response for the remaining\\n', 'agent to bid according to the equilibrium strategy. Note\\n', 'that this result holds even if other agents are shaving their\\n', 'bid by a negative fraction, and are thus irrationally bidding\\n', 'above their type.\\n', 'Theorem 5. In a first-price auction where F(θi) = θi, if\\n', 'each agent j = i bids according a strategy bj(θj) =\\n', 'N−1+αj\\n', 'N\\n', 'θj,\\n', 'where αj ≥ 0, then it is a best response for the remaining\\n', 'agent i to bid according to the strategy bi(θi) = N−1\\n', 'N\\n', 'θi.\\n', 'Obviously, these strategy profiles are not equilibria (unless\\n', 'each αj = 0), because each agent j has an incentive to set\\n', 'αj = 0. The point of this theorem is that a wide range of\\n', 'possible beliefs that an agent can hold about the strategies\\n', 'of the other agents will all lead him to play the equilibrium\\n', 'strategy. This is important because a common (and valid)\\n', 'criticism of equilibrium concepts such as Nash and \\n', 'BayesNash is that they are silent on how the agents converge\\n', 'on a strategy profile from which no one wants to deviate.\\n', 'However, if the equilibrium strategy is a best response to a\\n', 'large set of strategy profiles that are out of equilibrium, then\\n', 'it seems much more plausible that the agents will indeed\\n', 'converge on this equilibrium.\\n', 'It is important to note, though, that while this equilibrium\\n', 'is robust against arbitrary deviations to strategies that shave\\n', 'less, it is not robust to even a single agent shaving more off\\n', 'of its bid. In fact, if we take any strategy profile consistent\\n', 'with the conditions of Theorem 5 and change a single agent\\n', 'j\"s strategy so that its corresponding αj is negative, then\\n', 'agent i\"s best response is to shave more than 1\\n', 'N\\n', 'off of its\\n', 'bid.\\n', '3.4 Effects of Overbidding for\\n', 'Other Distributions\\n', 'A natural question is whether the best response bidding\\n', 'strategy is similarly robust to overbidding by competing\\n', 'agents for other distributions. It turns out that Theorem\\n', '5 holds for all distributions of the form F(θi) = (θi)k\\n', ', where\\n', 'k is some positive integer. However, taking a simple linear\\n', 'combination of two such distributions to produce F(θi) =\\n', 'θ2\\n', 'i +θi\\n', '2\\n', 'yields a distribution in which an agent should \\n', 'actually shave its bid more when other agents shave their bids\\n', 'less. In the example we present for this distribution (with\\n', 'the details in the appendix), there are only two players and\\n', 'the deviation by one agent is to bid his type. However, it\\n', 'can be generalized to a higher number of agents and to other\\n', 'deviations.\\n', 'Example 1. In a first-price auction where F(θi) =\\n', 'θ2\\n', 'i +θi\\n', '2\\n', 'and N = 2, if agent 2 always bids its type (b2(θ2) = θ2),\\n', 'then, for all θ1 > 0, agent 1\"s best response bidding strategy\\n', 'is strictly less than the bidding strategy of the symmetric\\n', 'equilibrium.\\n', 'We also note that the same result holds for the normalized\\n', 'exponential distribution (F(θi) = eθi −1\\n', 'e−1\\n', ').\\n', 'It is certainly the case that distributions can be found\\n', 'that support the intuition given above that agents should\\n', 'shave their bid less when other agents are doing likewise.\\n', 'Examples include F(θi) = −1\\n', '2\\n', 'θ2\\n', 'i + 3\\n', '2\\n', 'θi (the solution to the\\n', 'system of equations: F (θi) = −1, F(0) = 0, and F(1) = 1),\\n', 'and F(θi) = e−e(1−θi)\\n', 'e−1\\n', '.\\n', 'It would be useful to relate the direction of the change\\n', 'in the best response bidding strategy to a general \\n', 'condition on F(·). Unfortunately, we were not able to find such\\n', 'a condition, in part because the integral in the symmetric\\n', 'bidding strategy of a first-price auction cannot be solved\\n', 'without knowing F(·) (or at least some restrictions on it).\\n', 'We do note, however, that the sign of the second \\n', 'derivative of F(θi)/f(θi) is an accurate predictor for all of the\\n', 'distributions that we considered.\\n'], 'abstract': None, 'full-text': None, 'candidates': None, 'title': 'On Cheating in Sealed-Bid Auctions'}]\n"
     ]
    }
   ],
   "source": [
    "import glob, os, re\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from pandas import DataFrame\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "import Stemmer, string\n",
    "\n",
    "train=glob.glob('./se_txt/train/dummy/*.txt.final')   \n",
    "\n",
    "def load_files(path):\n",
    "    raw=[]\n",
    "    for file in path:\n",
    "        d_all={'doc_id': None, 'title': None, 'abstract': None, 'full-text': None, 'candidates': None}\n",
    "        file_id=os.path.basename(file).rstrip('.txt.final') #catch only file name  \n",
    "        source=open(file,encoding='utf-8').readlines()\n",
    "        \n",
    "        d_all['doc_id']=file_id\n",
    "        \n",
    "        ##########detect title\n",
    "        beginning=re.sub(\"\\n\", \"\", source[0]) #retrieve title\n",
    "        candidate=re.sub(\"\\n\", \"\", source[1]) # retrieve title candidate\n",
    "        h_candidate=word_tokenize(re.sub(\"-\",' ',candidate)) #tokenize the candidate\n",
    "        \n",
    "        title=[]\n",
    "        name=[]\n",
    "        for word in h_candidate:\n",
    "            if wordnet.synsets(word): #check if candidate exist on wordnet\n",
    "                title.append(word)\n",
    "            else:\n",
    "                name.append(word)\n",
    "            #if title>\n",
    "            if len(title)>len(name): \n",
    "                newtitle=beginning+' '+candidate\n",
    "            elif len(title)==len(name):\n",
    "                newtitle=beginning\n",
    "            else:\n",
    "                newtitle=beginning\n",
    "\n",
    "        d_all['title']=newtitle\n",
    "\n",
    "        ##################################\n",
    "        \n",
    "        content=source[2:]\n",
    "        ######check header, inconsistency all file\n",
    "        r_intro=re.compile(\"^1\\.?\\s[A-Z]+\")\n",
    "        r_ref=re.compile(\"[0-9]{1,2}?\\.?\\s?R[EFERENCES|eferences]\") #detect reference\n",
    "        #r_header=re.compile(\"[0-9]{1,2}?\\.?\\s?[A-Z]\")\n",
    "        \n",
    "        in_abstract=content.index('ABSTRACT\\n')\n",
    "        in_authorkey=content.index('Categories and Subject Descriptors\\n')\n",
    "        \n",
    "        list_intro=[i for i, item in enumerate(content) if re.search(r_intro, item)]\n",
    "        in_intro=list_intro[0]\n",
    "        list_ref=[i for i, item in enumerate(content) if re.search(r_ref, item)]\n",
    "        in_ref=list_ref[0]\n",
    "        \n",
    "        abstract=content[in_abstract+1:in_authorkey] #eliminate keyword and category\n",
    "        body=content[in_intro+1:in_ref] #remove reference       \n",
    "        \n",
    "        list_title=[]\n",
    "        list_title.append(newtitle)\n",
    "        \n",
    "        full_text=list(chain(list_title,abstract, body))\n",
    "        #d_all['abstract']=clean_merge(abstract)\n",
    "        #d_all['body']=clean_merge(body)\n",
    "        d_all['full_text']=full_text\n",
    "        \n",
    "        raw.append(d_all)\n",
    "    return raw\n",
    "\n",
    "\n",
    "print(load_files(train))\n",
    "#####pandas\n",
    "#l=load_files(train)\n",
    "#print(DataFrame(l).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s [['Keyphrase', 'extraction', 'is', 'the', 'task', 'of', 'identifying', 'single', 'or', 'multi-word', 'expressions', 'that', 'represent', 'the', 'main', 'topics', 'of', 'a', 'document', '.'], ['In', 'this', 'paper', 'we', 'present', 'TopicRank', ',', 'a', 'graph-based', 'keyphrase', 'extraction', 'method', 'that', 'relies', 'on', 'a', 'topical', 'representation', 'of', 'the', 'document', '.']]\n",
      "t [[('Keyphrase', 'NNP'), ('extraction', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('task', 'NN'), ('of', 'IN'), ('identifying', 'VBG'), ('single', 'JJ'), ('or', 'CC'), ('multi-word', 'JJ'), ('expressions', 'NNS'), ('that', 'WDT'), ('represent', 'VBP'), ('the', 'DT'), ('main', 'JJ'), ('topics', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('document', 'NN'), ('.', '.')], [('In', 'IN'), ('this', 'DT'), ('paper', 'NN'), ('we', 'PRP'), ('present', 'JJ'), ('TopicRank', 'NNP'), (',', ','), ('a', 'DT'), ('graph-based', 'JJ'), ('keyphrase', 'NN'), ('extraction', 'NN'), ('method', 'NN'), ('that', 'WDT'), ('relies', 'VBZ'), ('on', 'IN'), ('a', 'DT'), ('topical', 'JJ'), ('representation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('document', 'NN'), ('.', '.')]]\n",
      "s2 [{'POS': ['NNP', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'VBG', 'JJ', 'CC', 'JJ', 'NNS', 'WDT', 'VBP', 'DT', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.'], 'words': ['Keyphrase', 'extraction', 'is', 'the', 'task', 'of', 'identifying', 'single', 'or', 'multi-word', 'expressions', 'that', 'represent', 'the', 'main', 'topics', 'of', 'a', 'document', '.']}, {'POS': ['IN', 'DT', 'NN', 'PRP', 'JJ', 'NNP', ',', 'DT', 'JJ', 'NN', 'NN', 'NN', 'WDT', 'VBZ', 'IN', 'DT', 'JJ', 'NN', 'IN', 'DT', 'NN', '.'], 'words': ['In', 'this', 'paper', 'we', 'present', 'TopicRank', ',', 'a', 'graph-based', 'keyphrase', 'extraction', 'method', 'that', 'relies', 'on', 'a', 'topical', 'representation', 'of', 'the', 'document', '.']}]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize, pos_tag_sents\n",
    "\n",
    "text=\"\"\"Keyphrase extraction is the task of identifying single or\n",
    "                 multi-word expressions that represent the main topics of a\n",
    "                 document. In this paper we present TopicRank, a graph-based\n",
    "                 keyphrase extraction method that relies on a topical\n",
    "                 representation of the document.\"\"\"\n",
    "sents=[]\n",
    "\n",
    "#extract tokens and create list per sentence\n",
    "sentences=[word_tokenize(s) for s in sent_tokenize(text)]\n",
    "\n",
    "#create tuples from each token on sentences list\n",
    "tuples=pos_tag_sents(sentences)\n",
    "\n",
    "#create list of dictionary contains of pos and word\n",
    "for sentence in tuples:\n",
    "    sents.append({\n",
    "        \"words\":[x[0] for x in sentence],\n",
    "        \"POS\":[x[1] for x in sentence]\n",
    "    })\n",
    "print('s',sentences)\n",
    "print('t',tuples)\n",
    "print('s2',sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keyphrase', 'extraction', 'task', 'single', 'multi-word', 'expressions', 'main', 'topics', 'document', 'paper', 'present', 'topicrank', 'graph-based', 'keyphrase', 'extraction', 'method', 'topical', 'representation', 'document']\n"
     ]
    }
   ],
   "source": [
    "def extract_candidate_words(text, good_tags=set(['JJ','JJR','JJS','NN','NNP','NNS','NNPS'])):\n",
    "    import itertools, nltk, string\n",
    "\n",
    "    # exclude candidates that are stop words or entirely punctuation\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenize and POS-tag words\n",
    "    tagged_words = itertools.chain.from_iterable(nltk.pos_tag_sents(nltk.word_tokenize(sent)\n",
    "                                                                    for sent in nltk.sent_tokenize(text)))\n",
    "    #print('tag',list(tagged_words))\n",
    "    # filter on certain POS tags and lowercase all words\n",
    "    candidates = [word.lower() for word, tag in tagged_words\n",
    "                  if tag in good_tags and word.lower() not in stop_words\n",
    "                  and not all(char in punct for char in word)]\n",
    "\n",
    "    return candidates \n",
    "print(extract_candidate_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-bafde6c925e5>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-bafde6c925e5>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    for key, group in itertools.groupby(all_chunks, lambda (word,pos,chunk): chunk != 'O') if key]\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def extract_candidate_chunks(text, grammar=r'KT: {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}'):\n",
    "    import itertools, nltk, string\n",
    "    \n",
    "    # exclude candidates that are stop words or entirely punctuation\n",
    "    punct = set(string.punctuation)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenize, POS-tag, and chunk using regular expressions\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))\n",
    "    all_chunks = list(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent))\n",
    "                                                    for tagged_sent in tagged_sents))\n",
    "    # join constituent chunk words into a single chunked phrase\n",
    "    candidates = [' '.join(word for word, pos, chunk in group).lower()\n",
    "                  for key, group in itertools.groupby(all_chunks, lambda (word,pos,chunk): chunk != 'O') if key]\n",
    "\n",
    "    return [cand for cand in candidates\n",
    "            if cand not in stop_words and not all(char in punct for char in cand)]\n",
    "\n",
    "print(extract_candidate_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_keyphrases_by_tfidf(texts, candidates='chunks'):\n",
    "    import gensim, nltk\n",
    "    \n",
    "    # extract candidates from each text in texts, either chunks or words\n",
    "    if candidates == 'chunks':\n",
    "        boc_texts = [extract_candidate_chunks(text) for text in texts]\n",
    "    elif candidates == 'words':\n",
    "        boc_texts = [extract_candidate_words(text) for text in texts]\n",
    "    # make gensim dictionary and corpus\n",
    "    dictionary = gensim.corpora.Dictionary(boc_texts)\n",
    "    corpus = [dictionary.doc2bow(boc_text) for boc_text in boc_texts]\n",
    "    # transform corpus with tf*idf model\n",
    "    tfidf = gensim.models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    return corpus_tfidf, dictionary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
