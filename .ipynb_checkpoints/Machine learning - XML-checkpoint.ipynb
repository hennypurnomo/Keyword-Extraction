{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-27 18:27:42,891: DEBUG: CACHEDIR=C:\\Users\\user\\.matplotlib\n",
      "2018-08-27 18:27:42,891: DEBUG: CACHEDIR=C:\\Users\\user\\.matplotlib\n",
      "2018-08-27 18:27:42,962: DEBUG: Using fontManager instance from C:\\Users\\user\\.matplotlib\\fontList.json\n",
      "2018-08-27 18:27:42,962: DEBUG: Using fontManager instance from C:\\Users\\user\\.matplotlib\\fontList.json\n",
      "2018-08-27 18:27:45,919: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n",
      "2018-08-27 18:27:45,919: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n",
      "2018-08-27 18:27:46,695: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n",
      "2018-08-27 18:27:46,695: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "#This file contains noun phrase and n-gram filters on Semeval dataset (XML version)\n",
    "#only evaluate the model on combined label\n",
    "\n",
    "import glob, os\n",
    "import utils, preprocessing, generate_candidate\n",
    "import feature_extraction, generate_keyphrase\n",
    "\n",
    "#this is the default number\n",
    "number_keyphrase = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if these files are exist on pickle, please skip into next step\n",
    "\n",
    "#load gold keyphrase\n",
    "train_label_directory = open('./data/se_txt/train/train.combined.stem.final', \n",
    "                        encoding='utf-8').read()\n",
    "train_label = preprocessing.extract_keyphrase(train_label_directory)\n",
    "pickle_train_label = utils.create_pickle(train_label, './pickle/semeval/train label')\n",
    "\n",
    "test_label_directory = open('./data/se_txt/test_answer/test.combined.stem.final', \n",
    "                            encoding='utf-8').read()\n",
    "test_label = preprocessing.extract_keyphrase(test_label_directory)\n",
    "pickle_test_label = utils.create_pickle(test_label, './pickle/semeval/test label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only run one time, if pickles have been generated, please skip into next step\n",
    "#this section is intended to create candidates, supervised keyphraseness\n",
    "\n",
    "#load and create training data\n",
    "train_directory = glob.glob('./data/se_xml/train/*.xml')\n",
    "train_raw = preprocessing.load_xml(train_directory)\n",
    "pickle_train_raw = utils.create_pickle(train_raw,'./pickle/semeval/xml train raw')\n",
    "train_data = preprocessing.create_xml_corpus(train_raw)\n",
    "pickle_train_data = utils.create_pickle(train_data,'./pickle/semeval/xml train data')\n",
    "train_tf_corpus = feature_extraction.calculate_tf(train_data, vocab = None, type = 'ngram')\n",
    "pickle_train_tf_corpus = utils.create_pickle(train_tf_corpus,'./pickle/semeval/xml train tf corpus')\n",
    "\n",
    "#load and create testing data\n",
    "test_directory = glob.glob('./data/se_xml/test/*.xml')\n",
    "test_raw = preprocessing.load_xml(test_directory)\n",
    "pickle_test_raw = utils.create_pickle(test_raw,\n",
    "                                      './pickle/semeval/xml test raw')\n",
    "test_data = preprocessing.create_xml_corpus(test_raw)\n",
    "pickle_test_data = utils.create_pickle(test_data,\n",
    "                                       './pickle/semeval/xml test data')\n",
    "test_tf_corpus = feature_extraction.calculate_tf(test_data, vocab = None, type = 'ngram')\n",
    "pickle_test_tf_corpus = utils.create_pickle(test_tf_corpus,\n",
    "                                            './pickle/semeval/xml test tf corpus')\n",
    "\n",
    "\n",
    "#create candidates based on n-gram and store into pickle of training data\n",
    "print(\"Generating n-gram candidates..\")\n",
    "ngram_candidates = generate_candidate.calculate_tfidf(train_data, vocab=None, type='ngram') \n",
    "pickle_ngram_candidates = utils.create_pickle(ngram_candidates, \n",
    "                            './pickle/semeval/xml ngram candidates')\n",
    "\n",
    "#create candidates based on n-gram and store into pickle of testing data\n",
    "test_ngram_candidates = generate_candidate.calculate_tfidf(test_data, vocab=None, type='ngram') \n",
    "pickle_test_ngram_candidates = utils.create_pickle(test_ngram_candidates, \n",
    "                            './pickle/semeval/xml test ngram candidates')\n",
    "\n",
    "\n",
    "#create candidates based on noun phrase and store into pickle of training data\n",
    "print(\"Generating noun phrase candidates..\")\n",
    "nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(train_data)\n",
    "train_tf_nounphrase_corpus = feature_extraction.calculate_tf(train_data, \n",
    "                            vocab = nounphrase_vocabulary, type = 'np')\n",
    "pickle_train_tf_nounphrase_corpus = utils.create_pickle(train_tf_nounphrase_corpus,\n",
    "                            './pickle/semeval/xml train tf nounphrase corpus')\n",
    "nounphrase_candidates = generate_candidate.calculate_tfidf(train_data, \n",
    "                            nounphrase_vocabulary, type='np')\n",
    "pickle_nounphrase_candidates = utils.create_pickle(nounphrase_candidates, \n",
    "                            './pickle/semeval/xml nounphrase candidates')\n",
    "\n",
    "#create candidates based on noun phrase and store into pickle of testing data\n",
    "test_nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(test_data)\n",
    "test_tf_nounphrase_corpus = feature_extraction.calculate_tf(test_data, \n",
    "                            vocab = test_nounphrase_vocabulary, type = 'np')\n",
    "pickle_test_tf_nounphrase_corpus = utils.create_pickle(test_tf_nounphrase_corpus,\n",
    "                            './pickle/semeval/xml test tf new nounphrase corpus')\n",
    "test_nounphrase_candidates = generate_candidate.calculate_tfidf(test_data, \n",
    "                            test_nounphrase_vocabulary, type='np')\n",
    "pickle_test_nounphrase_candidates = utils.create_pickle(test_nounphrase_candidates, \n",
    "                            './pickle/semeval/xml test nounphrase candidates')\n",
    "\n",
    "\n",
    "#create a dictionary supervised keyphraseness on ngram filter by combined label\n",
    "supervised_key = feature_extraction.create_supervised_list(train_label, train_tf_corpus)\n",
    "supervised_corpus = utils.create_pickle(supervised_key, './pickle/semeval/xml ngram supervised keyphraseness')\n",
    "\n",
    "#create a dictionary supervised keyphraseness on noun phrase filter by combined label\n",
    "np_supervised_key = feature_extraction.create_supervised_list(train_label, train_tf_nounphrase_corpus)\n",
    "np_supervised_corpus = utils.create_pickle(np_supervised_key, './pickle/semeval/xml np supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening all pickles\n",
      "Opening all pickles\n"
     ]
    }
   ],
   "source": [
    "#opening all relevant pickles\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('./pickle/semeval/xml train raw')\n",
    "train_data = utils.open_pickle('./pickle/semeval/xml train data')\n",
    "\n",
    "train_label = utils.open_pickle('./pickle/semeval/train label')\n",
    "train_tf_corpus = utils.open_pickle('./pickle/semeval/xml train tf corpus')\n",
    "train_tf_nounphrase_corpus = utils.open_pickle('./pickle/semeval/xml train tf nounphrase corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('./pickle/semeval/xml test raw')\n",
    "test_data = utils.open_pickle('./pickle/semeval/xml test data')\n",
    "\n",
    "test_label = utils.open_pickle('./pickle/semeval/test label')\n",
    "test_tf_corpus = utils.open_pickle('./pickle/semeval/xml test tf corpus')\n",
    "test_tf_nounphrase_corpus = utils.open_pickle('./pickle/semeval/xml test tf nounphrase corpus')\n",
    "\n",
    "train_topics = utils.open_pickle('./pickle/semeval/xml train topics')\n",
    "test_topics = utils.open_pickle('./pickle/semeval/xml test topics')\n",
    "\n",
    "ngram_candidates = utils.open_pickle('./pickle/semeval/xml ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('./pickle/semeval/xml test ngram candidates')\n",
    "\n",
    "nounphrase_candidates = utils.open_pickle('./pickle/semeval/xml nounphrase candidates')\n",
    "test_nounphrase_candidates = utils.open_pickle('./pickle/semeval/xml test nounphrase candidates')\n",
    "\n",
    "supervised_key = utils.open_pickle('./pickle/semeval/xml ngram supervised keyphraseness')\n",
    "np_supervised_key = utils.open_pickle('./pickle/semeval/xml np supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features in training and testing data, \n",
    "#if those csv have been available, please skip to the next step\n",
    "\n",
    "#create examples on training and testing data\n",
    "print(\"Creating examples of n-gram on combined label..\")\n",
    "ngram_train = feature_extraction.create_features(train_data, \n",
    "                ngram_candidates, train_label, supervised_key, train_tf_corpus, \n",
    "                train_topics, name='./csv/semeval/xml_train_ngram', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "\n",
    "ngram_test = feature_extraction.create_features(test_data, \n",
    "                test_ngram_candidates, test_label, supervised_key, test_tf_corpus, \n",
    "                test_topics, name='./csv/semeval/xml_test_ngram', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "\n",
    "print(\"Creating examples of noun phrase on combined label..\")\n",
    "nounphrase_train = feature_extraction.create_features(train_data,\n",
    "                nounphrase_candidates, train_label, np_supervised_key, train_tf_nounphrase_corpus, \n",
    "                train_topics, name='./csv/semeval/xml_train_nounphrase', \n",
    "                n_keyphrase = number_keyphrase) \n",
    "\n",
    "nounphrase_test = feature_extraction.create_features(test_data, \n",
    "                test_nounphrase_candidates, test_label, np_supervised_key, test_tf_nounphrase_corpus, \n",
    "                test_topics, name='./csv/semeval/xml_test_nounphrase', \n",
    "                n_keyphrase = number_keyphrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on ngram filter:\n",
      "Evaluation on ngram filter:\n",
      "Precision, recall, f-measure on top 15 candidates: [('LR', (17.93, 17.79, 17.86)), ('NB', (2.33, 2.31, 2.32)), ('RF', (11.87, 11.77, 11.82)), ('AdaBoost', (11.73, 11.64, 11.68)), ('Bagging', (11.4, 11.31, 11.35))]\n",
      "Precision, recall, f-measure on top 15 candidates: [('LR', (17.93, 17.79, 17.86)), ('NB', (2.33, 2.31, 2.32)), ('RF', (11.87, 11.77, 11.82)), ('AdaBoost', (11.73, 11.64, 11.68)), ('Bagging', (11.4, 11.31, 11.35))]\n",
      "Evaluation on nounphrase filter:\n",
      "Evaluation on nounphrase filter:\n",
      "Precision, recall, f-measur on top 15 candidates: [('LR', (20.4, 20.24, 20.32)), ('NB', (13.6, 13.49, 13.54)), ('RF', (11.6, 11.51, 11.55)), ('AdaBoost', (11.33, 11.24, 11.28)), ('Bagging', (10.53, 10.45, 10.49))]\n",
      "Precision, recall, f-measur on top 15 candidates: [('LR', (20.4, 20.24, 20.32)), ('NB', (13.6, 13.49, 13.54)), ('RF', (11.6, 11.51, 11.55)), ('AdaBoost', (11.33, 11.24, 11.28)), ('Bagging', (10.53, 10.45, 10.49))]\n"
     ]
    }
   ],
   "source": [
    "#evaluation part\n",
    "\n",
    "print('Evaluation on ngram filter:')\n",
    "ngram_prediction = generate_keyphrase.predict_data(test_ngram_candidates, \n",
    "                test_label, train_data='./csv/semeval/xml_train_ngram', \n",
    "                test_data='./csv/semeval/xml_test_ngram', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "print('Precision, recall, f-measure on top 15 candidates:', ngram_prediction)\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates,\n",
    "                    train_data='./csv/semeval/xml_train_ngram', \n",
    "                    test_data='./csv/semeval/xml_test_ngram', \n",
    "                    csv_name='./csv/semeval/xml predicted ngram keyphrases keywords', \n",
    "                    n_keyphrase = number_keyphrase)\n",
    "\n",
    "print('Evaluation on nounphrase filter:')\n",
    "nounphrase_prediction = generate_keyphrase.predict_data(test_nounphrase_candidates, \n",
    "                test_label, train_data='./csv/semeval/xml_train_nounphrase', \n",
    "                test_data='./csv/semeval/xml_test_nounphrase', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "print('Precision, recall, f-measur on top 15 candidates:', nounphrase_prediction)\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "nounphrase_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_nounphrase_candidates,\n",
    "                    train_data='./csv/semeval/xml_train_nounphrase', \n",
    "                    test_data='./csv/semeval/xml_test_nounphrase', \n",
    "                    csv_name='./csv/semeval/xml predicted nounphrase keyphrases', \n",
    "                    n_keyphrase = number_keyphrase)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
