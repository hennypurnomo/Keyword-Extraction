{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'abstract': None, 'full_text': 'Network Monitors and Contracting Systems: Competition and Innovation Today\"s Internet industry suffers from several welnown pathologies, but none is as destructive in the long term as its resistance to evolution. Rather than introducing new services, ISPs are presently moving towards greater commoditization. It is apparent that the network\"s primitive system of contracts does not align incentives properly. In this study, we identify the network\"s lack of accounlity as a fundamental obstacle to correcting this problem: Employing an economic model, we argue that optimal routes and innovation are impossible unless new monitoring capability is introduced and incorporated with the contracting system. Furthermore, we derive the minimum requirements a monitoring system must meet to support firsest routing and innovation characteristics. Our work does not constitute a new protocol; rather, we provide practical and specific guidance for the design of monitoring systems, as well as a theoretical framework to explore the factors that influence innovation Many studies before us have noted the Internet\"s resistance to new services and evolution. In recent decades, numerous ideas have been developed in universities, implemented in code, and even written into the routers and end systems of the network, only to languish as network operators fail to turn them on on a large scale The list includes Multicast, IPv6, IntServ, and DiffServ. Lacking the incentives just to activate services, there seems to be little hope of ISPs devoting adequate resources to developing new ideas. In the long term, this pathology stands out as a critical obstacle to the network\"s continued success (Ratnasamy, Shenker, and McCanne provide extensive discussion in ) On a smaller time scale, ISPs shun new services in favor of cost cutting measures. Thus, the network has characteristics of a commodity market. Although in theory, ISPs have a plethora of routing policies at their disposal, the prevailing strategy is to route in the cheapest way possible . On one hand, this leads directly to suboptimal routing. More importantly, commoditization in the short term is surely related to the lack of innovation in the long term When the routing decisions of others ignore quality characteristics, ISPs are motivated only to lower costs. There is simply no reward for introducing new services or investing in quality improvements In response to these pathologies and others, researchers have put forth various proposals for improving the situation. These can be divided according to three higevel strategies: The first attempts to improve the status quo by empowering ensers. Clark, et al., suggest that giving ensers control over routing would lead to greater service diversity, recognizing that some payment mechanism must also be provided . Ratnasamy, Shenker, and McCanne postulate a link between network evolution and useirected routing . They propose a system of Anycast to give ensers the ability to tunnel their packets to an ISP that introduces a desirable protocol. The extra traffic to the ISP, the authors suggest, will motivate the initial investment The second strategy suggests a revision of the contracting system This is exemplified by MacKiason and Varian, who propose a smart market to control access to network resources . Prices are set to the markelearing level based on bids that users associate to their traffic. In another direction, Afergan and Wroclawski suggest that prices should be explicitly encoded in the routing protocols . They argue that such a move would improve slity and align incentives The third higevel strategy calls for greater network accounlity. In this vein, Argyraki, et al., propose a system of packet obituaries to provide feedback as to which ISPs drop packets . They argue that such feedback would help reveal which ISPs were adequately meeting their contractual obligations. Unlike the first two strategies, we are not aware of any previous studies that have connected accounlity with the pathologies of commoditization or lack of innovation It is clear that these three strategies are closely linked to each other (for example, , , and  each argue that giving ensers routing control within the current contracting system is problematic). Until today, however, the relationship between them has been poorly understood. There is currently little theoretical foundation to compare the relative merits of each proposal, and a particular lack of evidence linking accounlity with innovation and service differentiation. This paper will address both issues We will begin by introducing an economic network model that relates accounlity, contracts, competition, and innovation. Our model is highly stylized and may be considered preliminary: it is based on a single source sending data to a single destination Nevertheless, the structure is rich enough to expose previously unseen features of network behavior. We will use our model for two main purposes: First, we will use our model to argue that the lack of accounlity in today\"s network is a fundamental obstacle to overcoming the pathologies of commoditization and lack of innovation. In other words, unless new monitoring capabilities are introduced, and integrated with the system of contracts, the network cannot achieve optimal routing and innovation characteristics. This result provides motivation for the remainder of the paper, in which we explore how accounlity can be leveraged to overcome these pathologies and create a sustainable industry. We will approach this problem from a clealate perspective, deriving the level of accounlity needed to sustain an ideal competitive structure When we say that today\"s Internet has poor accounlity, we mean that it reveals little information about the behavior - or misbehavior - of ISPs. This welnown trait is largely rooted in the network\"s history. In describing the design philosophy behind the Internet protocols, Clark lists accounlity as the least important among seven second level goals.  Accordingly, accounlity received little attention during the network\"s formative years. Clark relates this to the network\"s military context, and finds that had the network been designed for commercial development, accounlity would have been a top priority Argyraki, et al., conjecture that applying the principles of layering and transparency may have led to the network\"s lack of accounlity . According to these principles, end hosts should be informed of network problems only to the extent that they are required to adapt. They notice when packet drops occur so that they can perform congestion control and retransmit packets. Details of where and why drops occur are deliberately concealed The network\"s lack of accounlity is highly relevant to a discussion of innovation because it constrains the system of contracts. This is because contracts depend upon external institutions to function - the judge in the language of incomplete contract theory, or simply the legal system. Ultimately, if a judge cannot verify that some condition holds, she cannot enforce a contract based on that condition. Of course, the vast majority of contracts never end up in court. Especially when a judge\"s ruling is easily predicted, the parties will typically comply with the contract terms on their own volition. This would not be possible, however, without the judge acting as a last resort An institution to support contracts is typically complex, but we abstract it as follows: We imagine that a contract is an algorithm that outputs a payment transfer among a set of ISPs (the parties) at every time. This payment is a function of the past and present behaviors of the participants, but only those that are verifiable Hence, we imagine that a contract only accepts proofs as inputs We will call any process that generates these proofs a contractible monitor. Such a monitor includes metering or sensing devices on the physical network, but it is a more general concept. Constructing a proof of a particular behavior may require readings from various devices distributed among many ISPs. The contractible monitor includes whatever distributed algorithmic mechanism is used to motivate ISPs to share this private information re 1 demonstrates how our model of contracts fits together. We make the assumption that all payments are mediated by contracts This means that without contractible monitors that attest to, say, latency, payments cannot be conditioned on latency re 1: Relationship between monitors and contracts With this model, we may conclude that the level of accounlity in today\"s Internet only permits best effort contracts. Nodes cannot condition payments on either quality or path characteristics Is there anything wrong with besffort contracts? The reader might wonder why the Internet needs contracts at all. After all, in noetwork industries, traditional firms invest in research and differentiate their products, all in the hopes of keeping their customers and securing new ones. One might believe that such market forces apply to ISPs as well. We may adopt this as our null hypothesis: Null hypothesis: Market forces are sufficient to maintain service diversity and innovation on a network, at least to the same extent as they do in traditional markets There is a popular intuitive argument that supports this hypothesis, and it may be summarized as follows: Intuitive argument supporting null hypothesis: 1. Access providers try to increase their quality to get more consumers 2. Access providers are themselves customers for second hop ISPs, and the second hops will therefore try to provide  highquality service in order to secure traffic from access providers. Access providers try to select high quality transit because that increases their quality 3. The process continues through the network, giving every ISP a competitive reason to increase quality We are careful to model our network in continuous time, in order to capture the essence of this argument. We can, for example, specify equilibria in which nodes switch to a new next hop in the event of a quality drop Moreover, our model allows us to explore any theoretically possible punishments against cheaters, including those that are costly for ensers to administer. By contrast, customers in the real world rarely respond collectively, and often simply seek the best deal currently offered. These constraints limit their ability to punish cheaters Even with these liberal assumptions, however, we find that we must reject our null hypothesis. Our model will demonstrate that identifying a cheating ISP is difficult under low accounlity, limiting the threat of market driven punishment. We will define an index of commoditization and show that it increases without bound as data paths grow long. Furthermore, we will demonstrate a framework in which an ISP\"s maximum research investment decreases hyperbolically with its distance from the enser Network Behavior Monitor Contract Proof Payments 184 To summarize, we argue that the Internet\"s lack of accounlity must be addressed before the pathologies of commoditization and lack of innovation can be resolved. This leads us to our next topic: How can we leverage accounlity to overcome these pathologies? We approach this question from a clealate perspective. Instead of focusing on incremental improvements, we try to imagine how an ideal industry would behave, then derive the level of accounlity needed to meet that objective. According to this approach, we first craft a new equilibrium concept appropriate for network competition. Our concept includes the following requirements: First, we require that punishing ISPs that cheat is done without rerouting the path. Rerouting is likely to prompt ensers to switch providers, punishing access providers who administer punishments correctly. Next, we require that the equilibrium cannot be threatened by a coalition of ISPs that exchanges illicit side payments. Finally, we require that the punishment mechanism that enforces contracts does not punish innocent nodes that are not in the coalition The last requirement is somewhat unconventional from an economic perspective, but we maintain that it is crucial for any reasonable solution. Although ISPs provide complementary services when they form a data path together, they are likely to be horizontal competitors as well. If innocent nodes may be punished, an ISP may decide to deliberately cheat and draw punishment onto itself and its neighbors. By cheating, the ISP may save resources, thereby ensuring that the punishment is more damaging to the other ISPs, which probably compete with the cheater directly for some customers. In the extreme case, the cheater may force the other ISPs out of business, thereby gaining a monopoly on some routes Applying this equilibrium concept, we derive the monitors needed to maintain innovation and optimize routes. The solution is surprisingly simple: contractible monitors must report the quality of the rest of the path, from each ISP to the destination. It turns out that this is the correct minimum accounlity requirement, as opposed to either ennd monitors or hoop monitors, as one might initially suspect Rest of path monitors can be implemented in various ways. They may be purely local algorithms that listen for packet echoes Alternately, they can be distributed in nature. We describe a way to construct a rest of path monitor out of monitors for individual ISP quality and for the data path. This requires a mechanism to motivate ISPs to share their monitor outputs with each other. The rest of path monitor then includes the component monitors and the distributed algorithmic mechanism that ensures that information is shared as required. This example shows that other types of monitors may be useful as building blocks, but must be combined to form rest of path monitors in order to achieve ideal innovation characteristics Our study has several practical implications for future protocol design. We show that new monitors must be implemented and integrated with the contracting system before the pathologies of commoditization and lack of innovation can be overcome Moreover, we derive exactly what monitors are needed to optimize routes and support innovation. In addition, our results provide useful input for clealate architectural design, and we use several novel techniques that we expect will be applicable to a variety of future research The rest of this paper is organized as follows: In section 2, we lay out our basic network model. In section 3, we present a  lowaccounlity network, modeled after today\"s Internet. We demonstrate how poor monitoring causes commoditization and a lack of innovation. In section 4, we present verifiable monitors, and show that proofs, even without contracts, can improve the status quo. In section 5, we turn our attention to contractible monitors We show that rest of path monitors can support competition games with optimal routing and innovation. We further show that rest of path monitors are required to support such competition games. We continue by discussing how such monitors may be constructed using other monitors as building blocks. In section 6, we conclude and present several directions for future research 2. BASIC NETWORK MODEL A source, S, wants to send data to destination, D. S and D are nodes on a directed, acyclic graph, with a finite set of intermediate nodes, { }NV ,...2,1= , representing ISPs. All paths lead to D, and every node not connected to D has at least two choices for next hop We will represent quality by a finite dimensional vector space, Q, called the quality space. Each dimension represents a distinct network characteristic that ensers care about. For example, latency, loss probability, jitter, and IP version can each be assigned to a dimension To each node, i, we associate a vector in the quality space, Qqi ∈  This corresponds to the quality a user would experience if i were the only ISP on the data path. Let N Q∈q be the vector of all node qualities Of course, when data passes through multiple nodes, their qualities combine in some way to yield a path quality. We represent this by an associative binary operation, *: QQQ →× . For path ( )nvvv ,...,, 21 , the quality is given by nvvv qqq ∗∗∗ ...21 . The * operation reflects the characteristics of each dimension of quality For example, * can act as an addition in the case of latency, multiplication in the case of loss probability, or a  minimumargument function in the case of security When data flows along a complete path from S to D, the source and destination, generally regarded as a single player, enjoy utility given by a function of the path quality, →Qu : . Each node along the path, i, experiences some cost of transmission, ci 2.1 Game Dynamics Ultimately, we are most interested in policies that promote innovation on the network. In this study, we will use innovation in a fairly general sense. Innovation describes any investment by an ISP that alters its quality vector so that at least one potential data path offers higher utility. This includes researching a new routing algorithm that decreases the amount of jitter users experience. It also includes deploying a new protocol that supports quality of service. Even more broadly, buying new equipment to decrease S D 185 latency may also be regarded as innovation. Innovation may be thought of as the micrevel process by which the network evolves Our analysis is limited in one crucial respect: We focus on inventions that a single ISP can implement to improve the enser experience. This excludes technologies that require adoption by all ISPs on the network to function Because such technologies do not create a competitive advantage, rewarding them is difficult and may require intellectual property or some other market distortion. We defer this interesting topic to future work At first, it may seem unclear how a largcale distributed process such as innovation can be influenced by mechanical details like networks monitors. Our model must draw this connection in a realistic fashion The rate of innovation depends on the profits that potential innovators expect in the future. The reward generated by an invention must exceed the total cost to develop it, or the inventor will not rationally invest. This reward, in turn, is governed by the competitive environment in which the firm operates, including the process by which firms select prices, and agree upon contracts with each other. Of course, these decisions depend on how routes are esished, and how contracts determine actual monetary exchanges Any model of network innovation must therefore relate at least three distinct processes: innovation, competition, and routing. We select a game dynamics that makes the relation between these processes as explicit as possible. This is represented schematically in re 2 The innovation stage occurs first, at time 2 . In this stage, each agent decides whether or not to make research investments. If she chooses not to, her quality remains fixed. If she makes an investment, her quality may change in some way. It is not necessary for us to specify how such changes take place. The agents\" choices in this stage determine the vector of qualities, q, common knowledge for the rest of the game Next, at time 1 , agents participate in the competition stage, in which contracts are agreed upon. In today\"s industry, these contracts include prices for transit access, and peering agreements Since access is provided on a besffort basis, a transit agreement can simply be represented by its price. Other contracting systems we will explore will require more detail Finally, beginning at  , firms participate in the routing stage Other research has already employed repeated games to study routing, for example , . Repetition reveals interesting effects not visible in a single stage game, such as informal collusion to elevate prices in . We use a game in continuous time in order to study such properties. For example, we will later ask whether a player will maintain higher quality than her contracts require, in the hope of keeping her customer base or attracting future customers Our dynamics reflect the fact that ISPs make innovation decisions infrequently. Although real firms have multiple opportunities to innovate, each opportunity is followed by a substantial length of time in which qualities are fixed. The decision to invest focuses on how the firm\"s new quality will improve the contracts it can enter into. Hence, our model places innovation at the earliest stage, attempting to capture a single investment decision. Contracting decisions are made on an intermediate time scale, thus appearing next in the dynamics. Routing decisions are made very frequently, mainly to maximize immediate profit flows, so they appear in the last stage Because of this ordering, our model does not allow firms to route strategically to affect future innovation or contracting decisions. In opposition, Afergan and Wroclawski argue that contracts are formed in response to current traffic patterns, in a feedback loop  Although we are sympathetic to their observation, such an addition would make our analysis intrace. Our model is most realistic when contracting decisions are infrequent Throughout this paper, our solution concept will be a subgame perfect equilibrium (SPE). An SPE is a strategy point that is a Nash equilibrium when restricted to each subgame. Three important subgames have been labeled in re 2. The innovation game includes all three stages. The competition game includes only the competition stage and the routing stage. The routing game includes only the routing stage An SPE guarantees that players are forwarooking. This means, for example, that in the competition stage, firms must act rationally, maximizing their expected profits in the routing stage. They cannot carry out threats they made in the innovation stage if it lowers their expected payoff Our schematic already suggests that the routing game is crucial for promoting innovation. To support innovation, the competition game must somehow reward ISPs with high quality. But that means that the routing game must tend to route to nodes with high quality. If the routing game always selects the lowesost routes, for example, innovation will not be supported. We will support this observation with analysis later 2.2 The Routing Game The routing game proceeds in continuous time, with all players discounting by a common factor, r. The outputs from previous stages, q and the set of contracts, are treated as exogenous parameters for this game. For each time 0≥t , each node must select a next hop to route data to. Data flows across the resultant path, causing utility flow to S and D, and a flow cost to the nodes on the path, as described above. Payment flows are also created, based on the contracts in place Relating our game to the familiar repeated prisoners\" dilemma, imagine that we are trying to impose a high quality, but costly path As we argued loosely above, such paths must be sustainable in order to support innovation. Each ISP on the path tries to maximize her own payment, net of costs, so she may not want to cooperate with our plan. Rather, if she can find a way to save on costs, at the expense of the high quality we desire, she will be tempted to do so Innovation Game Competition Game Routing Game Innovation stage Competition stage Routing stageQualities (q) Contracts (prices) Profits t = -2 t = -1 t ∈ [ 0 , ) re 2: Game Dynamics 186 Analogously to the prisoners\" dilemma, we will call such a decision cheating. A little more formally, Cheating refers to any action that an ISP can take, contrary to some target strategy point that we are trying to impose, that enhances her immediate payoff, but compromises the quality of the data path One type of cheating relates to the data path. Each node on the path has to pay the next node to deliver its traffic. If the next node offers high quality transit, we may expect that a lower quality node will offer a lower price. Each node on the path will be tempted to route to a cheaper next hop, increasing her immediate profits, but lowering the path quality. We will call this type of action cheating in route Another possibility we can model, is that a node finds a way to save on its internal forwarding costs, at the expense of its own quality We will call this cheating internally to distinguish it from cheating in route. For example, a node might drop packets beyond the rate required for congestion control, in order to throttle back TCP flows and thus save on forwarding costs . Alternately, a node employing quality of service could give high priority packets a lower class of service, thus saving on resources and perhaps allowing itself to sell more high priority service If either cheating in route or cheating internally is profie, the specified path will not be an equilibrium. We assume that cheating can never be caught instantaneously. Rather, a cheater can always enjoy the payoff from cheating for some positive time, which we label 0t . This includes the time for other players to detect and react to the cheating. If the cheater has a contract which includes a customer locn period, 0t also includes the time until customers are allowed to switch to a new ISP. As we will see later, it is socially beneficial to decrease 0t , so such locn is detrimental to welfare 3. PATHOLOGIES OF A  LOWACCOUNTABILITY NETWORK In order to motivate an exploration of monitoring systems, we begin in this section by considering a network with a poor degree of accounlity, modeled after today\"s Internet. We will show how the lack of monitoring necessarily leads to poor routing and diminishes the rate of innovation. Thus, the network\"s lack of accounlity is a fundamental obstacle to resolving these pathologies 3.1 Accounlity in the Current Internet First, we reflect on what accounlity characteristics the present Internet has. Argyraki, et al., point out that end hosts are given minimal information about packet drops . Users know when drops occur, but not where they occur, nor why. Dropped packets may represent the innocent signaling of congestion, or, as we mentioned above, they may be a form of cheating internally. The problem is similar for other dimensions of quality, or in fact more acute. Finding an ISP that gives high priority packets a lower class of service, for example, is further complicated by the lack of even basic diagnostic tools In fact, it is similarly difficult to identify an ISP that cheats in route Huston notes that Internet traffic flows do not always correspond to routing information . An ISP may hand a packet off to a neighbor regardless of what routes that neighbor has advertised Furthermore, blocks of addresses are summarized together for distant hosts, so a destination may not even be resolvable until packets are forwarded closer One might argue that diagnostic tools like ping and traceroute can identify cheaters. Unfortunately, Argyraki, et al., explain that these tools only reveal whether probe packets are echoed, not the fate of past packets . Thus, for example, they are ineffective in detecting lorequency packet drops. Even more fundamentally, a sophisticated cheater can always spot diagnostic packets and give them special treatment As a further complication, a cheater may assume different aliases for diagnostic packets arriving over different routes. As we will see below, this gives the cheater a significant advantage in escaping punishment for bad behavior, even if the data path is otherwise observable 3.2 Modeling Loccounlity As the above evidence suggests, the current industry allows for very little insight into the behavior of the network. In this section, we attempt to capture this lack of accounlity in our model. We begin by defining a monitor, our model of the way that players receive external information about network behavior, A monitor is any distributed algorithmic mechanism that runs on the network graph, and outputs, to specific nodes, informational statements about current or past network behavior We assume that all external information about network behavior is mediated in this way. The accounlity properties of the Internet can be represented by the following monitors: E2E (End to End): A monitor that informs  about what the total path quality is at any time (this is the quality they experience) ROP (Rest of Path): A monitor that informs each node along the data path what the quality is for the rest of the path to the destination PRc (Packets Received): A monitor that tells nodes how much data they accept from each other, so that they can charge by volume. It is important to note, however, that this information is aggregated over many sourcestination pairs. Hence, for the sake of realism, it cannot be used to monitor what the data path is Players cannot measure the qualities of other, single nodes, just the rest of the path. Nodes cannot see the path past the next hop. This last assumption is stricter than needed for our results. The critical ingredient is that nodes cannot verify that the path avoids a specific hop. This holds, for example, if the path is generally visible, except nodes can use different aliases for different parents. Similar results also hold if alternate paths always converge after some integer number, m, of hops It is important to stress that E2E and ROP are not the contractible monitors we described in the introduction - they do not generate proofs. Thus, even though a player observes certain information, she generally cannot credibly share it with another player. For example, if a node after the first hop starts cheating, the first hop will detect the sudden drop in quality for the rest of the path, but the first hop cannot make the source believe this observation - the 187 source will suspect that the first hop was the cheater, and fabricated the claim against the rest of the path Typically, E2E and ROP are envisioned as algorithms that run on a single node, and listen for packet echoes. This is not the only way that they could be implemented, however; an alternate strategy is to aggregate quality measurements from multiple points in the network. These measurements can originate in other monitors, located at various ISPs. The monitor then includes the component monitors as well as whatever mechanisms are in place to motivate nodes to share information honestly as needed. For example, if the source has monitors that reveal the qualities of individual nodes, they could be combined with path information to create an ROP monitor Since we know that contracts only accept proofs as input, we can infer that payments in this environment can only depend on the number of packets exchanged between players. In other words, contracts are besffort. For the remainder of this section, we will assume that contracts are also linear - there is a constant payment flow so long as a node accepts data, and all conditions of the contract are met. Other, more complicated tariffs are also possible, and are typically used to generate locn. We believe that our parameter t0 is sufficient to describe locn effects, and we believe that the insights in this section apply equally to any tariffs that are bounded so that the routing game remains continuous at infinity Restricting attention to linear contracts allows us to represent some node i\"s contract by its price, pi Because we further know that nodes cannot observe the path after the next hop, we can infer that contracts exist only between neighboring nodes on the graph. We will call this arrangement of contracts bilateral. When a competition game exclusively uses bilateral contracts, we will call it a bilateral contract competition game We first focus on the routing game and ask whether a high quality route can be maintained, even when a low quality route is cheaper Recall that this is a requirement in order for nodes to have any incentive to innovate. If nodes tend to route to low price next hops, regardless of quality, we say that the network is commoditized. To measure this tendency, we define an index of commoditization as follows: For a node on the data path, i, define its quality premium, minppd ji −= , where pj is the flow payment to the next hop in equilibrium, and pmin is the price of the lowest cost next hop Definition: The index of commoditization, CI , is the average, over each node on the data path, i, of i\"s flow profit as a fraction of i\"s quality premium, ( ) ijii dpcp /−−  CI ranges from 0, when each node spends all of its potential profit on its quality premium, to infinite, when a node absorbs positive profit, but uses the lowest price next hop. A high value for CI implies that nodes are spending little of their money inflow on purchasing high quality for the rest of the path. As the next claim shows, this is exactly what happens as the path grows long: Claim 1. If the only monitors are E2E, ROP, and PRc, ∞→CI as ∞→n , where n is the number of nodes on the data path To show that this is true, we first need the following lemma, which will esish the difficulty of punishing nodes in the network First a bit of notation: Recall that a cheater can benefit from its actions for 00 >t before other players can react. When a node cheats, it can expect a higher profit flow, at least until it is caught and other players react, perhaps by diverting traffic. Let node i\"s normal profit flow be iπ , and her profit flow during cheating be some greater value, yi. We will call the ratio, iiy π/ , the temptation to cheat Lemma 1. If the only monitors are E2E, ROP, and PRc, the discounted time, −nt rt e 0 , needed to punish a cheater increases at least as fast as the product of the temptations to cheat along the data path, ∏ −− ≥ 0 0 pathdataon 0 t rt i i i t rt e y e n π  Corollary. If nodes share a minimum temptation to cheat,  , the discounted time needed to punish cheating increases at least exponentially in the length of the data path, n, −− ≥ 0 00 t rt nt rt e y e n π  Since it is the discounted time that increases exponentially, the actual time increases faster than exponentially. If n is so large that tn is undefined, the given path cannot be maintained in equilibrium Proof. The proof proceeds by induction on the number of nodes on the equilibrium data path, n. For  , there is a single node, say i By cheating, the node earns extra profit ( ) − − 0 0 t rt ii ey π . If node i is then punished until time 1t , the extra profit must be cancelled out by the lost profit between time 0t and 1t , −1 0 t t rt i eπ . A little manipulation gives −− = 01 00 t rt i i t rt e y e π , as required For 1>n , assume for induction that the claim holds for 1−n . The source does not know whether the cheater is the first hop, or after the first hop. Because the source does not know the data path after the first hop, it is unable to punish nodes beyond it. If it chooses a new first hop, it might not affect the rest of the data path. Because of this, the source must rely on the first hop to punish cheating nodes farther along the path. The first hop needs discounted time, ∏ −0 0 hopfirstafter t rt i i i e y π , to accomplish this by assumption. So the source must give the first hop this much discounted time in order to punish defectors further down the line (and the source will expect poor quality during this period) Next, the source must be protected against a first hop that cheats, and pretends that the problem is later in the path. The first hop can 188 do this for the full discounted time, ∏ −0 0 hopfirstafter t rt i i i e y π , so the source must punish the first hop long enough to remove the extra profit it can make. Following the same argument as for  , we can show that the full discounted time is ∏ −0 0 pathdataon t rt i i i e y π , which completes the proof The above lemma and its corollary show that punishing cheaters becomes more and more difficult as the data path grows long, until doing so is impossible. To capture some intuition behind this result, imagine that you are an end user, and you notice a sudden drop in service quality. If your data only travels through your access provider, you know it is that provider\"s fault. You can therefore take your business elsewhere, at least for some time. This threat should motivate your provider to maintain high quality Suppose, on the other hand, that your data traverses two providers When you complain to your ISP, he responds, yes, we know your quality went down, but it\"s not our fault, it\"s the next ISP. Give us some time to punish them and then normal quality will resume. If your access provider is telling the truth, you will want to listen, since switching access providers may not even route around the actual offender. Thus, you will have to accept lower quality service for some longer time. On the other hand, you may want to punish your access provider as well, in case he is lying. This means you have to wait longer to resume normal service. As more ISPs are added to the path, the time increases in a recursive fashion With this lemma in hand, we can return to prove Claim 1 Proof of Claim 1. Fix an equilibrium data path of length n. Label the path nodes 1,2,…,n. For each node i, let i\"s quality premium be \\'11 ++ −= iii ppd . Then we have, [ ] = − = − + + = − + ++ = + −=− −− −− = −− − = −− = n i i n i iii iii n i iii ii n i i iii C g npcp pcp n pcp pp nd pcp n I 1 1 1 1 1 1 1 1 1 11 1 1 1 1 1 \\'1 \\'11 ,  where gi is node i\"s temptation to cheat by routing to the lowest price next hop. Lemma 1 tells us that Tg n i i <∏ =1 , where ( )01 rt eT − −= . It requires a bit of calculus to show that IC is minimized by setting each gi equal to n T /1 . However, as ∞→n , we have  →n T , which shows that ∞→CI  According to the claim, as the data path grows long, it increasingly resembles a lowesrice path. Since lowesrice routing does not support innovation, we may speculate that innovation degrades with the length of the data path. Though we suspect stronger claims are possible, we can demonstrate one such result by including an extra assumption: Available Bargain Path: A competitive market exists for  lowcost transit, such that every node can route to the destination for no more than flow payment, lp  Claim 2. Under the available bargain path assumption, if node i , a distance n from S, can invest to alter its quality, and the source will spend no more than sP for a route including node i\"s new quality, then the payment to node i, p, decreases hyperbolically with n, ( ) ( ) s n l P n T pp 1 1/1 − +≤ − ,  where ( )01 rt eT − −= is the bound on the product of temptations from the previous claim. Thus, i will spend no more than ( ) ( )− + − s n l P n T p r 1 1 1/1 on this quality improvement, which approaches the bargain path\"s payment, r pl , as ∞→n  The proof is given in the appendix. As a node gets farther from the source, its maximum payment approaches the bargain price, pl Hence, the reward for innovation is bounded by the same amount Large innovations, meaning substantially more expensive than rpl / , will not be pursued deep into the network Claim 2 can alternately be viewed as a lower bound on how much it costs to elicit innovation in a network. If the source S wants node i to innovate, it needs to get a motivating payment, p, to i during the routing stage. However, it must also pay the nodes on the way to i a premium in order to motivate them to route properly. The claim shows that this premium increases with the distance to i, until it dwarfs the original payment, p Our claims stand in sharp contrast to our null hypothesis from the introduction. Comparing the intuitive argument that supported our hypothesis with these claims, we can see that we implicitly used an oversimplified model of market pressure (as either present or not) As is now clear, market pressure relies on the decisions of customers, but these are limited by the lack of information. Hence, competitive forces degrade as the network deepens 4. VERIFIABLE MONITORS In this section, we begin to introduce more accounlity into the network. Recall that in the previous section, we assumed that players couldn\"t convince each other of their private information What would happen if they could? If a monitor\"s informational signal can be credibly conveyed to others, we will call it a verifiable monitor. The monitor\"s output in this case can be thought of as a statement accompanied by a proof, a string that can be processed by any player to determine that the statement is true A verifiable monitor is a distributed algorithmic mechanism that runs on the network graph, and outputs, to specific nodes, proofs about current or past network behavior Along these lines, we can imagine verifiable counterparts to E2E and ROP. We will label these E2Ev and ROPv. With these monitors, each node observes the quality of the rest of the path and can also convince other players of these observations by giving them a proof 189 By adding verifiability to our monitors, identifying a single cheater is straightforward. The cheater is the node that cannot produce proof that the rest of path quality decreased. This means that the negative results of the previous section no longer hold. For example, the following lemma stands in contrast to Lemma 1 Lemma 2. With monitors E2Ev, ROPv, and PRc, and provided that the node before each potential cheater has an alternate next hop that isn\"t more expensive, it is possible to enforce any data path in SPE so long as the maximum temptation is less than what can be deterred in finite time, − ≤ 0 0 max 1 t rt er y π  Proof. This lemma follows because nodes can share proofs to identify who the cheater is. Only that node must be punished in equilibrium, and the preceding node does not lose any payoff in administering the punishment With this lemma in mind, it is easy to construct counterexamples to Claim 1 and Claim 2 in this new environment Unfortunately, there are at least four reasons not to be satisfied with this improved monitoring system. The first, and weakest reason is that the maximum temptation remains finite, causing some distortion in routes or payments. Each node along a route must extract some positive profit unless the next hop is also the cheapest Of course, if t0 is small, this effect is minimal The second, and more serious reason is that we have always given our source the ability to commit to any punishment. Real world users are less likely to act collectively, and may simply search for the best service currently offered. Since punishment phases are generally characterized by a drop in quality, real world ensers may take this opportunity to shop for a new access provider. This will make nodes less motivated to administer punishments The third reason is that Lemma 2 does not apply to cheating by coalitions. A coalition node may pretend to punish its successor, but instead enjoy a secret payment from the cheating node Alternately, a node may bribe its successor to cheat, if the punishment phase is profie, and so forth. The required discounted time for punishment may increase exponentially in the number of coalition members, just as in the previous section! The final reason not to accept this monitoring system is that when a cheater is punished, the path will often be routed around not just the offender, but around other nodes as well. Effectively, innocent nodes will be punished along with the guilty. In our abstract model, this doesn\"t cause trouble since the punishment falls off the equilibrium path. The effects are not so benign in the real world When ISPs lie in sequence along a data path, they contribute complementary services, and their relationship is vertical. From the perspective of other sourcestination pairs, however, these same firms are likely to be horizontal competitors. Because of this, a node might deliberately cheat, in order to trigger punishment for itself and its neighbors. By cheating, the node will save money to some extent, so the cheater is likely to emerge from the punishment phase better off than the innocent nodes. This may give the cheater a strategic advantage against its competitors. In the extreme, the cheater may use such a strategy to drive neighbors out of business, and thereby gain a monopoly on some routes 5. CONTRACTIBLE MONITORS At the end of the last section, we identified several drawbacks that persist in an environment with E2Ev, ROPv, and PRc. In this section, we will show how all of these drawbacks can be overcome To do this, we will require our third and final category of monitor: A contractible monitor is simply a verifiable monitor that generates proofs that can serve as input to a contract. Thus, contractible is jointly a property of the monitor and the institutions that must verify its proofs. Contractibility requires that a court, 1. Can verify the monitor\"s proofs 2. Can understand what the proofs and contracts represent to the extent required to police illegal activity 3. Can enforce payments among contracting parties Understanding the agreements between companies has traditionally been a matter of reading contracts on paper. This may prove to be a harder task in a future network setting. Contracts may plausibly be negotiated by machine, be numerous, even pelow, and be further complicated by the many dimensions of quality When a monitor (together with institutional infrastructure) meets these criteria, we will label it with a subscript c, for contractible The reader may recall that this is how we labeled the packets received monitor, PRc, which allows ISPs to form contracts with peacket payments. Similarly, E2Ec and ROPc are contractible versions of the monitors we are now familiar with At the end of the previous section, we argued for some desirable properties that we\"d like our solution to have. Briefly, we would like to enforce optimal data paths with an equilibrium concept that doesn\"t rely on routing for punishment, is coalition proof, and doesn\"t punish innocent nodes when a coalition cheats. We will call such an equilibrium a fixeoute coalitioroof  protect-theinnocent equilibrium As the next claim shows, ROPc allows us to create a system of linear (price, quality) contracts under just such an equilibrium Claim 3. With ROPc, for any feasible and consistent assignment of rest of path qualities to nodes, and any corresponding payment schedule that yields noegative payoffs, these qualities can be maintained with bilateral contracts in a fixeoute coalitioroof protect-the-innocent equilibrium Proof: Fix any data path consistent with the given rest of path qualities. Select some monetary punishment, P, large enough to prevent any cheating for time t0 (the discounted total payment from the source will work). Let each node on the path enter into a contract with its parent, which fixes an arbitrary payment schedule so long as the rest of path quality is as prescribed. When the parent node, which has ROPc, submits a proof that the rest of path quality is less than expected, the contract awards her an instantaneous transfer, P, from the downstream node. Such proofs can be submitted every 0t for the previous interval Suppose now that a coalition, C, decides to cheat. The source measures a decrease in quality, and according to her contract, is awarded P from the first hop. This means that there is a net outflow of P from the ISPs as a whole. Suppose that node i is not in C. In order for the parent node to claim P from i, it must submit proof that the quality of the path starting at i is not as prescribed. This means 190 that there is a cheater after i. Hence, i would also have detected a change in quality, so i can claim P from the next node on the path Thus, innocent nodes are not punished. The sequence of payments must end by the destination, so the net outflow of P must come from the nodes in C. This esishes all necessary conditions of the equilibrium Essentially, ROPc allows for an implementation of (price, quality) contracts. Building upon this result, we can construct competition games in which nodes offer various qualities to each other at specified prices, and can credibly commit to meet these performance targets, even allowing for coalitions and a desire to damage other ISPs Example 1. Define a Stackelberg pricuality competition game as follows: Extend the partial order of nodes induced by the graph to any complete ordering, such that downstream nodes appear before their parents. In this order, each node selects a contract to offer to its parents, consisting of a rest of path quality, and a linear price. In the routing game, each node selects a next hop at every time, consistent with its advertised rest of path quality. The Stackelberg pricuality competition game can be implemented in our model with ROPc monitors, by using the strategy in the proof, above. It has the following useful property: Claim 4. The Stackelberg pricuality competition game yields optimal routes in SPE The proof is given in the appendix. This property is favorable from an innovation perspective, since firms that invest in high quality will tend to fall on the optimal path, gaining positive payoff. In general, however, investments may be over or under rewarded. Extra conditions may be given under which innovation decisions approach perfect efficiency for large innovations. We omit the full analysis here Example 2. Alternately, we can imagine that players report their private information to a central authority, which then assigns all contracts. For example, contracts could be computed to implement the cosinimizing VCG mechanism proposed by Feigenbaum, et al. in . With ROPc monitors, we can adapt this mechanism to maximize welfare. For node, i, on the optimal path, L, the net payment must equal, essentially, its contribution to the welfare of S, D, and the other nodes. If L\" is an optimal path in the graph with i removed, the profit flow to i is, ( ) ( ) ∈≠∈ +−− \\', \\' Lj j ijLj jLL ccququ ,  where Lq and \\'Lq are the qualities of the two paths. Here, (price, quality) contracts ensure that nodes report their qualities honestly The incentive structure of the VCG mechanism is what motivates nodes to report their costs accurately A nice feature of this game is that individual innovation decisions are efficient, meaning that a node will invest in an innovation whenever the investment cost is less than the increased welfare of the optimal data path. Unfortunately, the source may end up paying more than the utility of the path Notice that with just E2Ec, a weaker version of Claim 3 holds Bilateral (price, quality) contracts can be maintained in an equilibrium that is fixeoute and coalitioroof, but not  protectthnnocent. This is done by writing contracts to punish everyone on the path when the end to end quality drops. If the path length is n, the first hop pays nP to the source, the second hop pays ( )Pn 1− to the first, and so forth. This ensures that every node is punished sufficiently to make cheating unprofie. For the reasons we gave previously, we believe that this solution concept is less than ideal, since it allows for malicious nodes to deliberately trigger punishments for potential competitors Up to this point, we have adopted fixeoute coalitioroof protechnnocent equilibrium as our desired solution concept, and shown that ROPc monitors are sufficient to create some competition games that are desirable in terms of service diversity and innovation. As the next claim will show, rest of path monitoring is also necessary to construct such games under our solution concept Before we proceed, what does it mean for a game to be desirable from the perspective of service diversity and innovation? We will use a very weak assumption, essentially, that the game is not fully commoditized for any node. The claim will hold for this entire class of games Definition: A competition game is nowherommoditized if for each node, i, not adjacent to D, there is some assignment of qualities and marginal costs to nodes, such that the optimal data path includes i, and i has a positive temptation to cheat In the case of linear contracts, it is sufficient to require that ∞<CI , and that every node make positive profit under some assignment of qualities and marginal costs Strictly speaking, ROPc monitors are not the only way to construct these desirable games. To prove the next claim, we must broaden our notion of rest of path monitoring to include the similar ROPc\" monitor, which attests to the quality starting at its own node, through the end of the path. Compare the two monitors below: ROPc: gives a node proof that the path quality from the next node to the destination is not correct ROPc\": gives a node proof that the path quality from that node to the destination is correct We present a simplified version of this claim, by including an assumption that only one node on the path can cheat at a time (though conspirators can still exchange side payments). We will discuss the full version after the proof Claim 5. Assume a set of monitors, and a nowherommoditized bilateral contract competition game that always maintains the optimal quality in fixeoute coalitioroof protechnnocent equilibrium, with only one node allowed to cheat at a time. Then for each node, i, not adjacent to D, either i has an ROPc monitor, or i\"s children each have an ROPc\" monitor Proof: First, because of the fixeoute assumption, punishments must be purely monetary Next, when cheating occurs, if the payment does not go to the source or destination, it may go to another coalition member, rendering it ineffective. Thus, the source must accept some monetary compensation, net of its normal flow payment, when cheating occurs. Since the source only contracts with the first hop, it must accept this money from the first hop. The source\"s contract must therefore distinguish when the path quality is normal from when it is lowered by cheating. To do so, it can either accept proofs 191 from the source, that the quality is lower than required, or it can accept proofs from the first hop, that the quality is correct. These nodes will not rationally offer the opposing type of proof By definition, any monitor that gives the source proof that the path quality is wrong is an ROPc monitor. Any monitor that gives the first hop proof that the quality is correct is a ROPc\" monitor. Thus, at least one of these monitors must exist By the protechnnocent assumption, if cheating occurs, but the first hop is not a cheater, she must be able to claim the same size reward from the next ISP on the path, and thus pass on the punishment. The first hop\"s contract with the second must then distinguish when cheating occurs after the first hop. By argument similar to that for the source, either the first hop has a ROPc monitor, or the second has a ROPc\" monitor. This argument can be iterated along the entire path to the penultimate node before D Since the marginal costs and qualities can be arranged to make any path the optimal path, these statements must hold for all nodes and their children, which completes the proof The two possibilities for monitor correspond to which node has the burden of proof. In one case, the prior node must prove the suboptimal quality to claim its reward. In the other, the subsequent node must prove that the quality was correct to avoid penalty Because the two monitors are similar, it seems likely that they require comparable costs to implement. If submitting the proofs is costly, it seems natural that nodes would prefer to use the ROPc monitor, placing the burden of proof on the upstream node Finally, we note that it is straightforward to derive the full version of the claim, which allows for multiple cheaters. The only complication is that cheaters can exchange side payments, which makes any money transfers between them redundant. Because of this, we have to further generalize our rest of path monitors, so they are less constrained in the case that there are cheaters on either side 5.1 Implementing Monitors Claim 5 should not be interpreted as a statement that each node must compute the rest of path quality locally, without input from other nodes. Other monitors, besides ROPc and ROPc\" can still be used, loosely speaking, as building blocks. For instance, network tomography is concerned with measuring properties of the network interior with tools located at the edge. Using such techniques, our source might learn both individual node qualities and the data path This is represented by the following two monitors: SHOPc i : (sourcased hop quality) A monitor that gives the source proof of what the quality of node i is SPATHc: (sourcased path) A monitor that gives the source proof of what the data path is at any time, at least as far as it matches the equilibrium path With these monitors, a punishment mechanism can be designed to fulfill the conditions of Claim 5. It involves the source sharing the proofs it generates with nodes further down the path, which use them to determine bilateral payments. Ultimately however, the proof of Claim 5 shows us that each node i\"s bilateral contracts require proof of the rest of path quality. This means that node i (or possibly its children) will have to combine the proofs that they receive to generate a proof of the rest of path quality. Thus, the combined process is itself a rest of path monitor What we have done, all in all, is constructed a rest of path monitor using SPATHc and SHOPc i as building blocks. Our new monitor includes both the component monitors and whatever distributed algorithmic mechanism exists to make sure nodes share their proofs correctly This mechanism can potentially involve external institutions. For a concrete example, suppose that when node i suspects it is getting poor rest of path quality from its successor, it takes the downstream node to court. During the discovery process, the court subpoenas proofs of the path and of node qualities from the source (ultimately, there must be some threat to ensure the source complies). Finally, for the court to issue a judgment, one party or the other must compile a proof of what the rest of path quality was. Hence, the entire discovery process acts as a rest of path monitor, albeit a rather costly monitor in this case Of course, mechanisms can be designed to combine these monitors at much lower cost. Typically, such mechanisms would call for automatic sharing of proofs, with court intervention only as a last resort. We defer these interesting mechanisms to future work As an aside, intuition might dictate that SHOPc i generates more information than ROPc; after all, inferring individual node qualities seems a much harder problem. Yet, without path information, SHOPc i is not sufficient for our firsest innovation result. The proof of this demonstrates a useful technique: Claim 6. With monitors E2E, ROP, SHOPc i and PRc, and a nowherommoditized bilateral contract competition game, the optimal quality cannot be maintained for all assignments of quality and marginal cost, in fixeoute coalitioroof  protect-theinnocent equilibrium Proof: Because nodes cannot verify the data path, they cannot form a proof of what the rest of path quality is. Hence, ROPc monitors do not exist, and therefore the requirements of Claim 5 cannot hold 6. CONCLUSIONS AND FUTURE WORK It is our hope that this study will have a positive impact in at least three different ways. The first is practical: we believe our analysis has implications for the design of future monitoring protocols and for public policy For protocol designers, we first provide fresh motivation to create monitoring systems. We have argued that the poor accounlity of the Internet is a fundamental obstacle to alleviating the pathologies of commoditization and lack of innovation. Unless accounlity improves, these pathologies are guaranteed to remain Secondly, we suggest directions for future advances in monitoring We have shown that adding verifiability to monitors allows for some improvements in the characteristics of competition. At the same time, this does not present a fully satisfying solution. This paper has suggested a novel standard for monitors to aspire to - one of supporting optimal routes in innovative competition games under fixeoute coalitioroof protechnnocent equilibrium. We have shown that under bilateral contracts, this specifically requires contractible rest of path monitors This is not to say that other types of monitors are unimportant. We included an example in which individual hop quality monitors and a path monitor can also meet our standard for sustaining competition However, in order for this to happen, a mechanism must be included 192 to combine proofs from these monitors to form a proof of rest of path quality. In other words, the monitors must ultimately be combined to form contractible rest of path monitors. To support service differentiation and innovation, it may be easier to design rest of path monitors directly, thereby avoiding the task of designing mechanisms for combining component monitors As far as policy implications, our analysis points to the need for legal institutions to enforce contracts based on quality. These institutions must be equipped to verify proofs of quality, and police illegal contracting behavior. As qualitased contracts become numerous and complicated, and possibly negotiated by machine, this may become a challenging task, and new standards and regulations may have to emerge in response. This remains an interesting and unexplored area for research The second area we hope our study will benefit is that of clealate architectural design. Traditionally, clealate design tends to focus on creating effective and elegant networks for a static set of requirements. Thus, the approach is often one of engineering, which tends to neglect competitive effects. We agree with Ratnasamy, Shenker, and McCanne, that designing for evolution should be a top priority . We have demonstrated that the network\"s monitoring ability is critical to supporting innovation, as are the institutions that support contracting. These elements should feature prominently in new designs. Our analysis specifically suggests that architectures based on bilateral contracts should include contractible rest of path monitoring. From a clealate perspective, these monitors can be transparently and fully integrated with the routing and contracting systems Finally, the last contribution our study makes is methodological We believe that the mathematical formalization we present is applicable to a variety of future research questions. While a significant literature addresses innovation in the presence of network effects, to the best of our knowledge, ours is the first model of innovation in a network industry that successfully incorporates the actual topological structure as input. This allows the discovery of new properties, such as the weakening of market forces with the number of ISPs on a data path that we observe with  lowaccountability Our method also stands in contrast to the typical approach of distributed algorithmic mechanism design. Because this field is based on a principlgent framework, contracts are usually proposed by the source, who is allowed to make a take it or leave it offer to network nodes. Our technique allows contracts to emerge from a competitive framework, so the source is limited to selecting the most desirable contract. We believe this is a closer reflection of the industry Based on the insights in this study, the possible directions for future research are numerous and exciting. To some degree, contracting based on quality opens a Pandora\"s Box of pressing questions: Do qualitased contracts stand counter to the principle of network neutrality? Should ISPs be allowed to offer a choice of contracts at different quality levels? What antompetitive behaviors are enabled by qualitased contracts? Can a contracting system support optimal multicast trees? In this study, we have focused on bilateral contracts. This system has seemed natural, especially since it is the prevalent system on the current network. Perhaps its most important benefit is that each contract is local in nature, so both parties share a common, familiar legal jurisdiction. There is no need to worry about who will enforce a punishment against another ISP on the opposite side of the planet, nor is there a dispute over whose legal rules to apply in interpreting a contract Although this benefit is compelling, it is worth considering other systems. The clearest alternative is to form a contract between the source and every node on the path. We may call these source contracts. Source contracting may present surprising advantages For instance, since ISPs do not exchange money with each other, an ISP cannot save money by selecting a cheaper next hop Additionally, if the source only has contracts with nodes on the intended path, other nodes won\"t even be willing to accept packets from this source since they won\"t receive compensation for carrying them. This combination seems to eliminate all temptation for a single cheater to cheat in route. Because of this and other encouraging features, we believe source contracts are a fertile topic for further study Another important research task is to relax our assumption that quality can be measured fully and precisely. One possibility is to assume that monitoring is only probabilistic or suffers from noise Even more relevant is the possibility that quality monitors are fundamentally incomplete. A quality monitor can never anticipate every dimension of quality that future applications will care about, nor can it anticipate a new and valuable protocol that an ISP introduces. We may define a monitor space as a subspace of the quality space that a monitor can measure, QM ⊂ , and a corresponding monitoring function that simply projects the full range of qualities onto the monitor space, MQm →:  Clearly, innovations that leave quality invariant under m are not easy to support - they are invisible to the monitoring system. In this environment, we expect that path monitoring becomes more important, since it is the only way to ensure data reaches certain innovator ISPs. Further research is needed to understand this process 7. ACKNOWLEDGEMENTS We would like to thank the anonymous reviewers, Jens Grossklags, Moshe Babaioff, Scott Shenker, Sylvia Ratnasamy, and Hal Varian for their comments. This work is supported in part by the National Science Foundation under ITR award AN331659', 'candidates': None, 'full-text': None, 'title': 'Network Monitors and Contracting Systems: Competition and Innovation', 'doc_id': 'C-62'}, {'abstract': None, 'full_text': 'Relaxed Online SVMs for Spam Filtering Spam is a key problem in electronic communication,  including largcale email systems and the growing number of blogs. Contenased filtering is one reliable method of  combating this threat in its various forms, but some academic researchers and industrial practitioners disagree on how best to filter spam. The former have advocated the use of  Support Vector Machines (SVMs) for contenased filtering, as this machine learning methodology gives stathrt performance for text classification. However, similar  performance gains have yet to be demonstrated for online spam filtering. Additionally, practitioners cite the high cost of SVMs as reason to prefer faster (if less statistically robust) Bayesian methods. In this paper, we offer a resolution to this controversy. First, we show that online SVMs indeed give stathrt classification performance on online spam filtering on large benchmark data sets. Second, we show that nearly equivalent performance may be achieved by a Relaxed Online SVM (ROSVM) at greatly reduced  computational cost. Our results are experimentally verified on email spam, blog spam, and splog detection tasks Electronic communication is increasingly plagued by  unwanted or harmful content known as spam. The most well known form of spam is email spam, which remains a major problem for large email systems. Other forms of spam are also becoming problematic, including blog spam, in which spammers post unwanted comments in blogs , and splogs, which are fake blogs constructed to enable link spam with the hope of boosting the measured importance of a given webpage in the eyes of automated search engines . There are a variety of methods for identifying these many forms of spam, including compiling blacklists of known spammers, and conducting link analysis The approach of content analysis has shown particular promise and generality for combating spam. In content  analysis, the actual message text (often including hypeext and metext, such as HTML and headers) is analyzed using machine learning techniques for text classification to  determine if the given content is spam. Content analysis has been widely applied in detecting email spam , and has also been used for identifying blog spam  and splogs  In this paper, we do not explore the related problem of link spam, which is currently best combated by link analysis  1.1 An Antpam Controversy The antpam community has been divided on the choice of the best machine learning method for contenased spam detection. Academic researchers have tended to favor the use of Support Vector Machines (SVMs), a statistically  robust machine learning method  which yields  statheart performance on general text classification . However, SVMs typically require training time that is quadratic in the number of training examples, and are impractical for  largescale email systems. Practitioners requiring contenased spam filtering have typically chosen to use the faster (if less statistically robust) machine learning method of Naive Bayes text classification . This Bayesian method requires only linear training time, and is easily implemented in an online setting with incremental updates. This allows a deployed system to easily adapt to a changing environment over time. Other fast methods for spam filtering include compression models  and logistic regression . It has not yet been empirically demonstrated that SVMs give  improved performance over these methods in an online spam detection setting  1.2 Contributions In this paper, we address the antpam controversy and offer a potential resolution. We first demonstrate that  online SVMs do indeed provide stathrt spam detection through empirical tests on several large benchmark data sets of email spam. We then analyze the effect of the tradeoff parameter in the SVM objective function, which shows that the expensive SVM methodology may, in fact, be overkill for spam detection. We reduce the computational cost of SVM learning by relaxing this requirement on the maximum  margin in online settings, and create a Relaxed Online SVM, ROSVM, appropriate for high performance contenased spam filtering in largcale settings 2. SPAM AND ONLINE SVMS The controversy between academics and practitioners in spam filtering centers on the use of SVMs. The former  advocate their use, but have yet to demonstrate strong  performance with SVMs on online spam filtering. Indeed, the results of  show that, when used with default parameters, SVMs actually perform worse than other methods. In this section, we review the basic workings of SVMs and describe a simple Online SVM algorithm. We then show that Online SVMs indeed achieve stathrt performance on  filtering email spam, blog comment spam, and splogs, so long as the tradeoff parameter C is set to a high value. However, the cost of Online SVMs turns out to be prohibitive for  largescale applications. These findings motivate our proposal of Relaxed Online SVMs in the following section 2.1 Background: SVMs SVMs are a robust machine learning methodology which has been shown to yield stathrt performance on text classification . by finding a hyperplane that separates two classes of data in data space while maximizing the  margin between them We use the following notation to describe SVMs, which draws from . A data set X contains n labeled example vectors {(x1, y1) . . . (xn, yn)}, where each xi is a vector  containing features describing example i, and each yi is the class label for that example. In spam detection, the classes spam and ham (i.e., not spam) are assigned the numerical class labels +1 and −1, respectively. The linear SVMs we employ in this paper use a hypothesis vector w and bias term b to classify a new example x, by generating a predicted class label f(x): f(x) = sign(< w, x > +b) SVMs find the hypothesis w, which defines the separating hyperplane, by minimizing the following objective function over all n training examples: τ(w, ξ) = 1 2 ||w||2 + C nX i=i ξi under the constraints that ∀i = {1..n} : yi(< w, xi > +b) ≥ 1 − ξi, ξi ≥ 0 In this objective function, each slack variable ξi shows the amount of error that the classifier makes on a given example xi. Minimizing the sum of the slack variables corresponds to minimizing the loss function on the training data, while minimizing the term 1 2 ||w||2 corresponds to maximizing the margin between the two classes . These two optimization goals are often in conflict; the tradeoff parameter C  determines how much importance to give each of these tasks Linear SVMs exploit data sparsity to classify a new  instance in O(s) time, where s is the number of noero  features. This is the same classification time as other linear Given: data set X = (x1, y1), . . . , (xn, yn), C, m: Initialize w := 0, b := 0, seenData := { } For Each xi ∈ X do: Classify xi using f(xi) = sign(< w, xi > +b) IF yif(xi) < 1 Find w , b using SMO on seenData, using w, b as seed hypothesis Add xi to seenData done re 1: Pseudo code for Online SVM classifiers, and as Naive Bayesian classification. Training SVMs, however, typically takes O(n2 ) time, for n training examples. A variant for linear SVMs was recently proposed which trains in O(ns) time , but because this method has a high constant, we do not explore it here 2.2 Online SVMs In many traditional machine learning applications, SVMs are applied in batch mode. That is, an SVM is trained on an entire set of training data, and is then tested on a  separate set of testing data. Spam filtering is typically tested and deployed in an online setting, which proceeds  incrementally. Here, the learner classifies a new example, is told if its prediction is correct, updates its hypothesis accordingly, and then awaits a new example. Online learning allows a deployed system to adapt itself in a changing environment Rraining an SVM from scratch on the entire set of  previously seen data for each new example is cost prohibitive However, using an old hypothesis as the starting point for rraining reduces this cost considerably. One method of  incremental and decremental SVM learning was proposed in . Because we are only concerned with incremental  learning, we apply a simpler algorithm for converting a batch SVM learner into an online SVM (see re 1 for  pseudocode), which is similar to the approach of  Each time the Online SVM encounters an example that was poorly classified, it retrains using the old hypothesis as a starting point. Note that due to the Karusuhucker (KKT) conditions, it is not necessary to rrain on  wellclassified examples that are outside the margins  We used Platt\"s SMO algorithm  as a core SVM solver, because it is an iterative method that is well suited to  converge quickly from a good initial hypothesis. Because  previous work (and our own initial testing) indicates that binary feature values give the best results for spam filtering [20, 9], we optimized our implementation of the Online SMO to exploit fast inneroducts with binary vectors. 1 2.3 Feature Mapping Spam Content Extracting machine learning features from text may be done in a variety of ways, especially when that text may include hypeontent and metontent such as HTML and header information. However, previous research has shown that simple methods from text classification, such as bag of words vectors, and overlapping characteevel rams, can achieve strong results . Formally, a bag of words  vector is a vector x with a unique dimension for each possible 1 Our source code is freely available at www.cs.tufts.edu/∼dsculley/onlineSMO 1 0.999 0.995 0.99 0.985 0.98 0.1 1 10 100 1000 ROCArea C 2-grams 3-grams 4-grams words re 2: Tuning the Tradeoff Parameter C. Tests were conducted with Online SMO, using binary  feature vectors, on the spamassassin data set of 6034 examples. Graph plots C versus Area under the ROC curve word, defined as a contiguous substring of nohitespace characters. An ram vector is a vector x with a unique dimension for each possible substring of n total characters Note that rams may include whitespace, and are  overlapping. We use binary feature scoring, which has been shown to be most effective for a variety of spam detection  methods . We normalize the vectors with the Euclidean norm. Furthermore, with email data, we reduce the impact of long messages (for example, with attachments) by  considering only the first 3,000 characters of each string. For blog comments and splogs, we consider the whole text,  including any metata such as HTML tags, as given. No other feature selection or domain knowledge was used 2.4 Tuning the Tradeoff Parameter, C The SVM tradeoff parameter C must be tuned to balance the (potentially conflicting) goals of maximizing the  margin and minimizing the training error. Early work on SVM based spam detection  showed that high values of C give best performance with binary features. Later work has not always followed this lead: a (low) default setting of C was used on splog detection , and also on email spam  Following standard machine learning practice, we tuned C on separate tuning data not used for later testing. We used the publicly available spamassassin email spam data set, and created an online learning task by randomly interleaving all 6034 labeled messages to create a single ordered set For tuning, we performed a coarse parameter search for C using powers of ten from .0001 to 10000. We used the Online SVM described above, and tested both binary bag of words vectors and ram vectors with n = {2, 3, 4}. We used the first 3000 characters of each message, which included header information, body of the email, and possibly attachments Following the recommendation of , we use Area under the ROC curve as our evaluation measure. The results (see re 2) agree with : there is a plateau of high  performance achieved with all values of C ≥ 10, and performance degrades sharply with C < 1. For the remainder of our  experiments with SVMs in this paper, we set C = 100. We will return to the observation that very high values of C do not degrade performance as support for the intuition that relaxed SVMs should perform well on spam e 1: Results for Email Spam filtering with  Online SVM on benchmark data sets. Score reported is (OCA)%, where 0 is optimal trec05p-1 trec06p OnSVM: words 0.015 (.01022) 0.034 (.02046) rams 0.011 (.00015) 0.025 (.01035) rams 0.008 (.00011) 0.023 (.01032) SpamProbe 0.059 (.04071) 0.092 (.07110) BogoFilter 0.048 (.03062) 0.077 (.05105) TREC Winners 0.019 (.01023) 0.054 (.03085) 5nsemble 0.007 (.00008) 0.020 (.00050) e 2: Results for Blog Comment Spam Detection using SVMs and Leave One Out Cross Validation We report the same performance measures as in the prior work for meaningful comparison accuracy precision recall SVM C = 100: words 0.931 0.946 0.954 rams 0.951 0.963 0.965 rams 0.949 0.967 0.956 Prior best method 0.83 0.874 0.874 2.5 Email Spam and Online SVMs With C tuned on a separate tuning set, we then tested the performance of Online SVMs in spam detection. We used two large benchmark data sets of email spam as our test corpora. These data sets are the 2005 TREC public data set trec05 of 92,189 messages, and the 2006 TREC public data sets, trec06p, containing 37,822 messages in English (We do not report our strong results on the trec06c corpus of Chinese messages as there have been questions raised over the validity of this test set.) We used the canonical ordering provided with each of these data sets for fair comparison Results for these experiments, with bag of words vectors and and ram vectors appear in e 1. To compare our results with previous scores on these data sets, we use the same (OCA)% measure described in , which is one  minus the area under the ROC curve, expressed as a percent This measure shows the percent chance of error made by a classifier asserting that one message is more likely to be spam than another. These results show that Online SVMs do give state of the art performance on email spam. The only known system that ouerforms the Online SVMs on the trec05 data set is a recent ensemble classifier which combines the results of 53 unique spam filters . To our knowledge, the Online SVM has ouerformed every other single filter on these data sets, including those using Bayesian methods , compression models , logistic regression , and perceptron variants , the TREC  competition winners , and open source email spam filters BogoFilter v1.1.5 and SpamProbe v1.4d 2.6 Blog Comment Spam and SVMs Blog comment spam is similar to email spam in many  regards, and contenased methods have been proposed for detecting these spam comments . However, large  benchmark data sets of labeled blog comment spam do not yet  exist. Thus, we run experiments on the only publicly available data set we know of, which was used in contenased blog e 3: Results for Splog vs. Blog Detection using SVMs and Leave One Out Cross Validation. We report the same evaluation measures as in the prior work for meaningful comparison features precision recall F1 SVM C = 100: words 0.921 0.870 0.895 rams 0.904 0.866 0.885 rams 0.928 0.876 0.901 Prior SVM with: words 0.887 0.864 0.875 rams 0.867 0.844 0.855 wordrls 0.893 0.869 0.881 comment spam detection experiments by . Because of the small size of the data set, and because prior researchers did not conduct their experiments in an oine setting, we test the performance of linear SVMs using leavnut cross validation, with SVight, a standard opeource SVM implementation . We use the parameter setting C = 100, with the same feature space mappings as above We report accuracy, precision, and recall to compare these to the results given on the same data set by . These results (see e 2) show that SVMs give superior performance on this data set to the prior methodology 2.7 Splogs and SVMs As with blog comment spam, there is not yet a large,  publicly available benchmark corpus of labeled splog detection test data. However, the authors of  kindly provided us with the labeled data set of 1,389 blogs and splogs that they used to test contenased splog detection using SVMs. The only difference between our methodology and that of  is that they used default parameters for C, which SVight sets to 1 avg||x||2 . (For normalized vectors, this default value sets C = 1.) They also tested several domainformed  feature mappings, such as giving special features to url tags For our experiments, we used the same feature mappings as above, and tested the effect of setting C = 100. As with the methodology of , we performed leave one out cross validation for applepples comparison on this data. The results (see e 3) show that a high value of C produces higher performance for the same feature space mappings, and even enables the simple ram mapping to ouerform the previous best mapping which incorporated domain  knowledge by using words and urls 2.8 Computational Cost The results presented in this section demonstrate that  linfeatures trec06p trec05 words 12196s 66478s rams 44605s 128924s rams 87519s 242160s corpus size 32822 92189 e 4: Execution time for Online SVMs with email spam detection, in CPU seconds. These times do not include the time spent mapping strings to  feature vectors. The number of examples in each data set is given in the last row as corpus size A B re 3: Visualizing the effect of C.  Hyperplane A maximizes the margin while accepting a small amount of training error. This corresponds to setting C to a low value. Hyperplane B  accepts a smaller margin in order to reduce  training error. This corresponds to setting C to a high value. Contenased spam filtering appears to do best with high values of C ear SVMs give state of the art performance on contenased spam filtering. However, this performance comes at a price Although the blog comment spam and splog data sets are too small for the quadratic training time of SVMs to  appear problematic, the email data sets are large enough to illustrate the problems of quadratic training cost e 4 shows computation time versus data set size for each of the online learning tasks (on same system). The training cost of SVMs are prohibitive for largcale content based spam detection, or a large blog host. In the  following section, we reduce this cost by relaxing the expensive requirements of SVMs', 'candidates': None, 'full-text': None, 'title': 'Relaxed Online SVMs for Spam Filtering', 'doc_id': 'H-37'}, {'abstract': None, 'full_text': 'Implementing Commitmenased Interactions∗ Although agent interaction plays a vital role in MAS, and  messagecentric approaches to agent interaction have their drawbacks, present agenriented programming languages do not provide support for implementing agent interaction that is flexible and robust. Instead, messages are provided as a primitive building block. In this  paper we consider one approach for modelling agent interactions: the commitment machines framework. This framework supports  modelling interactions at a higher level (using social commitments),  resulting in more flexible interactions. We investigate how  commitmentbased interactions can be implemented in conventional agenriented programming languages. The contributions of this paper are: a mapping from a commitment machine to a collection of BDtyle plans; extensions to the semantics of BDI programming languages; and an examination of two issues that arise when distributing  commitment machines (turn management and race conditions) and  solutions to these problems Agents are social, and agent interaction plays a vital role in  multiagent systems. Consequently, design and implementation of agent interaction is an important research topic The standard approach for designing agent interactions is  messagecentric: interactions are defined by interaction protocols that give the permissible sequences of messages, specified using notations such as finite state machines, Petri nets, or Agent UML It has been argued that this messagentric approach to  interaction design is not a good match for intelligent agents. Intelligent agents should exhibit the ability to persist in achieving their goals in the face of failure (robustness) by trying different approaches (flexibility). On the other hand, when following an interaction  protocol, an agent has limited flexibility and robustness: the ability to persistently try alternative means to achieving the interaction\"s aim is limited to those options that the protocol\"s designer provided, and in practice, messagentric design processes do not tend to lead to protocols that are flexible or robust Recognising these limitations of the traditional approach to  designing agent interactions, a number of approaches have been  proposed in recent years that move away from messagentric  interaction protocols, and instead consider designing agent interactions using higheevel concepts such as social commitments [8, 10, 18] or interaction goals . There has also been work on richer forms of interaction in specific settings, such as teams of  cooperative agents  However, although there has been work on designing flexible and robust agent interactions, there has been virtually no work on  providing programming language support for implementing such  interactions. Current Agent Oriented Programming Languages  (AOPLs) do not provide support for implementing flexible and robust agent interactions using higheevel concepts than messages.  Indeed, modern AOPLs , with virtually no exceptions, provide only simple message sending as the basis for implementing agent interaction This paper presents what, to the best of our knowledge, is the second AOPL to support higevel, flexible, and robust agent  interaction implementation. The first such language, STAPLE, was proposed a few years ago , but is not described in detail, and is arguably impractical for use by nopecialists, due to its logical basis and heavy reliance on temporal and modal logic This paper presents a scheme for extending BDike AOPLs to support direct implementation of agent interactions that are  designed using Yolum & Singh\"s commitment machine (CM)  framework . In the remainder of this paper we briefly review  commitment machines and present a simple abstraction of BDI AOPLs which lies in the common subset of languages such as Jason, 3APL, and CAN. We then present a scheme for translating commitment machines to this language, and indicate how the language needs to be extended to support this. We then extend our scheme to  address a range of issues concerned with distribution, including turn tracking , and race conditions 2. BACKGROUND 2.1 Commitment Machines The aim of the commitment machine framework is to allow for the definition of interactions that are more flexible than traditional messagentric approaches. A Commitment Machine (CM)  specifies an interaction between entities (e.g. agents, services,  processes) in terms of actions that change the interaction state. This interact state consists of fluents (predicates that change value over time), but also social commitments, both basevel and conditional A basevel social commitment is an undertaking by debtor A to creditor B to bring about condition p, denoted C(A, B, p). This is sometimes abbreviated to C(p), where it is not important to specify the identities of the entities in question. For example, a  commitment by customer C to merchant M to make the fluent paid true would be written as C(C, M, paid) A conditional social commitment is an undertaking by debtor A to creditor B that should condition q become true, A will then  commit to bringing about condition p. This is denoted by CC(A, B, q, p), and, where the identity of the entities involved is unimportant (or obvious), is abbreviated to CC(q p) where the arrow is a  reminder of the causal link between q becoming true and the creation of a commitment to make p true. For example, a commitment to make the fluent paid true once goods have been received would be written CC(goods paid) The semantics of commitments (both basevel and conditional) is defined with rules that specify how commitments change over time. For example, the commitment C(p) (or CC(q p)) is  discharged when p becomes true; and the commitment CC(q p) is replaced by C(p) when q becomes true. In this paper we use the more symmetric semantics proposed by  and subsequently  reformalised by . In brief, these semantics deal with a number of more complex cases, such as where commitments are created when conditions already hold: if p holds when CC(p q) is meant to be created, then C(q) is created instead of CC(p q) An interaction is defined by specifying the entities involved, the possible contents of the interaction state (both fluents and  commitments), and (most importantly) the actions that each entity can  perform along with the preconditions and effects of each action,  specified as add and delete lists A commitment machine (CM) defines a range of possible  interactions that each start in some state1 , and perform actions until reaching a final state. A final state is one that has no basevel commitments. One way of visualising the interactions that are  possible with a given commitment machine is to generate the finite state machine corresponding to the CM. For example, re 1 gives the FSM2 corresponding to the NetBill  commitment machine: a simple CM where a customer (C) and merchant (M) attempt to trade using the following actions3 : 1 Unlike standard interaction protocols, or finite state machines, there is no designated initial state for the interaction 2 The finite state machine is softwarenerated: the nodes and  connections were computed by an implementation of the axioms  (available from httww.winikoff.neM) and were then laid out by graphviz (httww.graphviz.or 3 We use the notation A(X) : P ⇒ E to indicate that action A is performed by entity X, has precondition P (with : P omitted if empty) and effect E • sendRequest(C) ⇒ request • sendQuote(M) ⇒ offer where offer ≡ promiseGoods ∧ promiseReceipt and promiseGoods ≡ CC(M, C, accept, goods) and promiseReceipt ≡ CC(M, C, pay, receipt) • sendAccept(C) ⇒ accept where accept ≡ CC(C, M, goods, pay) • sendGoods(M) ⇒ promiseReceipt ∧ goods where promiseReceipt ≡ CC(M, C, pay, receipt) • sendEPO(C) : goods ⇒ pay • sendReceipt(M) : pay ⇒ receipt The commitment accept is the customer\"s promise to pay once goods have been sent, promiseGoods is the merchant\"s promise to send the goods once the customer accepts, and promiseReceipt is the merchant\"s promise to send a receipt once payment has been made As seen in re 1, commitment machines can support a range of interaction sequences 2.2 An Abstract Agent ProgrammingLanguage Agent programming languages in the BDI tradition (e.g. dMARS, JAM, PRS, URS, JACK, AgentSpeak(L), Jason, 3APL, CAN, Jadex) define agent behaviour in terms of evenriggered plans, where each plan specifies what it is triggered by, under what  situations it can be considered to be applicable (defined using a salled context condition), and a plan body: a sequence of steps that can include posting events which in turn triggers further plans. Given a collection of plans and an event e that has been posted the agent first collects all plans types that are triggered by that event (the  relevant plans), then evaluates the context conditions of these plans to obtain a set of applicable plan instances. One of these is chosen and is executed We now briefly define the formal syntax and semantics of a  Simple Abstract (BDI) Agent Programming Language (SAAPL). This language is intended to be an abstraction that is in the common subset of such languages as Jason [1, Chapter 1], 3APL [1,  Chapter 2], and CAN . Thus, it is intentionally incomplete in some areas, for instance it doesn\"t commit to a particular mechanism for dealing with plan failure, since different mechanisms are used by different AOPLs An agent program (denoted by Π) consists of a collection of plan clauses of the form e : C ← P where e is an event, C is a context condition (a logical formula over the agent\"s beliefs), and P is the plan body. The plan body is built up from the following constructs We have the empty step which always succeeds and does nothing, operations to add ) and delete (−b) beliefs, sending a message m to agent N (↑N m), and posting an event4 (e). These can be sequenced (P; P) C  b | C ∧ C | C ∨ C | ¬C | ∃x.C P  | +b | −b | e | ↑N m | P; P Formal semantics for this language is given in re 2. This  semantics is based on the semantics for AgentSpeak given by , which in turn is based on the semantics for CAN . The  semantics is in the style of Plotkin\"s Structural Operational Semantics, and assumes that operations exist that check whether a condition 4 We use ↓N m as short hand for the event corresponding to  receiving message m from agent N 874 The Sixth Intl. Joint Conf. on Autonomous Agents and Multgent Systems (AAMAS 07) re 1: Finite State Machine for NetBill (shaded = final states) follows from a belief set, that add a belief to a belief set, and that delete a belief from a belief set. In the case of beliefs being a set of ground atoms these operations are respectively consequence  checking (B |= C), and set addition (B ∪ {b}) and deletion (B \\\\ {b}) More sophisticated belief management methods may be used, but are not considered here We define a basic conration S = Q, N, B, P where Q is a (global) message queue (modelled as a sequence5 where messages are added at one end and removed from the other end), N is the name of the agent, B is the beliefs of the agent and P is the plan body being executed (i.e. the intention). We also define an agent conration, where instead of a single plan body P there is a set of plan instances, Γ. Finally, a complete MAS is a pair Q, As of a global message queue Q and a set of agent conrations (without the queue, Q). The global message queue is a sequence of triplets of the form sendeecipienessage A transition S0 −→ S1 specifies that executing S0 a single step yields S1. We annotate the arrow with an indication of whether the conration in question is basic, an agent conration, or a MAS conration. The transition relation is defined using rules of the form S −→ S or of the form S −→ Sr S −→ Sr ; the latter are  conditional with the top (numerator) being the premise and the bottom (denominator) being the conclusion Note that there is noeterminism in SAAPL, e.g. the choice of plan to execute from a set of applicable plans. This is resolved by using selection functions: SO selects one of the applicable plan instances to handle a given event, SI selects which of the plan  instances that can be executed should be executed next, and SA  selects which agent should execute (a step) next 3. IMPLEMENTING COMMITMENASED INTERACTIONS In this section we present a mapping from a commitment  machine to a collection of SAAPL programs (one for each role). We begin by considering the simple case of two interacting agents, and 5 The + operator is used to denote sequence concatenation assume that the agents take turns to act. In section 4 we relax these assumptions Each action A(X) : P ⇒ E is mapped to a number of plans: there is a plan (for agent X) with context condition P that  performs the action (i.e. applies the effects E to the agent\"s beliefs) and sends a message to the other agent, and a plan (for the other agent) that updates its state when a message is received from X For example, given the action sendAccept(C) ⇒ accept we have the following plans, where each plan is preceded by M: or C: to indicate which agent that plan belongs to. Note that where the identify of the sender (respectively recipient) is obvious, i.e. the other agent, we abbreviate ↑N m to ↑m (resp. ↓N m to ↓m). Turn taking is captured through the event ı (short for interact): the agent that is active has an ı event that is being handled. Handling the event involves sending a message to the other agent, and then doing nothing until a response is received C: ı : true ← +accept; ↑sendAccept M: ↓sendAccept : true ← +accept; ı If the action has a norivial precondition then there are two plans in the recipient: one to perform the action (if possible), and another to report an error if the action\"s precondition doesn\"t hold (we  return to this in section 4). For example, the action sendReceipt(M) : pay ⇒ receipt generates the following plans: M: ı : pay ← +receipt; ↑sendReceipt C: ↓sendReceipt : pay ← +receipt; ı C: ↓sendReceipt : ¬pay ← . . . report error . . .  In addition to these plans, we also need plans to start and finish the interaction. An interaction can be completed whenever there are no basevel commitments, so both agents have the following plans: ı : ¬∃p.C(p) ← ↑done ↓done : ¬∃p.C(p) ←  ↓done : ∃p.C(p) ← . . . report error . . .  An interaction is started by setting up an agent\"s initial beliefs, and then having it begin to interact. Exactly how to do this depends on the agent platform: e.g. the agent platform in question may offer a simple way to load beliefs from a file. A generic approach that is a little cumbersome, but is pore, is to send each of the agents involved in the interaction a sequence of init messages, each The Sixth Intl. Joint Conf. on Autonomous Agents and Multgent Systems (AAMAS 07) 875 Q, N, B, +b Basic −→ Q, N, B ∪ {b}, Q, N, B, −b Basic −→ Q, N, B \\\\ {b}, Δ = {Piti : ci ← Pi) ∈ Π ∧ tiθ = e ∧ B |= ciθ} Q, N, B, e Basic −→ Q, N, B, SO(Δ) Q, N, B, P1 Basic −→ Q , N, B , P Q, N, B, P1; P2 Basic −→ Q , N, B , P ; P2 Q, N, B, ; P Basic −→ Q, N, B, P Q, N, B, ↑NB m Basic −→ Q + , N, B, Q = N + Q Q, N, B, Γ Agent −→ Q , N, B, Γ ∪ {↓NA m} P = SI(Γ) Q, N, B, P Basic −→ Q , N, B , P Q, N, B, Γ Agent −→ Q , N, B , (Γ \\\\ {P}) ∪ {P } P = SI(Γ) P = Q, N, B, Γ Agent −→ Q, N, B, (Γ \\\\ {P}) N, B, Γ = SA(As) Q, N, B, Γ Agent −→ Q , N, B , Γ Q, As MAS −→ Q , (As ∪ { N, B , Γ }) \\\\ { N, B, Γ } re 2: Operational Semantics for SAAPL containing a belief to be added; and then send one of the agents a start message which begins the interaction. Both agents thus have the following two plans: ↓init(B) : true ← +B ↓start : true ← ı re 3 gives the SAAPL programs for both merchant and  customer that implement the NetBill protocol. For conciseness the error reporting plans are omitted We now turn to refining the context conditions. There are three refinements that we consider. Firstly, we need to prevent  performing actions that have no effect on the interaction state. Secondly, an agent may want to specify that certain actions that it is able to perform should not be performed unless additional conditions hold For example, the customer may not want to agree to the merchant\"s offer unless the goods have a certain price or property. Thirdly, the context conditions of the plans that terminate the interaction need to be refined in order to avoid terminating the interaction prematurely For each plan of the form ı : P ← +E; ↑m we replace the  context condition P with the enhanced condition P ∧ P ∧ ¬E where P is any additional conditions that the agent wishes to impose, and ¬E is the negation of the effects of the action. For  example, the customer\"s payment plan becomes (assuming no additional conditions, i.e. no P ): ı : goods ∧ ¬pay ← +pay; ↑sendEPO For each plan of the form ↓m : P ← +E; ı we could add ¬E to the precondition, but this is redundant, since it is already checked by the performer of the action, and if the action has no effect then Customer\"s plans: ı : true ← +request; ↑sendRequest ı : true ← +accept; ↑sendAccept ı : goods ← +pay; ↑sendEPO ↓sendQuote : true ← +promiseGoods; +promiseReceipt; ı ↓sendGoods : true ← +promiseReceipt; +goods; ı ↓sendReceipt : pay ← +receipt; ı Merchant\"s plans: ı : true ← +promiseGoods; +promiseReceipt; ↑sendQuote ı : true ← +promiseReceipt; +goods; ↑sendGoods ı : pay ← +receipt; ↑sendReceipt ↓sendRequest : true ← +request; ı ↓sendAccept : true ← +accept; ı ↓sendEPO : goods ← +pay; ı Shared plans (i.e. plans of both agents): ı : ¬∃p.C(p) ← ↑done ↓done : ¬∃p.C(p) ←  ↓init(B) : true ← +B ↓start : true ← ı Where accept ≡ CC(goods pay) promiseGoods ≡ CC(accept goods) promiseReceipt ≡ CC(pay receipt) offer ≡ promiseGoods ∧ promiseReceipt re 3: SAAPL Implementation of NetBill the sender won\"t perform it and send the message (see also the  discussion in section 4) When specifying additional conditions (P ), some care needs to be taken to avoid situations where progress cannot be made because the only action(s) possible are prevented by additional conditions One way of indicating preference between actions (in many agent platforms) is to reorder the agent\"s plans. This is clearly safe, since actions are not prevented, just considered in a different order The third refinement of context conditions concerns the plans that terminate the interaction. In the Commitment Machine  framework any state that has no basevel commitment is final, in that the interaction may end there (or it may continue). However, only some of these final states are desirable final states. Which final states are considered to be desirable depends on the domain and the desired interaction outcome. In the NetBill example, the  desirable final state is one where the goods have been sent and paid for, and a receipt issued (i.e. goods ∧ pay ∧ receipt). In order to prevent an agent from terminating the interaction too early we add this as a precondition to the termination plan: ı : goods ∧ pay ∧ receipt ∧ ¬∃p.C(p) ← ↑done re 4 shows the plans that are changed from re 3 In order to support the realisation of CMs, we need to change SAAPL in a number of ways. These changes, which are discussed below, can be applied to existing BDI languages to make them commitment machine supportive. We present the three changes, explain what they involve, and for each change explain how the change was implemented using the 3APL agent oriented  programming language. The three changes are: 1. extending the beliefs of the agent so that they can contain commitments; 876 The Sixth Intl. Joint Conf. on Autonomous Agents and Multgent Systems (AAMAS 07) Customer\"s plans: ı : ¬request ← +request; ↑sendRequest ı : ¬accept ← +accept; ↑sendAccept ı : goods ∧ ¬pay ← +pay; ↑sendEPO Merchant\"s plans: ı : ¬offer ← +promiseGoods; +promiseReceipt; ↑sendQuote ı : ¬(promiseReceipt ∧ goods) ← +promiseReceipt; +goods; ↑sendGoods ı : pay ∧ ¬receipt ← +receipt; ↑sendReceipt Where accept ≡ CC(goods pay) promiseGoods ≡ CC(accept goods) promiseReceipt ≡ CC(pay receipt) offer ≡ promiseGoods ∧ promiseReceipt re 4: SAAPL Implementation of NetBill with refined  context conditions (changed plans only) 2. changing the definition of |= to encompass implied  commitments; and 3. whenever a belief is added, updating existing commitments, according to the rules of commitment dynamics Extending the notion of beliefs to encompass commitments in fact requires no change in agent platforms that are proloike and support terms as beliefs (e.g. Jason, 3APL, CAN). However, other agent platforms do require an extension. For example, JACK, which is an extension of Java, would require changes to support  commitments that can be nested. In the case of 3APL no change is needed to support this Whenever a context condition contains commitments,  determining whether the context condition is implied by the agent\"s beliefs (B |= C) needs to take into account the notion of implied  commitments . In brief, a commitment can be considered to follow from a belief set B if the commitment is in the belief set (C ∈ B), but also under other conditions. For example, a commitment to pay C(pay) can be considered to be implied by a belief set containing pay because the commitment may have held and been discharged when pay was made true. Similar rules apply for conditional  commitments. These rules, which were introduced in  were  subsequently rormalised in a simpler form by  resulting in the four inference rules in the bottom part of re 5 The change that needs to be made to SAAPL to support  commitment machine implementations is to extend the definition of |= to include these four rules. For 3APL this was realised by having each agent include the following Prolog clauses: holds(X) :- clause(X,true) holds(c(P)) :- holds(P) holds(c(P)) :- clause(cc(Q,P),true), holds(Q) holds(cc(_,Q)) :- holds(Q) holds(cc(_,Q)) :- holds(c(Q)) The first clause simply says that anything holds if it is in agent\"s beliefs (clause(X,true) is true if X is a fact). The  remaining four clauses correspond respectively to the inference rules C1, C2, CC1 and CC2. To use these rules we then modify context conditions in our program so that instead of writing, for  example, cc(m,c, pay, receipt) we write holds(cc(m,c, pay, receipt)) B = norm(B ∪ {b}) Q, N, B, +b −→ Q, N, B , function norm(B) B ← B for each b ∈ B do if b = C(p) ∧ B |= p then B ← B \\\\ {b} elseif b = CC(p q) then if B |= q then B ← B \\\\ {b} elseif B |= p then B ← (B \\\\ {b}) ∪ {C(q)} elseif B |= C(q) then B ← B \\\\ {b} endif endif endfor return B end function B |= P B |= C(P) C1 CC(Q P) ∈ B B |= Q B |= P C2 B |= CC(P Q) B |= Q CC1 B |= C(Q) B |= CC(P Q) CC2 re 5: New Operational Semantics The final change is to update commitments when a belief is added. Formally, this is done by modifying the semantic rule for belief addition so that it applies an algorithm to update  commitments. The modified rule and algorithm (which mirrors the  definition of norm in ) can be found in the top part of re 5 For 3APL this final change was achieved by manually inserting update() after updating beliefs, and defining the following rules for update(): update() <- c(P) AND holds(P) | {Deletec(P) ; update()}, update() <- cc(P,Q) AND holds(Q) | {Deletecc(P,Q) ; update()}, update() <- cc(P,Q) AND holds(P) | {Deletecc(P,Q) ; Addc(Q) ; update()}, update() <- cc(P,Q) AND holds(c(Q)) | {Deletecc(P,Q) ; update()}, update() <- true | Skip where Deletec and Deletecc delete respectively a basevel and conditional commitment, and Addc adds a basevel  commitment One aspect that doesn\"t require a change is linking commitments and actions. This is because commitments don\"t trigger actions  directly: they may trigger actions indirectly, but in general their effect is to prevent completion of an interaction while there are  outstanding (base level) commitments re 6 shows the message sequences from a number of runs of a 3APL implementation of the NetBill commitment machine6 . In order to illustrate the different possible interactions the code was modified so that each agent selected randomly from the actions that it could perform, and a number of runs were made with the customer as the initiator, and then with the merchant as the  initiator. There are other possible sequences of messages, not shown, 6 Source code is available from httww.winikoff.neM The Sixth Intl. Joint Conf. on Autonomous Agents and Multgent Systems (AAMAS 07) 877 re 6: Sample runs from 3APL implementation (alternating turns) including the obvious one: request, quote, accept, goods, payment, receipt, and then done One minor difference between the 3APL implementation and SAAPL concerns the semantics of messages. In the semantics of SAAPL (and of most AOPLs), receiving a message is treated as an event. However, in 3APL, receiving a message is modelled as the addition to the agent\"s beliefs of a fact indicating that the message was received . Thus in the 3APL implementation we have PG rules that are triggered by these beliefs, rather than by any event One issue with this approach is that the belief remains there, so we need to ensure that the belief in question is either deleted once  handled, or that we modify preconditions of plans to avoid handling it more than once. In our implementation we delete these received beliefs when they are handled, to avoid duplicate handling of  messages 4. BEYOND TWO PARTICIPANTS Generalising to more than two interaction participants requires revisiting how turn management is done, since it is no longer  possible to assume alternating turns  In fact, perhaps surprisingly, even in the two participant setting, an alternating turn setup is an unreasonable assumption! For  example, consider the path (in re 1) from state 1 to 15 (sendGoods) then to state 12 (sendAccept). The result, in an alternating turn setup, is a deand: there is only a single possible action in state 12, namely sendEPO, but this action is done by the customer, and it is the merchant\"s turn to act! re 7 shows the FSM for NetBill with alternating initiative A solution to this problem that works in this example, but doesn\"t generalise7 , is to weaken the alternating turn taking regime by  allowing an agent to act twice in a row if its second action is driven by a commitment A general solution is to track whose turn it is to act. This can be done by working out which agents have actions that are able to be performed in the current state. If there is only a single active agent, then it is clearly that agent\"s turn to act. However, if more than one agent is active then somehow the agents need to work out who should act next. Working this out by negotiation is not a particularly good solution for two reasons. Firstly, this negotiation has to be done at every step of the interaction where more than one agent is active (in the NetBill, this applies to seven out of sixteen states), so it is highly desirable to have a ligheight mechanism for doing this. Secondly, it is not clear how the negotiation can avoid an infinite regress situation (you go first, no, you go first, . ..) without imposing some arbitrary rule. It is also possible to resolve who should act by imposing an arbitrary rule, for example, that the customer always acts in preference to the merchant, or that each agent has a numerical priority (perhaps determined by the order in which they joined the interaction?) that determines who acts An alternative solution, which exploits the symmetrical  properties of commitment machines, is to not try and manage turn taking 7 Consider actions A1(C) ⇒ p, A2(C) ⇒ q, and A3(M) : p ∧ q ⇒ r re 7: NetBill with alternating initiative Instead of tracking and controlling whose turn it is, we simply allow the agents to act freely, and rely on the properties of the interaction space to ensure that things work out, a notion that we shall make precise, and prove, in the remainder of this section The issue with having multiple agents be active simultaneously is that instead of all agents agreeing on the current interaction state, agents can be in different states. This can be visualised as each agent having its own copy of the FSM that it navigates through where it is possible for agents to follow different paths through the FSM. The two specific issues that need to be addressed are: 1. Can agents end up in different final states? 2. Can an agent be in a position where an error occurs because it cannot perform an action corresponding to a received  message? We will show that, because actions commute under certain  assumptions, agents cannot end up in different final states, and  furthermore, that errors cannot occur (again, under certain  assumptions) By actions commute we mean that the state resulting from  performing a sequence of actions A1 . . . An is the same, regardless of the order in which the actions are performed. This means that even if agents take different paths through the FSM, they still end up in the same resulting state, because once all messages have been  processed, all agents will have performed the same set of actions. This addresses the issue of ending up in different final states. We return to the possibility of errors occurring shortly Definition 1 (Monotonicity) An action is monotonic if it does not delete8 any fluents or commitments. A Commitment Machine is 8 That is directly deletes, it is fine to discharge commitments by adding fluents/commitments 878 The Sixth Intl. Joint Conf. on Autonomous Agents and Multgent Systems (AAMAS 07) monotonic if all of its actions are monotonic. (Adapted from [14, Definition 6]) Theorem 1 If A1 and A2 are monotonic actions, then performing A1 followed by A2 has the same effect on the agent\"s beliefs as performing A2 followed by A1. (Adapted from [14, Theorem 2]) This assumes that both actions can be performed. However, it is possible for the performance of A1 to disable A2 from being done For example, if A1 has the effect +p, and A2 has precondition ¬p, then although both actions may be enabled in the initial state, they cannot be performed in either order. We can prevent this by ensuring that actions\" preconditions do not contain negation (or  implication), since a monotonic action cannot result in a precondition that is negatioree becoming false. Note that this restriction only applies to the original action precondition, P, not to any additional preconditions imposed by the agent (P ). This is because only P is used to determine whether another agent is able to perform the action Thus monotonic CMs with preconditions that do not contain negations have actions that commute. However, in fact, the  restriction to monotonic CMs is unnecessarily strong: all that is needed is that whenever there is a choice of agent that can act, then the possible actions are monotonic. If there is only a single agent that can act, then no restriction is needed on the actions: they may or may not be monotonic Definition 2 (Locally Monotonic) A commitment machine is  locally monotonic if for any state S either (a) only a single agent has actions that can be performed; or (b) all actions that can be performed in S are monotonic Theorem 2 In a locally monotonic CM, once all messages have been processed, all agents will be in the same state. Furthermore, no errors can occur Proof: Once all messages have been processed we have that all agents will have performed the same action set, perhaps in a  different order. The essence of the proof is to argue that as long as agents haven\"t yet converged to the same state, all actions must be monotonic, and hence that these actions commute, and cannot disable any other actions Consider the first point of divergence, where an agent performs action A and at the same time another agent (call it XB) performs action B. Clearly, this state has actions of more than one agent  enabled, so, since the CM is locally monotonic, the relevant actions must be monotonic. Therefore, after doing A, the action B must still be enabled, and so the message to do B can be processed by updating the recipient agent\"s beliefs with the effects of B.  Furthermore, because monotonic actions commute, the result of doing A before B is the same as doing B before A: S A −−−−−→ SA ? ? yB B ? ? y SB −−−−−→ A SAB However, what happens if the next action after A is not B, but C? Because B is enabled, and C is not done by agent XB (see below), we must have that C is also monotonic, and hence (a) the result of doing A and B and C is the same regardless of the order in which the three actions are done; and (b) C doesn\"t disable B, so B can still be done after C S A −−−−−→ SA C −−−−−→ SAC ? ? yB B ? ? y B ? ? y SB −−−−−→ A SAB −−−−−→ C SABC The reason why C cannot be done by XB is that messages are processed in the order of their arrival9 . From the perspective of XB the action B was done before C, and therefore from any other agent\"s perspective the message saying that B was done must be received (and processed) before a message saying that C is done This argument can be extended to show that once agents start taking different paths through the FSM all actions taken until the point where they converge on a single state must be monotonic, and hence it is always possible to converge (because actions aren\"t disabled), so the interaction is error free; and the resulting state once convergence occurs is the same (because monotonic actions commute) This theorem gives a strong theoretical guarantee that not  doing turn management will not lead to disaster. This is analogous to proving that disabling all traffic lights would not lead to any  accidents, and is only possible because the refined CM axioms are symmetrical Based on this theorem the generic transformation from CM to code should allow agents to act freely, which is achieved by simply changing ı : P ∧ P ∧ ¬E ← +E; ↑A to ı : P ∧ P ∧ ¬E ← +E; ↑A; ı For example, instead of ı : ¬request ← +request; ↑sendRequest we have ı : ¬request ← +request; ↑sendRequest; ı One consequence of the theorem is that it is not necessary to ensure that agents process messages before continuing to  interact. However, in order to avoid unnecessary parallelism, which can make debugging harder, it may still be desirable to process  messages before performing actions re 8 shows a number of runs from the 3APL implementation that has been modified to allow free, nolternating, interaction 5. DISCUSSION We have presented a scheme for mapping commitment machines to BDI platforms (using SAAPL as an exemplar), identified three changes that needed to be made to SAAPL to support Cased  interaction, and shown that turn management can be avoided in  CMbased interaction, provided the CM is locally monotonic. The three changes to SAAPL, and the translation scheme from commitment machine to BDI plans are both applicable to any BDI language As we have mentioned in section 1, there has been some work on designing flexible and robust agent interaction, but virtually no work on implementing flexible and robust interactions We have already discussed STAPLE . Another piece of work that is relevant is the work by Cheong and Winikoff on their Hermes methodology . Although the main focus of their work is a pragmatic design methodology, they also provide guidelines for implementing Hermes designs using BDI platforms (specifically Jadex) . However, since Hermes does not yield a design that is formal, it is only possible to generate skeleton code that then needs to be completed. Also, they do not address the turn taking issue: how to decide which agent acts when more than one agent is able to act 9 We also assume that the communication medium does not deliver messages out of order, which is the case for (e.g.) TCP The Sixth Intl. Joint Conf. on Autonomous Agents and Multgent Systems (AAMAS 07) 879 re 8: Sample runs from 3APL implementation (nolternating turns) The work of Kremer and Flores (e.g. ) also uses  commitments, and deals with implementation. However, they provide  infrastructure support (CASA) rather than a programming language, and do not appear to provide assistance to a programmer seeking to implement agents Although we have implemented the NetBill interaction using 3APL, the changes to the semantics were done by modifying our NetBill 3APL program, rather than by modifying the 3APL  implementation itself. Clearly, it would be desirable to modify the semantics of 3APL (or of another language) directly, by changing the implementation. Also, although we have not done so, it should be clear that the translation from a CM to its implementation could easily be automated Another area for further work is to look at how the assumptions required to ensure that actions commute can be relaxed Finally, there is a need to perform empirical evaluation. There has already been some work on comparing Hermes with a  conventional messagentric approach to designing interaction, and this has shown that using Hermes results in designs that are  significantly more flexible and robust . It would be interesting to compare commitment machines with Hermes, but, since  commitment machines are a framework, not a design methodology, we need to compare Hermes with a methodology for designing  interactions that results in commitment machines ', 'candidates': None, 'full-text': None, 'title': 'Implementing Commitmenased Interactions∗', 'doc_id': 'I-45'}, {'abstract': None, 'full_text': 'Applying Learning Algorithms to Preference Elicitation We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of  learning an unknown function from learning theory. We show that learning algorithms can be used as a basis for  preference elicitation algorithms. The resulting elicitation  algorithms perform a polynomial number of queries. We also give conditions under which the resulting algorithms have polynomial communication. Our conversion procedure  allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and lineahreshold functions. In particular, we obtain an  algorithm that elicits XOR bids with polynomial  communication In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone. Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be  problematic. Communicating valuations in a onhot fashion can be prohibitively expensive if the number of goods is only moderately large. Furthermore, it might even be hard for agents to determine their valuations for single bundles  It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors. These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal  allocation of goods There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from  computational learning theory . In learning theory, the goal is to learn a function via various types of queries, such as What is the function\"s value on these inputs? In  preference elicitation, the goal is to elicit enough partial  information about preferences to be able to compute an optimal allocation. Though the goals of learning and preference  elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other We show that any exact learning algorithm with  membership and equivalence queries can be converted into a  preference elicitation algorithm with value and demand queries The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries. Here we mean polynomial in the number of goods, agents, and the sizes of the agents\" valuation functions in a given  encoding scheme. Preference elicitation schemes have not  traditionally considered this last parameter. We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter. Introducing this parameter also allows us to guarantee polynomial worsase  communication, which usually cannot be achieved in the number of goods and agents alone. Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions Of course, a onhot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents\" valuations, and only require one query. The advantage of our scheme is that agents can be viewed as blacoxes that provide incremental information about their valuations There is no burden on the agents to formulate their  valuations in an encoding scheme of the auctioneer\"s choosing We expect this to be an important consideration in practice Also, with our scheme entire revelation only happens in the worst-case 180 For now, we leave the issue of incentives aside when  deriving elicitation algorithms. Our focus is on the time and communication complexity of preference elicitation  regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation Related work. Zinkevich et al.  consider the problem of learning restricted classes of valuation functions which can be represented using reance formulas and Toolbox DNF Reance formulas can represent certain substitulities, but no complementarities, whereas the opposite holds for Toolbox DNF. Since their work is also grounded in learning theory, they allow dependence on the size of the target  valuation as we do (though reance valuations can always be succinctly represented anyway). Their work only makes use of value queries, which are quite limited in power. Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions Blum et al.  provide results relating the complexities of query learning and preference elicitation. They consider models with membership and equivalence queries in query learning, and value and demand queries in preference  elicitation. They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vicersa In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning. We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a  solution to the elicitation problem Nisan and Segal  study the communication  complexity of preference elicitation. They show that for many rich classes of valuations, the worsase communication  complexity of computing an optimal allocation is exponential Their results apply to the blacox model of  computational complexity. In this model algorithms are allowed to ask questions about agent valuations and receive honest  responses, without any insight into how the agents internally compute their valuations. This is in fact the basic  framework of learning theory. Our work also addresses the issue of communication complexity, and we are able to derive  algorithms that provide significant communication guarantees despite Nisan and Segal\"s negative results. Their work  motivates the need to rely on the sizes of agents\" valuation functions in stating worsase results 2. THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin . In this model the learning  algorithm\"s objective is to exactly identify an unknown target function f : X → Y via queries to an oracle. The target function is drawn from a function class C that is known to the algorithm. Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê. As the algorithm progresses, it  constructs a manifest hypothesis ˜f which is its current estimate of the target function. Upon termination, the manifest  hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x  consists of m 1\"s, and f(x) = 0 otherwise. This function may simply be represented as a list of 2m values. Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct. The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm. Let size(f) be the size of the encoding of f with respect to the given representation class. Most  representation classes have a natural measure of encoding size. The size of a polynomial can be defined as the number of noero coefficients in the polynomial, for example. We will usually only refer to representation classes; the corresponding  function classes will be implied. For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions Two types of queries are commonly used for exact  learning: membership and equivalence queries. On a membership query, the learner presents some x ∈ X and the oracle replies with f(x). On an equivalence query, the learner presents its manifest hypothesis ˜f. The oracle either replies ‘YES\" if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x) An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented We are interested in efficient learning algorithms. The  following definitions are adapted from Kearns and Vazirani : Definition 1. The representation class C is  polynomialquery exactly learnable from membership and  equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence  queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x Similarly, the representation class C is efficiently  exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·) Here m is the dimension of the domain. Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f) 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be  allocated among a set of agents N so as to maximize the sum of the agents\" valuations. Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency. We let n = |N| and m = | An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations. Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles Each valuation vi is drawn from a known class of valuations Vi. The valuation classes do not need to coincide We will assume that all the valuations considered are  normalized, meaning v(∅) = 0, and that there are no  externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her). Valuations  satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasinear utility functions, meaning that agents\" utilities can be divided into monetary and noonetary components. If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p A valuation function may be viewed as a vector of 2m − 1 noegative reaalues. Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations . A classic example which we will refer to again later is the XOR bidding language In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value. To  determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ) As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied. For example, the XOR bidding language implies the class of  valuations satisfying freisposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B) We let size(v1, . . . , vn) = Èn  size(vi). That is, the size of a vector of valuations is the size of the concatenation of the valuations\" representations in their respective encoding schemes (bidding languages) To make an analogy to computational learning theory, we assume that all representation classes considered are  polynomially interpree , meaning that the value of a bundle may be computed in polynomial time given the valuation function\"s representation. More formally, a representation class (bidding language) C is polynomially interpree if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents\" valuation functions via various types of queries. She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made. They may also simply be default or random values if no information has been acquired about certain bundles. The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations. Note that we only require one such optimal allocation condition of freisposal (monotonicity), but we do not need it at this point 2 This excludes OR∗ , assuming P = NP, because  interpreting bids from this language is Nard by reduction from weighted seacking, and there is no weltudied  representation class in learning theory that is clearly analogous to OR∗  3 This view of iterative auctions is meant to parallel the learning setting. In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids Two typical queries used in preference elicitation are value and demand queries. On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) . On a demand query, the auctioneer presents a vector of noegative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds ‘YES\" if it is the case that S ∈ arg max S ⊆M \\xa0 v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a  better one .4 Note that we include ∅ as a bundle, so the agent will only respond ‘YES\" if its utility for the proposed bundle is noegative. Note also that communicating  nonlinear prices does not necessarily entail quoting a price for every possible bundle. There may be more succinct ways of communicating this vector, as we show in section 5 We make the following definitions to parallel the query learning setting and to simplify the statements of later  results: Definition 2. The representation classes V1, . . . , Vn can be polynomiauery elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an  algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an  allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si) Similarly, the representation class C can be efficiently elicited from value and demand queries if the  algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·) There are some key differences here with the query  learning definition. We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation. Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time. This reflects the fact that  communication rather than runtime is the bottleneck in elicitation Computing an optimal allocation of goods even when given the true valuations is Nard for a wide range of  valuation classes. It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm. We are happy to focus on the communication complexity of elicitation because this problem is widely  believed to be more significant in practice than that of winner determination .5 4 This differs slightly from the definition provided by Blum et al.  Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods. In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle. This is why the lower bound in their Theorem 2 does not contradict our result that follows 5 Though the winner determination problem is Nard for general valuations, there exist many algorithms that solve it efficiently in practice. These range from special  purpose algorithms  to approaches using ofhhelf IP solvers  182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting. Intuitively, this parameter is justified because we must learn valuations  exactly when performing elicitation, in the worsase. We address this in the next section 3. PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference  elicitation settings in a manner that highlights their similarities Value and membership queries are clear analogs. Slightly less obvious is the fact that equivalence and demand queries are also analogs. To see this, we need the concept of Lindahl prices. Lindahl prices are nonlinear and nononymous prices over the bundles. They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods. They are nononymous in the sense that two agents may face different prices for the same bundle of goods. Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N Lindahl prices are presented to the agents in demand  queries When agents have normalized quasinear utility  functions, Bikhchandani and Ostroy  show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal  allocation if and only if Si ∈ arg max Si \\xa0 vi(Si) − pi(Si) ¡ ∀i ∈ N  (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si)  Condition  states that each agent is allocated a bundle that maximizes its utility at the given prices. Condition  states that the allocation maximizes the auctioneer\"s  revenue at the given prices. The scenario in which these  conditions hold is called a Lindahl equilibrium, or often a  competitive equilibrium. We say that the Lindahl prices support the optimal allocation. It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral  The dual variables to this linear program are supporting Lindahl prices for the resulting allocation. The objective function to the dual program is: min pi(S) πs + i∈N πi  with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller There is usually a range of possible Lindahl prices  supporting a given optimal allocation. The agent\"s manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices. Out of all possible  vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire  social welfare. Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents\" utilities) are minimal Lindahl prices. Any Lindahl prices will do for our results, but some may have better elicitation  properties than others. Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent. We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi}  for all i ∈ N and S ⊆ M yields valid Lindahl prices. These prices leave every agent indifferent across all bundles with positive price, and satisfy condition . Thus demand  queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality . In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries Lemma 1. Suppose an agent replies with a preferred  bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agent\"s  manifest valuation). Then either ˜v(S) = v(S) or ˜v(S ) = v(S ) Proof. We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S)  v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S)  Inequality  holds because the prices support the proposed allocation with respect to the manifest valuation. Inequality  holds because the agent in fact prefers S to S given the prices, according to its response to the demand query. If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction. Thus at least one of S and S is a counterexample to the agent\"s manifest valuation Finally, we justify dependence on size(v1, . . . , vn) in  elicitation problems. Nisan and Segal (Proposition 1, ) and Parkes (Theorem 1, ) show that supporting Lindahl prices must necessarily be revealed in the course of any  preference elicitation protocol which terminates with an optimal allocation. Furthermore, Nisan and Segal (Lemma 1, ) state that in the worsase agents\" prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes). Since revealing Lindahl prices is a necessary condition for esishing an optimal allocation, and since Lindahl prices contain the same  information as valuation functions (in the worsase), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural 183 4. FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an  elicitation algorithm is to simulate equivalence queries with  demand and value queries until an optimal allocation is found Because of our Lindahl price construction, when all agents reply ‘YES\" to a demand query, we have found an optimal  allocation, analogous to the case where an agent replies ‘YES\" to an equivalence query when the target function has been exactly learned. Otherwise, we can obtain a  counterexample to an equivalence query given an agent\"s response to a demand query Theorem 1. The representation classes V1, . . . , Vn can be polynomiauery elicited from value and demand queries if they can each be polynomiauery exactly learned from membership and equivalence queries Proof. Consider the elicitation algorithm in re 1 Each membership query in step 1 is simulated with a value query since these are in fact identical. Consider step 4. If all agents reply ‘YES\", condition  holds. Condition  holds because the computed allocation is revenuaximizing for the auctioneer, regardless of the agents\" true valuations Thus an optimal allocation has been found. Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1 We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query This procedure will halt, since in the worsase all agent valuations will be learned exactly, in which case the  optimal allocation and Lindahl prices will be accepted by all agents. The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomiauery learning algorithms Note that the conversion procedure results in a  preference elicitation algorithm, not a learning algorithm. That is, the resulting algorithm does not simply learn the  valuations exactly, then compute an optimal allocation. Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough  information has been gathered by proposing an allocation to the agents through demand queries. It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an  allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents\" valuations have been exactly learned. The use of demand queries to simulate equivalence queries enables this early halting. We would not obtain this property with  equivalence queries based on manifest valuations 5. COMMUNICATION COMPLEXITY In this section, we turn to the issue of the  communication complexity of elicitation. Nisan and Segal  show that for a variety of rich valuation spaces (such as general and submodular valuations), the worsase communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is  measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn) Theorem 2. The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries Proof. The size of any value query is O(m): the  message consists solely of the queried bundle. To communicate Lindahl prices to agent i, it is sufficient to communicate the agent\"s manifest valuation function and the value πi, by equality . Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size,  because the algorithm\"s runtime would then also be  superpolynomial, contradicting efficiency. Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that uppeounds the runtime of the efficient learning algorithm. Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpree, and thus any value generated will be of polynomial size. We must also communicate to i its allocated bundle, so the total  message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m(m). Clearly, an agent\"s response to a value or demand query has size at most q(size(vi), m) + O(m). Thus the value and demand queries, and the  responses to these queries, are always of polynomial size. An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting  elicitation algorithm is polynomial in the relevant parameters There will often be explicit bounds on the number of  membership and equivalence queries performed by a learning  algorithm, with constants that are not masked by bi  notation. These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm. We uppeounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2. We are likely to be able to do much better than this in practice. Recall that an  equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made. If the learning algorithm\"s equivalence  queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the  resulting elicitation algorithm Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and  Segal\"s  negative results on the worsase communication complexity of efficient allocation problems. They provide guarantees with respect to the sizes of the instances of  valuation functions faced at any run of the algorithm. These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages. We consider these issues below 6. APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for  combinatorial valuations. We have shown that the preference  elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively Loop until there is a signal to halt: 1. Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agent\"s exact valuation 2. Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far 3. Present the allocation and prices to the agents in the form of a demand query 4. If they all reply ‘YES\", output the allocation and halt. Otherwise there is some agent i that has replied with some preferred bundle Si. Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai re 1: Converting learning algorithms to an elicitation algorithm to the problem of finding an efficient learning algorithm for each of these classes separately. This is significant because there already exist learning algorithms for a wealth of  function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the  preference elicitation problem directly. We can develop an  elicitation algorithm that is tailored to each agent\"s valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithndependent way We show that existing learning algorithms for  polynomials, monotone DNF formulae, and lineahreshold functions can be converted into preference elicitation algorithms for general valuations, valuations with freisposal, and  valuations with substitulities, respectively. We focus on representations that are polynomially interpree, because the computational learning theory literature places a heavy emphasis on computational traclity  In interpreting the methods we emphasize the  expressiveness and succinctness of each representation class. The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most  common functions in the class 6.1 Polynomial Representations Schapire and Sellie  give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol. The equivalence queries made by this algorithm are all proper. Specifically, their  algorithm learns the representation class of parse  multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1. A parse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4. A polynomial over the real numbers has coefficients drawn from the real numbers. Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial  To get an idea of the succinctness of polynomials as a bidding language, consider the additive and singltem  valuations presented by Nisan . In the additive valuation, the value of a bundle is the number of goods the bundle  contains. In the singltem valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item). It is not hard to show that the singltem valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation. Polynomials are thus appropriate for valuations that are mostly additive, with a few substitulities and complementarities that can be introduced by adjusting  coefficients The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti membership queries to an agent i, where ti is the sparcity of the polynomial representing vi . We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the  combinatorial auctions literature. Recall that an XOR bid is  characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the  valuation function: v(B) = max {B ∈B | B ⊆B} w(B )  XOR bids can represent valuations that satisfy freisposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B) The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy freisposal. However, XOR is as  expressive as required in most economic settings. Nisan  notes that XOR bids can represent the singltem valuation with m atomic bids, but 2m − 1 atomic bids are needed to  represent the additive valuation. Since the opposite holds for polynomials, these two languages are incomparable in  succinctness, and somewhat complementary for practical use Blum et al.  note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature. A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5. Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to reaalued functions. These insights allow us to generalize a classic learning algorithm for monotone DNF ( Theorem 6 Note that Theorem 1 applies even if valuations do not  satisfy free-disposal 185 1,  Theorem B) to a learning algorithm for XOR bids.7 Lemma 2. An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries Proof. The algorithm will identify each atomic bid in the target XOR bid in turn. Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids). Present ˜v as an  equivalence query. If the response is ‘YES\", we are done. Otherwise we obtain a bundle S for which v(S) = ˜v(S). Create a  bundle T as follows. First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}) If so set T = T − {i}. Otherwise leave T as is and proceed to the next item We claim that (T, v(T)) is an atomic bid of the target XOR bid. For each item i in T, we have v(T) = v(T − {i}) To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T. Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items. Now assume v(T) = v(T − {i}). Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts freisposal, since T − {i} ⊆ ¯T − {i} Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction. Assume that every atomic bid (R, ˜v(R))  identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)) This assumption holds vacuously when the manifest  valuation is initialized. Using the notation from , let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function. We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption. Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S)  Now assume v(T) = ˜v(T). Then, ˜v(T) = v(T) = v(S) = ˜v(S)  The second equality follows from the fact that the value remains constant when we derive T from S. The last  inequality holds because S is a counterexample to the  manifest valuation. From equation  and freisposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.\"s  elicitation algorithm for Toolbox DNF. Recall that Toolbox DNF are polynomials with noegative  coefficients. For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods have ˜v(T) < ˜v(S). Then again from equation  it  follows that v(S) < ˜v(S). This contradicts , so we in fact have v(T) = ˜v(T). Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis. We add (T, v(T)) to our hypothesis and repeat the process above,  performing additional equivalence queries until all atomic bids have been identified After each equivalence query, an atomic bid is identified with at most m membership queries. Each counterexample leads to the discovery of a new atomic bid. Thus we make at most tm membership queries and exactly t + 1 equivalence queries The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient. Applying Theorem 2, we therefore obtain the following corollary: Theorem 3. The representation class of XOR bids can be efficiently elicited from value and demand queries This contrasts with Blum et al.\"s negative results (,  Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods 6.3 Lineahreshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR, OOR, and OR∗ ) fail to succinctly represent the majority  valuation . In this valuation, bundles have value 1 if they contain at least  items, and value 0 otherwise. More  generally, consider the  family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise. The  majority valuation is a special case of the  valuation with r =  and S = M. These valuations are appropriate for representing substitulities: once a required set of items has been obtained, no other items can add value Letting k = | such valuations are succinctly represented by  threshold functions. These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise. Here i1, . . . , ik are the items in S. Littlestone\"s WINNOW 2 algorithm can learn such functions using  equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries . To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown. The elicitation algorithm that results from WINNOW 2 uses demand  queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values) Note that  threshold functions can always be  succinctly represented in O(m) space. Thus we obtain an  algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone 186 7. CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with  membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand  queries. At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries,  specialized to the problem of preference elicitation. Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation A learning approach to elicitation also motivates a  different approach to designing elicitation algorithms that  decomposes neatly across agent types. If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents\"  valuations and integrate them into an elicitation scheme. The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the  original learning algorithms are efficient We do not require that agent valuations can be learned with value and demand queries. Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed. This is the  preference elicitation problem. Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning  algorithms\" complexity. It would be interesting to find  examples of valuation classes for which elicitation is easier than learning. Blum et al.  provide such an example when considering membershialue queries only (Theorem 4) In future work we plan to address the issue of  incentives when converting learning algorithms to elicitation  algorithms. In the learning setting, we usually assume that oracles will provide honest responses to queries; in the  elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility We also plan to implement the algorithms for learning  polynomials and XOR bids as elicitation algorithms, and test their performance against other esished combinatorial auction protocols . An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation? We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence  queries. Finally, it would be useful to determine whether the OR∗ bidding language  can be efficiently learned (and hence elicited), given this language\"s expressiveness and  succinctness for a wide variety of valuation classes Acknowledgements We would like to thank Debasis Mishra for helpful  discussions. This work is supported in part by NSF grant  IIS0238147', 'candidates': None, 'full-text': None, 'title': 'Applying Learning Algorithms to Preference Elicitation', 'doc_id': 'J-72'}]\n"
     ]
    }
   ],
   "source": [
    "import glob, os, re\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from pandas import DataFrame\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "import Stemmer, string\n",
    "\n",
    "#train=glob.glob('./se_txt/train/dummy/small/*.txt.final')\n",
    "train=glob.glob('./se_txt/train/dummy/*.txt.final')\n",
    "\n",
    "def clean(input_list):\n",
    "    result=[]\n",
    "    trash=[]\n",
    "    legit=[]\n",
    "    for line in input_list:\n",
    "        clean=re.sub(\"(\\.)?\\n\",'', line) #remove \\n\n",
    "        #check if line only contains 2 words, is it exist on wordnet?\n",
    "        if len(word_tokenize(clean))<=2 and not wordnet.synsets(clean):\n",
    "            trash.append(clean)\n",
    "        elif len(word_tokenize(clean))==1:\n",
    "            trash.append(clean)\n",
    "        else:\n",
    "            clean=re.sub(\"\\S([\\=|\\+|\\-|\\:|\\*|\\/]\\S)+\",'', clean)\n",
    "            clean=re.sub(\"\\[([0-9]{1,2}\\,?\\s?)+\\]\",'', clean) #remove [2]\n",
    "            clean=re.sub(\"\\(([0-9]{1,2}\\,?\\s?)+\\)\",'', clean) #remove (2)\n",
    "            #remove fig. 2 etc, need improvement to catch the sentence after it\n",
    "            clean=re.sub(\"[[Ff]ig.|[Ff]igure|[Tt]ab.|[Tt]able]\\s?[0-9]{1,2}\",'', clean) #remove fig. 2 etc\n",
    "            legit.append(clean)\n",
    "        result.append(clean)\n",
    "    return result\n",
    "\n",
    "\n",
    "def merge(input_list):\n",
    "    merge=' '.join(input_list) #merge all elements into one element\n",
    "    '''\n",
    "    clean=re.sub(\"(\\.)?\\n\",' ', merge) #remove \\n\n",
    "    clean=re.sub(\"\\s{2,}\",' ', clean) #remove double or more whitespaces\n",
    "    clean=re.sub(\"(\\[([0-9]{1,2}\\,?\\s?)+\\])\",'', clean) #remove [2]\n",
    "    clean=re.sub(\"\\(([0-9]{1,2}\\,?\\s?)+\\)\",'', clean) #remove (2)\n",
    "    #remove fig. 2 etc, need improvement to catch the sentence after it\n",
    "    clean=re.sub(\"[[Ff]ig.|[Ff]igure|[Tt]ab.|[Tt]able]\\s?[0-9]{1,2}\",'', clean) #remove fig. 2 etc\n",
    "    #clean=re.sub(\"((https?\\:)?\\S+\\.(\\S+\\.){1,3})\",' ', clean) #remove link\n",
    "    #remove mathematic equation\n",
    "    #skip the header, next put header and separate it\n",
    "    \n",
    "    '''\n",
    "    return merge\n",
    "\n",
    "def stem(text):\n",
    "    stemmer=stemmer.stemmer('en')\n",
    "    return stemmer.stemWord(text)\n",
    "\n",
    "\n",
    "#def calculate_tdidf(input_list):\n",
    "    \n",
    "\n",
    "def load_files(path):\n",
    "    raw=[]\n",
    "    for file in path:\n",
    "        d_all={'doc_id': None, 'title': None, 'abstract': None, 'full-text': None, 'candidates': None}\n",
    "        file_id=os.path.basename(file).rstrip('.txt.final') #catch only file name  \n",
    "        source=open(file,encoding='utf-8').readlines()\n",
    "        source=clean(source)\n",
    "        \n",
    "        d_all['doc_id']=file_id\n",
    "        \n",
    "        ##########detect title\n",
    "        beginning=source[0] #retrieve title\n",
    "        candidate=source[1] # retrieve title candidate\n",
    "        h_candidate=word_tokenize(re.sub(\"-\",' ',candidate)) #tokenize the candidate\n",
    "        \n",
    "        title=[]\n",
    "        name=[]\n",
    "        for word in h_candidate:\n",
    "            if wordnet.synsets(word): #check if candidate exist on wordnet\n",
    "                title.append(word)\n",
    "            else:\n",
    "                name.append(word)\n",
    "            #if title>\n",
    "            if len(title)>len(name): \n",
    "                newtitle=beginning+' '+candidate\n",
    "            elif len(title)==len(name):\n",
    "                newtitle=beginning\n",
    "            else:\n",
    "                newtitle=beginning\n",
    "\n",
    "        d_all['title']=newtitle\n",
    "\n",
    "        ##################################\n",
    "        \n",
    "        content=source[2:]\n",
    "        ######check header, inconsistency all file\n",
    "        r_intro=re.compile(\"^1\\.?\\s[A-Z]+\")\n",
    "        r_ref=re.compile(\"[0-9]{1,2}?\\.?\\s?R[EFERENCES|eferences]\") #detect reference\n",
    "        #r_header=re.compile(\"[0-9]{1,2}?\\.?\\s?[A-Z]\")\n",
    "        \n",
    "        in_abstract=content.index('ABSTRACT')\n",
    "        in_authorkey=content.index('Categories and Subject Descriptors')\n",
    "        \n",
    "        list_intro=[i for i, item in enumerate(content) if re.search(r_intro, item)]\n",
    "        in_intro=list_intro[0]\n",
    "        list_ref=[i for i, item in enumerate(content) if re.search(r_ref, item)]\n",
    "        in_ref=list_ref[0]\n",
    "        \n",
    "        abstract=content[in_abstract+1:in_authorkey] #eliminate keyword and category\n",
    "        body=content[in_intro+1:in_ref] #remove reference       \n",
    "        \n",
    "        list_title=[]\n",
    "        list_title.append(newtitle)\n",
    "        \n",
    "        full_text=list(chain(list_title,abstract, body))\n",
    "        #d_all['abstract']=clean_merge(abstract)\n",
    "        #d_all['body']=clean_merge(body)\n",
    "        d_all['full_text']=merge(full_text)\n",
    "        \n",
    "        raw.append(d_all)\n",
    "    return raw\n",
    "\n",
    "def convert_tocorpus(raw_data):\n",
    "    #PUT STEMMER\n",
    "    \n",
    "    train_data=[]\n",
    "    for doc in raw_data:\n",
    "        train_data.append(doc['full_text'])\n",
    "    return train_data\n",
    "\n",
    "def calculate_tfidf(corpus):\n",
    "    import nltk.stem\n",
    "    english_stemmer=nltk.stem.SnowballStemmer('english')\n",
    "    \n",
    "    \n",
    "    #this code from https://stackoverflow.com/questions/26195699\n",
    "    #/sklearn-how-to-speed-up-a-vectorizer-eg-tfidfvectorizer\n",
    "    #english_stemmer=Stemmer.Stemmer('en')\n",
    "    class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "        \n",
    "        def build_analyzer(self):\n",
    "            analyzer=super(TfidfVectorizer, self).build_analyzer()\n",
    "            return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
    "            #return lambda doc: english_stemmer.stemWords(analyzer(doc))\n",
    "\n",
    "    tfidf=StemmedTfidfVectorizer(ngram_range=(1,5), stop_words='english')\n",
    "    tfidf_matrix=tfidf.fit_transform(corpus)\n",
    "\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "\n",
    "    #score tfidf per each feature\n",
    "    score=tfidf.idf_\n",
    "    result=dict(zip(feature_names, score))\n",
    "    \n",
    "    # uncomment for feature per document\n",
    "    vocab_perdoc=tfidf.inverse_transform(tfidf_matrix)\n",
    "    #create algorithm to parse it into each document, and save into pickle as candidates\n",
    "    \n",
    "    return vocab_perdoc\n",
    "    #return vocab_perdoc\n",
    "\n",
    "#def extract n_grams(corpus):\n",
    "#    punct=set(string.punctuation)\n",
    "#    stop_words=set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "print(load_files(train))\n",
    "#####pandas\n",
    "#l=load_files(train)\n",
    "#print(DataFrame(l).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "source=load_files(train)\n",
    "train_data=convert_tocorpus(source) #convert raw data into corpus\n",
    "\n",
    "tfidf_score=calculate_tfidf(train_data) #dictionary\n",
    "#print(tfidf_score)\n",
    "\n",
    "candidates=[]\n",
    "for doc in tfidf_score:\n",
    "    cand={}\n",
    "    for element in doc:\n",
    "        cand[element]=None\n",
    "    candidates.append(cand)\n",
    "\n",
    "print(candidates)\n",
    "#extract candidates\n",
    "#df=DataFrame.from_records(tfidf_score)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract n grams\n",
    "import textacy\n",
    "import spacy\n",
    "\n",
    "#nlp=spacy.load('en_core_web_sm')\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer=Lemmatizer()\n",
    "\n",
    "def extract_ngrams(corpus):\n",
    "    tokens=lemmatizer(corpus)\n",
    "    #doc=textacy.Corpus(spacy, docs=corpus)\n",
    "    #ngram=textacy.extract.ngrams(doc, 2, filter_stops=True, \n",
    "    #                             filter_punct=True, filter_nums=True, \n",
    "    #                            min_freq=1)\n",
    "    return ([token.lemma_ for token in tokens])\n",
    "\n",
    "\n",
    "candidate=extract_ngrams(train_data)\n",
    "print(list(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract n grams FAILED\n",
    "import textacy\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_sm\n",
    "\n",
    "#nlp=spacy.load('en_core_web_sm')\n",
    "nlp=en_core_web_sm.load()\n",
    "def extract_ngrams(corpus):\n",
    "    doc=textacy.Corpus(spacy, docs=corpus)\n",
    "    ngram=textacy.extract.ngrams(doc, 2, filter_stops=True, \n",
    "                                 filter_punct=True, filter_nums=True, \n",
    "                                min_freq=1)\n",
    "    return ngram\n",
    "\n",
    "\n",
    "candidate=extract_ngrams(train_data)\n",
    "print(list(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'challenging', 'problem', '!', 'faced', 'by', 'researchers', '#', 'and', 'developers', 'of', 'distributed', 'real-time', 'and', 'embedded', '(', 'DRE', ')', 'systems', 'is', 'devising', 'and', 'implementing', 'effective', 'adaptive', 'resource', 'management', 'strategies', 'that', 'can', 'meet', 'end-to-end', 'quality', 'of', 'service', '(', 'QoS', ')', 'requirements', 'in', 'varying', 'operational', 'conditions'], ['This', 'paper', 'presents', 'two', 'contributions', 'to', 'research', 'in', 'adaptive', 'resource', 'management', 'for', 'DRE', 'systems', '.'], ['Overutilization', 'of', 'these', 'system', 'resources', 'can', 'yield', 'unpredictable', 'and', 'unstable', 'behavior', ',', 'whereas', 'under-utilization', 'can', 'yield', 'excessive', 'system', 'cost', '.'], ['HyARM', 'is', 'based', 'on', 'hybrid', 'control', 'theoretic', 'techniques', '[', '8', ']', ',', 'which', 'provide', 'a', 'theoretical', 'framework', 'for', 'designing', 'control', 'of', 'complex', 'system', 'with', 'both', 'continuous', 'and', 'discretedynamics', '.']]\n",
      "[[('A', 'DT'), ('challenging', 'NN'), ('problem', 'NN'), ('!', '.'), ('faced', 'VBN'), ('by', 'IN'), ('researchers', 'NNS'), ('#', '#'), ('and', 'CC'), ('developers', 'NNS'), ('of', 'IN'), ('distributed', 'VBN'), ('real-time', 'NN'), ('and', 'CC'), ('embedded', 'VBD'), ('(', '('), ('DRE', 'NNP'), (')', ')'), ('systems', 'NNS'), ('is', 'VBZ'), ('devising', 'VBG'), ('and', 'CC'), ('implementing', 'VBG'), ('effective', 'JJ'), ('adaptive', 'JJ'), ('resource', 'NN'), ('management', 'NN'), ('strategies', 'NNS'), ('that', 'WDT'), ('can', 'MD'), ('meet', 'VB'), ('end-to-end', 'JJ'), ('quality', 'NN'), ('of', 'IN'), ('service', 'NN'), ('(', '('), ('QoS', 'NNP'), (')', ')'), ('requirements', 'NNS'), ('in', 'IN'), ('varying', 'VBG'), ('operational', 'JJ'), ('conditions', 'NNS')], [('This', 'DT'), ('paper', 'NN'), ('presents', 'VBZ'), ('two', 'CD'), ('contributions', 'NNS'), ('to', 'TO'), ('research', 'NN'), ('in', 'IN'), ('adaptive', 'JJ'), ('resource', 'NN'), ('management', 'NN'), ('for', 'IN'), ('DRE', 'NNP'), ('systems', 'NNS'), ('.', '.')], [('Overutilization', 'NN'), ('of', 'IN'), ('these', 'DT'), ('system', 'NN'), ('resources', 'NNS'), ('can', 'MD'), ('yield', 'VB'), ('unpredictable', 'JJ'), ('and', 'CC'), ('unstable', 'JJ'), ('behavior', 'NN'), (',', ','), ('whereas', 'IN'), ('under-utilization', 'NN'), ('can', 'MD'), ('yield', 'VB'), ('excessive', 'JJ'), ('system', 'NN'), ('cost', 'NN'), ('.', '.')], [('HyARM', 'NNP'), ('is', 'VBZ'), ('based', 'VBN'), ('on', 'IN'), ('hybrid', 'JJ'), ('control', 'NN'), ('theoretic', 'JJ'), ('techniques', 'NNS'), ('[', 'VBP'), ('8', 'CD'), (']', 'NN'), (',', ','), ('which', 'WDT'), ('provide', 'VBP'), ('a', 'DT'), ('theoretical', 'JJ'), ('framework', 'NN'), ('for', 'IN'), ('designing', 'VBG'), ('control', 'NN'), ('of', 'IN'), ('complex', 'JJ'), ('system', 'NN'), ('with', 'IN'), ('both', 'DT'), ('continuous', 'JJ'), ('and', 'CC'), ('discretedynamics', 'NNS'), ('.', '.')]]\n",
      "[('A', 'DT', 'O'), ('challenging', 'NN', 'B-NP'), ('problem', 'NN', 'I-NP'), ('!', '.', 'O'), ('faced', 'VBN', 'O'), ('by', 'IN', 'O'), ('researchers', 'NNS', 'B-NP'), ('#', '#', 'O'), ('and', 'CC', 'O'), ('developers', 'NNS', 'B-NP'), ('of', 'IN', 'O'), ('distributed', 'VBN', 'O'), ('real-time', 'NN', 'B-NP'), ('and', 'CC', 'O'), ('embedded', 'VBD', 'O'), ('(', '(', 'O'), ('DRE', 'NNP', 'B-NP'), (')', ')', 'O'), ('systems', 'NNS', 'B-NP'), ('is', 'VBZ', 'O'), ('devising', 'VBG', 'O'), ('and', 'CC', 'O'), ('implementing', 'VBG', 'O'), ('effective', 'JJ', 'B-NP'), ('adaptive', 'JJ', 'I-NP'), ('resource', 'NN', 'I-NP'), ('management', 'NN', 'I-NP'), ('strategies', 'NNS', 'I-NP'), ('that', 'WDT', 'O'), ('can', 'MD', 'O'), ('meet', 'VB', 'O'), ('end-to-end', 'JJ', 'B-NP'), ('quality', 'NN', 'I-NP'), ('of', 'IN', 'I-NP'), ('service', 'NN', 'I-NP'), ('(', '(', 'O'), ('QoS', 'NNP', 'B-NP'), (')', ')', 'O'), ('requirements', 'NNS', 'B-NP'), ('in', 'IN', 'O'), ('varying', 'VBG', 'O'), ('operational', 'JJ', 'B-NP'), ('conditions', 'NNS', 'I-NP'), ('This', 'DT', 'O'), ('paper', 'NN', 'B-NP'), ('presents', 'VBZ', 'O'), ('two', 'CD', 'O'), ('contributions', 'NNS', 'B-NP'), ('to', 'TO', 'O'), ('research', 'NN', 'B-NP'), ('in', 'IN', 'I-NP'), ('adaptive', 'JJ', 'I-NP'), ('resource', 'NN', 'I-NP'), ('management', 'NN', 'I-NP'), ('for', 'IN', 'O'), ('DRE', 'NNP', 'B-NP'), ('systems', 'NNS', 'I-NP'), ('.', '.', 'O'), ('Overutilization', 'NN', 'B-NP'), ('of', 'IN', 'O'), ('these', 'DT', 'O'), ('system', 'NN', 'B-NP'), ('resources', 'NNS', 'I-NP'), ('can', 'MD', 'O'), ('yield', 'VB', 'O'), ('unpredictable', 'JJ', 'O'), ('and', 'CC', 'O'), ('unstable', 'JJ', 'B-NP'), ('behavior', 'NN', 'I-NP'), (',', ',', 'O'), ('whereas', 'IN', 'O'), ('under-utilization', 'NN', 'B-NP'), ('can', 'MD', 'O'), ('yield', 'VB', 'O'), ('excessive', 'JJ', 'B-NP'), ('system', 'NN', 'I-NP'), ('cost', 'NN', 'I-NP'), ('.', '.', 'O'), ('HyARM', 'NNP', 'B-NP'), ('is', 'VBZ', 'O'), ('based', 'VBN', 'O'), ('on', 'IN', 'O'), ('hybrid', 'JJ', 'B-NP'), ('control', 'NN', 'I-NP'), ('theoretic', 'JJ', 'B-NP'), ('techniques', 'NNS', 'I-NP'), ('[', 'VBP', 'O'), ('8', 'CD', 'O'), (']', 'NN', 'B-NP'), (',', ',', 'O'), ('which', 'WDT', 'O'), ('provide', 'VBP', 'O'), ('a', 'DT', 'O'), ('theoretical', 'JJ', 'B-NP'), ('framework', 'NN', 'I-NP'), ('for', 'IN', 'O'), ('designing', 'VBG', 'O'), ('control', 'NN', 'B-NP'), ('of', 'IN', 'I-NP'), ('complex', 'JJ', 'I-NP'), ('system', 'NN', 'I-NP'), ('with', 'IN', 'O'), ('both', 'DT', 'O'), ('continuous', 'JJ', 'O'), ('and', 'CC', 'O'), ('discretedynamics', 'NNS', 'B-NP'), ('.', '.', 'O')]\n",
      "['challenging problem', 'researchers', 'developers', 'real-time', 'dre', 'systems', 'effective adaptive resource management strategies', 'end-to-end quality of service', 'qos', 'requirements', 'operational conditions', 'paper', 'contributions', 'research in adaptive resource management', 'dre systems', 'overutilization', 'system resources', 'unstable behavior', 'under-utilization', 'excessive system cost', 'hyarm', 'hybrid control theoretic techniques', ']', 'theoretical framework', 'control of complex system', 'discretedynamics']\n",
      "['challenging problem', 'researchers', 'developers', 'real-time', 'dre', 'systems', 'effective adaptive resource management strategies', 'end-to-end quality of service', 'qos', 'requirements', 'operational conditions', 'paper', 'contributions', 'research in adaptive resource management', 'dre systems', 'overutilization', 'system resources', 'unstable behavior', 'under-utilization', 'excessive system cost', 'hyarm', 'hybrid control theoretic techniques', 'theoretical framework', 'control of complex system', 'discretedynamics']\n"
     ]
    }
   ],
   "source": [
    "##learning\n",
    "#from http://bdewilde.github.io/blog/2014/09/23/intro-to-automatic-keyphrase-extraction/\n",
    "import itertools, nltk, string\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk import word_tokenize, pos_tag_sents\n",
    "from nltk.chunk import tree2conlltags\n",
    "\n",
    "#per sentence\n",
    "text=['A challenging problem! faced by researchers# and developers of distributed real-time and embedded (DRE) systems is  devising and implementing effective adaptive resource management strategies that can meet end-to-end quality of service (QoS) requirements in varying operational conditions'\n",
    "      ,'This paper presents two contributions to research in adaptive resource management for DRE systems.'\n",
    "      ,'Overutilization of these system resources can yield unpredictable and unstable behavior, whereas under-utilization can yield excessive system cost.'\n",
    "      ,'HyARM is based on hybrid control theoretic techniques [8], which provide a theoretical framework for designing control of complex system with both continuous and discretedynamics.'\n",
    "      ]\n",
    "\n",
    "#function for unpack lambda\n",
    "def lambda_unpack(f):\n",
    "    return lambda args:f(*args)\n",
    "\n",
    "#print(vocab_nounphrases(text))\n",
    "punct = set(string.punctuation) \n",
    "stop_words = set(stopwords.words('english'))\n",
    "grammar=r'NP: {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}' \n",
    "chunker = RegexpParser(grammar) #chunker from nltk\n",
    "postag_sents = pos_tag_sents(word_tokenize(sent) for sent in text)\n",
    "noun_phrases = list(chain.from_iterable(tree2conlltags(chunker.parse(tagged_sent)) for tagged_sent in postag_sents))\n",
    "merged_nounphrase = [' '.join(word for word, pos, chunk in group).lower() for key, group in\n",
    "                    itertools.groupby(noun_phrases, lambda_unpack(lambda word, pos, chunk: chunk != 'O')) if key]\n",
    "candidates=[cand for cand in merged_nounphrase\n",
    "            if cand not in stop_words and not all(char in punct for char in cand)]\n",
    "print(list(word_tokenize(sent) for sent in text))\n",
    "print(postag_sents)\n",
    "print(noun_phrases)\n",
    "print(merged_nounphrase)\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "training=load_files(train)\n",
    "with open('semeval_txt_dummy.pickle','wb') as handle:\n",
    "    pickle.dump(training, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('file has been stored on pickle')\n",
    "    \n",
    "for key, value in training.items():\n",
    "    print(value['title'])\n",
    "'''\n",
    "\n",
    "####convert to csv\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "with open('semeval_txt_dummy.pickle','rb') as handle:\n",
    "    training=pickle.load(handle)\n",
    "\n",
    "header=['id','text','title']\n",
    "\n",
    "with open(\"test.csv\",'wb') as f:\n",
    "    w=csv.DictWriter(f, header)\n",
    "    w.writeheader()\n",
    "    for k in training:\n",
    "        w.writerow({header: training[k].get(field) or k for field in header})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
