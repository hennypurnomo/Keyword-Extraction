{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, utils, preprocessing, generate_candidate \n",
    "import feature_extraction, generate_keyphrase\n",
    "from datetime import datetime\n",
    "\n",
    "number_keyphrase = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if these files are exist on pickle, please skip into next step\n",
    "#load gold keyphrase\n",
    "\n",
    "train_label_directory = open('./data/se_txt/train/train.combined.stem.final', \n",
    "                        encoding='utf-8').read()\n",
    "train_label = preprocessing.extract_keyphrase(train_label_directory)\n",
    "pickle_train_label = utils.create_pickle(train_label, './pickle/semeval/train label')\n",
    "\n",
    "test_label_directory = open('./data/se_txt/test_answer/test.combined.stem.final', \n",
    "                            encoding='utf-8').read()\n",
    "test_label = preprocessing.extract_keyphrase(test_label_directory)\n",
    "pickle_test_label = utils.create_pickle(test_label, './pickle/semeval/test label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run one time, if pickles have been available, please skip this step\n",
    "#this section is intended to create candidates, supervised keyphraseness\n",
    "\n",
    "#load train and test data\n",
    "train_directory = glob.glob('./data/se_txt/train/*.txt.final')\n",
    "train_raw = preprocessing.load_files(train_directory)\n",
    "pickle_train_raw = utils.create_pickle(train_raw,'./pickle/semeval/txt train raw')\n",
    "train_data = preprocessing.create_corpus(train_raw)\n",
    "pickle_train_data = utils.create_pickle(train_data,'./pickle/semeval/txt train data')\n",
    "train_tf_corpus = feature_extraction.calculate_tf(train_data, vocab = None, \n",
    "                    type = 'ngram')\n",
    "pickle_train_tf_corpus = utils.create_pickle(train_tf_corpus,\n",
    "                        './pickle/semeval/txt train tf corpus')\n",
    "\n",
    "test_directory = glob.glob('./data/se_txt/test/*.txt.final')\n",
    "test_raw = preprocessing.load_files(test_directory)\n",
    "pickle_test_raw = utils.create_pickle(test_raw,'./pickle/semeval/txt test raw')\n",
    "test_data = preprocessing.create_corpus(test_raw)\n",
    "pickle_test_data = utils.create_pickle(test_data,'./pickle/semeval/txt test data')\n",
    "test_tf_corpus = feature_extraction.calculate_tf(test_data, vocab = None, \n",
    "                    type = 'ngram')\n",
    "pickle_test_tf_corpus = utils.create_pickle(test_tf_corpus,\n",
    "                    './pickle/semeval/txt test tf corpus')\n",
    "\n",
    "\n",
    "#create candidates based on ngram for both training and testing\n",
    "ngram_candidates = generate_candidate.calculate_tfidf(train_data, vocab=None, \n",
    "                        type='ngram') \n",
    "pickle_ngram_candidates = utils.create_pickle(ngram_candidates,\n",
    "                            './pickle/semeval/txt ngram candidates')\n",
    "\n",
    "test_ngram_candidates = generate_candidate.calculate_tfidf(test_data, vocab=None, \n",
    "                            type='ngram')\n",
    "pickle_test_ngram_candidates = utils.create_pickle(test_ngram_candidates, \n",
    "                                './pickle/semeval/txt test ngram candidates')\n",
    "\n",
    "#create candidates based on noun phrase for both training and testing\n",
    "print(\"Noun phrase TF-IDF version\")\n",
    "nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(train_data)\n",
    "train_tf_nounphrase_corpus = feature_extraction.calculate_tf(train_data, \n",
    "                                vocab = nounphrase_vocabulary, type = 'np')\n",
    "pickle_train_tf_nounphrase_corpus = utils.create_pickle(train_tf_nounphrase_corpus,\n",
    "                                    './pickle/semeval/txt train tf new nounphrase corpus')\n",
    "nounphrase_candidates = generate_candidate.calculate_tfidf(train_data, \n",
    "                        nounphrase_vocabulary, type='np')\n",
    "pickle_nounphrase_candidates = utils.create_pickle(nounphrase_candidates, \n",
    "                                './pickle/semeval/txt nounphrase candidates')\n",
    "\n",
    "test_nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(test_data)\n",
    "test_tf_nounphrase_corpus = feature_extraction.calculate_tf(test_data, \n",
    "                            vocab = test_nounphrase_vocabulary, type = 'np')\n",
    "pickle_test_tf_nounphrase_corpus = utils.create_pickle(test_tf_nounphrase_corpus,\n",
    "                                    './pickle/semeval/txt test tf new nounphrase corpus')\n",
    "test_nounphrase_candidates = generate_candidate.calculate_tfidf(test_data, \n",
    "                                test_nounphrase_vocabulary, type='np')\n",
    "pickle_test_nounphrase_candidates = utils.create_pickle(test_nounphrase_candidates, \n",
    "                                        './pickle/semeval/txt test nounphrase candidates')\n",
    "\n",
    "#create dictionary of supervised_keyphraseness\n",
    "supervised_key = feature_extraction.create_supervised_list(train_label, train_tf_corpus)\n",
    "supervised_corpus = utils.create_pickle(supervised_key, './pickle/semeval/txt ngram supervised keyphraseness')\n",
    "\n",
    "np_supervised_key = feature_extraction.create_supervised_list(train_label, train_tf_nounphrase_corpus)\n",
    "np_supervised_corpus = utils.create_pickle(np_supervised_key, './pickle/semeval/txt np supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#open all relevant pickles\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('./pickle/semeval/txt train raw')\n",
    "train_data = utils.open_pickle('./pickle/semeval/txt train data')\n",
    "\n",
    "train_label = utils.open_pickle('./pickle/semeval/train label')\n",
    "train_tf_corpus = utils.open_pickle('./pickle/semeval/txt train tf corpus')\n",
    "train_tf_nounphrase_corpus = utils.open_pickle('./pickle/semeval/txt train tf nounphrase corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('./pickle/semeval/txt test raw')\n",
    "test_data = utils.open_pickle('./pickle/semeval/txt test data')\n",
    "\n",
    "test_label = utils.open_pickle('./pickle/semeval/test label')\n",
    "test_tf_corpus = utils.open_pickle('./pickle/semeval/txt test tf corpus')\n",
    "test_tf_nounphrase_corpus = utils.open_pickle('./pickle/semeval/txt test tf nounphrase corpus')\n",
    "\n",
    "train_topics = utils.open_pickle('./pickle/semeval/txt train topics')\n",
    "test_topics = utils.open_pickle('./pickle/semeval/txt test topics')\n",
    "\n",
    "ngram_candidates = utils.open_pickle('./pickle/semeval/txt ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('./pickle/semeval/txt test ngram candidates')\n",
    "\n",
    "nounphrase_candidates = utils.open_pickle('./pickle/semeval/txt nounphrase candidates')\n",
    "test_nounphrase_candidates = utils.open_pickle('./pickle/semeval/txt test nounphrase candidates')\n",
    "\n",
    "supervised_key = utils.open_pickle('./pickle/semeval/txt ngram supervised keyphraseness')\n",
    "np_supervised_key = utils.open_pickle('./pickle/semeval/txt np supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if training and testing data are available on csv folder, please skip this step\n",
    "#create examples on training and testing data\n",
    "\n",
    "print(\"creating ngram examples..\")\n",
    "\n",
    "ngram_train = feature_extraction.create_features(train_data, \n",
    "                                                 ngram_candidates, \n",
    "                                                 train_label,\n",
    "                                                 supervised_key,\n",
    "                                                 train_tf_corpus, \n",
    "                                                 train_topics, \n",
    "                                                 name='./csv/semeval/txt_train_ngram', \n",
    "                                                 n_keyphrase = number_keyphrase\n",
    "                                                 )\n",
    "\n",
    "ngram_test = feature_extraction.create_features(test_data, \n",
    "                                                test_ngram_candidates, \n",
    "                                                test_label, \n",
    "                                                supervised_key,\n",
    "                                                test_tf_corpus, \n",
    "                                                test_topics, \n",
    "                                                name='./csv/semeval/txt_test_ngram',\n",
    "                                                n_keyphrase = number_keyphrase\n",
    "                                                )\n",
    "\n",
    "print(\"creating noun phrase examples..\")\n",
    "\n",
    "nounphrase_train = feature_extraction.create_features( \n",
    "                                                train_data, \n",
    "                                                nounphrase_candidates, \n",
    "                                                train_label, \n",
    "                                                np_supervised_key,\n",
    "                                                train_tf_nounphrase_corpus, \n",
    "                                                train_topics,\n",
    "                                                name='./csv/semeval/txt_train_nounphrase',\n",
    "                                                n_keyphrase = number_keyphrase\n",
    "                                                )\n",
    "\n",
    "nounphrase_test = feature_extraction.create_features(\n",
    "                                                test_data, \n",
    "                                                test_nounphrase_candidates, \n",
    "                                                test_label,\n",
    "                                                np_supervised_key, \n",
    "                                                test_tf_nounphrase_corpus, \n",
    "                                                test_topics,\n",
    "                                                name='./csv/semeval/txt_test_nounphrase',\n",
    "                                                n_keyphrase = number_keyphrase\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#evaluation\n",
    "'''\n",
    "print(\"Evaluation on model - txt:\")\n",
    "ngram_prediction = generate_keyphrase.predict_data(test_ngram_candidates, \n",
    "                                                test_label, \n",
    "                                                train_data='./csv/semeval/txt_train_ngram', \n",
    "                                                test_data='./csv/semeval/txt_test_ngram',\n",
    "                                                n_keyphrase = number_keyphrase)\n",
    "print('Evaluation metric on ngram', ngram_prediction)\n",
    "'''\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates, \n",
    "                                        train_data='./csv/semeval/txt_train_ngram', \n",
    "                                        test_data='./csv/semeval/txt_test_ngram', \n",
    "                                        csv_name='./csv/semeval/txt predicted ngram keyphrases',\n",
    "                                        n_keyphrase = number_keyphrase)\n",
    "\n",
    "'''\n",
    "nounphrase_prediction = generate_keyphrase.predict_data(test_nounphrase_candidates, \n",
    "                                                test_label,\n",
    "                                                train_data='./csv/semeval/txt_train_nounphrase', \n",
    "                                                test_data='./csv/semeval/txt_test_nounphrase', \n",
    "                                                n_keyphrase = number_keyphrase)\n",
    "print('Evaluation metric on noun phrase', nounphrase_prediction)\n",
    "'''\n",
    "nounphrase_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(\n",
    "                                        test_nounphrase_candidates, \n",
    "                                        train_data='./csv/semeval/txt_train_nounphrase', \n",
    "                                        test_data='./csv/semeval/txt_test_nounphrase', \n",
    "                                        csv_name='./csv/semeval/txt predicted nounphrase keyphrases',\n",
    "                                        n_keyphrase = number_keyphrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model - cross validation\n",
    "\n",
    "ngram_prediction = generate_keyphrase.cross_validation( \n",
    "                train_label, train_data='./csv/semeval/xml_train_ngram' \n",
    "                )\n",
    "print(ngram_prediction)\n",
    "\n",
    "np_prediction = generate_keyphrase.cross_validation( \n",
    "                train_label, train_data='./csv/semeval/xml_train_nounphrase' \n",
    "                )\n",
    "print(np_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = generate_keyphrase.feature_selection(train_data='./csv/semeval/txt_train_ngram')\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = generate_keyphrase.feature_selection(train_data='./csv/semeval/txt_test_ngram')\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########testing topic rank \n",
    "import glob, utils, preprocessing, generate_candidate \n",
    "import generate_keyphrase, tr_feature_extraction\n",
    "from datetime import datetime\n",
    "\n",
    "number_keyphrase=15\n",
    "start = datetime.now()\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('./pickle/txt train raw')\n",
    "train_data = utils.open_pickle('./pickle/txt train data')\n",
    "\n",
    "train_label = utils.open_pickle('./pickle/train label')\n",
    "train_tf_corpus = utils.open_pickle('./pickle/txt train tf corpus')\n",
    "train_tf_nounphrase_corpus = utils.open_pickle('./pickle/txt train tf new nounphrase corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('./pickle/txt test raw')\n",
    "test_data = utils.open_pickle('./pickle/txt test data')\n",
    "\n",
    "test_label = utils.open_pickle('./pickle/test label')\n",
    "test_tf_corpus = utils.open_pickle('./pickle/txt test tf corpus')\n",
    "test_tf_nounphrase_corpus = utils.open_pickle('./pickle/txt test tf new nounphrase corpus')\n",
    "\n",
    "train_topics = utils.open_pickle('./pickle/txt train topics')\n",
    "test_topics = utils.open_pickle('./pickle/txt test topics')\n",
    "\n",
    "\n",
    "ngram_candidates = utils.open_pickle('./pickle/txt ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('./pickle/txt test ngram candidates')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "nounphrase_candidates = utils.open_pickle('./pickle/txt nounphrase candidates')\n",
    "test_nounphrase_candidates = utils.open_pickle('./pickle/txt test nounphrase candidates')\n",
    "\n",
    "ngram_train = tr_feature_extraction.create_features(train_raw, train_data, ngram_candidates, train_label, \n",
    "                                                   train_tf_corpus, train_topics, name='./csv/tr2_txt_train_ngram', \n",
    "                                                    n_keyphrase = number_keyphrase)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "print(\"creating example on testing\")\n",
    "\n",
    "ngram_test = tr_feature_extraction.create_features(test_raw, test_data, test_ngram_candidates, test_label, \n",
    "                                                  test_tf_corpus, test_topics, name='./csv/tr2_txt_test_ngram', \n",
    "                                                  n_keyphrase = number_keyphrase)\n",
    "print(\"time=\", datetime.now()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
