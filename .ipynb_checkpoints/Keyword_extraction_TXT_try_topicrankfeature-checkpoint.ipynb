{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, utils, preprocessing, generate_candidate, feature_extraction, keyphrase_extraction\n",
    "import special_features\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run one time\n",
    "#load train and test data\n",
    "train_directory = glob.glob('./se_txt/train/*.txt.final')\n",
    "train_raw = preprocessing.load_files(train_directory)\n",
    "pickle_train_raw = utils.create_pickle(train_raw,'txt train raw')\n",
    "train_data = preprocessing.create_corpus(train_raw)\n",
    "pickle_train_data = utils.create_pickle(train_data,'txt train data')\n",
    "train_tf_corpus = feature_extraction.calculate_tf(train_data, vocab = None, type = 'ngram')\n",
    "pickle_train_tf_corpus = utils.create_pickle(train_tf_corpus,'txt train tf corpus')\n",
    "\n",
    "test_directory = glob.glob('./se_txt/test/*.txt.final')\n",
    "test_raw = preprocessing.load_files(test_directory)\n",
    "pickle_test_raw = utils.create_pickle(test_raw,'txt test raw')\n",
    "test_data = preprocessing.create_corpus(test_raw)\n",
    "pickle_test_data = utils.create_pickle(test_data,'txt test data')\n",
    "test_tf_corpus = feature_extraction.calculate_tf(test_data, vocab = None, type = 'ngram')\n",
    "pickle_test_tf_corpus = utils.create_pickle(test_tf_corpus,'txt test tf corpus')\n",
    "\n",
    "#load gold keyphrase\n",
    "train_label_directory = open('./se_txt/train/train.combined.stem.final', encoding='utf-8').read()\n",
    "train_label = preprocessing.extract_keyphrase(train_label_directory)\n",
    "pickle_train_label = utils.create_pickle(train_label, 'train label')\n",
    "test_label_directory = open('./se_txt/test_answer/test.combined.stem.final', encoding='utf-8').read()\n",
    "test_label = preprocessing.extract_keyphrase(test_label_directory)\n",
    "pickle_test_label = utils.create_pickle(test_label, 'test label')\n",
    "\n",
    "train_reader_label_directory = open('./se_txt/train/train.reader.stem.final', encoding='utf-8').read()\n",
    "train_reader_label = preprocessing.extract_keyphrase(train_reader_label_directory)\n",
    "pickle_train_reader_label = utils.create_pickle(train_reader_label, 'train reader label')\n",
    "train_author_label_directory = open('./se_txt/train/train.author.stem.final', encoding='utf-8').read()\n",
    "train_author_label = preprocessing.extract_keyphrase(train_author_label_directory)\n",
    "pickle_train_author_label = utils.create_pickle(train_author_label, 'train author label')\n",
    "\n",
    "test_reader_label_directory = open('./se_txt/test_answer/test.reader.stem.final', encoding='utf-8').read()\n",
    "test_reader_label = preprocessing.extract_keyphrase(test_reader_label_directory)\n",
    "pickle_test_reader_label = utils.create_pickle(test_reader_label, 'test reader label')\n",
    "test_author_label_directory = open('./se_txt/test_answer/test.author.stem.final', encoding='utf-8').read()\n",
    "test_author_label = preprocessing.extract_keyphrase(test_author_label_directory)\n",
    "pickle_test_author_label = utils.create_pickle(test_author_label, 'test author label')\n",
    "\n",
    "\n",
    "#### Ngram version\n",
    "print(\"N-gram TF-IDF version\")\n",
    "'''\n",
    "ngram_candidates = generate_candidate.calculate_tfidf(train_data, vocab=None, type='ngram') \n",
    "pickle_ngram_candidates = utils.create_pickle(ngram_candidates, 'txt ngram candidates')\n",
    "#ngram_top_keyphrases = keyphrase_extraction.get_top_candidates(ngram_candidates, 15)\n",
    "#ngram_fmeasure = keyphrase_extraction.calculate_fmeasure(ngram_top_keyphrases, train_label)\n",
    "#print(\"F-measure on training:\", ngram_fmeasure)\n",
    "\n",
    "test_ngram_candidates = generate_candidate.calculate_tfidf(test_data, vocab=None, type='ngram')\n",
    "pickle_test_ngram_candidates = utils.create_pickle(test_ngram_candidates, 'txt test ngram candidates')\n",
    "#test_ngram_top_candidates = keyphrase_extraction.get_top_candidates(test_ngram_candidates, 15)\n",
    "#test_ngram_fmeasure = keyphrase_extraction.calculate_fmeasure(test_ngram_top_candidates, test_label)\n",
    "#print(\"F-measure on testing:\", test_ngram_fmeasure)\n",
    "'''\n",
    "\n",
    "#### Noun phrase version\n",
    "print(\"Noun phrase TF-IDF version\")\n",
    "nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(train_data)\n",
    "train_tf_nounphrase_corpus = feature_extraction.calculate_tf(train_data, vocab = nounphrase_vocabulary, type = 'np')\n",
    "pickle_train_tf_nounphrase_corpus = utils.create_pickle(train_tf_nounphrase_corpus,'txt train tf new nounphrase corpus')\n",
    "nounphrase_candidates = generate_candidate.calculate_tfidf(train_data, nounphrase_vocabulary, type='np')\n",
    "pickle_nounphrase_candidates = utils.create_pickle(nounphrase_candidates, 'txt nounphrase candidates')\n",
    "#nounphrase_top_keyphrases = keyphrase_extraction.get_top_candidates(nounphrase_candidates, 15)\n",
    "#nounphrase_fmeasure = keyphrase_extraction.calculate_fmeasure(nounphrase_top_keyphrases, train_label)\n",
    "#print(\"F-measure on training:\", nounphrase_fmeasure)\n",
    "\n",
    "test_nounphrase_vocabulary = generate_candidate.create_phrase_vocabulary(test_data)\n",
    "test_tf_nounphrase_corpus = feature_extraction.calculate_tf(test_data, vocab = test_nounphrase_vocabulary, type = 'np')\n",
    "pickle_test_tf_nounphrase_corpus = utils.create_pickle(test_tf_nounphrase_corpus,'txt test tf new nounphrase corpus')\n",
    "test_nounphrase_candidates = generate_candidate.calculate_tfidf(test_data, test_nounphrase_vocabulary, type='np')\n",
    "pickle_test_nounphrase_candidates = utils.create_pickle(test_nounphrase_candidates, 'txt test nounphrase candidates')\n",
    "#test_nounphrase_top_candidates = keyphrase_extraction.get_top_candidates(test_nounphrase_candidates, 15)\n",
    "#test_nounphrase_fmeasure = keyphrase_extraction.calculate_fmeasure(test_nounphrase_top_candidates, test_label)\n",
    "#print(\"F-measure on testing:\", test_nounphrase_fmeasure)\n",
    "\n",
    "###create topicrank per testing and training only one time only\n",
    "train_topic_rank = special_features.calculate_topic_rank(train_data)\n",
    "utils.create_pickle(train_topic_rank, 'txt train topic rank')\n",
    "test_topic_rank = special_features.calculate_topic_rank(test_data)\n",
    "utils.create_pickle(test_topic_rank, 'txt test topic rank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####with machine learning\n",
    "##NGRAM\n",
    "#open all pickle\n",
    "#this can be change\n",
    "number_keyphrase=15\n",
    "start = datetime.now()\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('txt train raw')\n",
    "train_data = utils.open_pickle('txt train data')\n",
    "\n",
    "train_label = utils.open_pickle('train label')\n",
    "train_tf_corpus = utils.open_pickle('txt train tf corpus')\n",
    "train_tf_nounphrase_corpus = utils.open_pickle('txt train tf new nounphrase corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('txt test raw')\n",
    "test_data = utils.open_pickle('txt test data')\n",
    "\n",
    "test_label = utils.open_pickle('test label')\n",
    "test_tf_corpus = utils.open_pickle('txt test tf corpus')\n",
    "test_tf_nounphrase_corpus = utils.open_pickle('txt test tf new nounphrase corpus')\n",
    "\n",
    "train_topic_rank = utils.open_pickle('txt train topic rank')\n",
    "test_topic_rank = utils.open_pickle('txt test topic rank')\n",
    "\n",
    "\n",
    "ngram_candidates = utils.open_pickle('txt ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('txt test ngram candidates')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "\n",
    "nounphrase_candidates = utils.open_pickle('txt nounphrase candidates')\n",
    "test_nounphrase_candidates = utils.open_pickle('txt test nounphrase candidates')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "\n",
    "#############temporary#############\n",
    "train_dpm_values = special_features.calculate_dpm(ngram_candidates)\n",
    "utils.create_pickle(train_dpm_values, 'txt train dpm values')\n",
    "test_dpm_values = special_features.calculate_dpm(ngram_candidates)\n",
    "utils.create_pickle(test_dpm_values, 'txt test dpm values')\n",
    "##################################\n",
    "\n",
    "train_dpm_values = utils.open_pickle('txt train dpm values')\n",
    "test_dpm_values = utils.open_pickle('txt test dpm values')\n",
    "\n",
    "\n",
    "print(\"creating example on training\")\n",
    "'''\n",
    "ngram_x_train = feature_extraction.create_features(train_raw, train_data, ngram_candidates, \n",
    "                train_label, train_tf_corpus, topic_rank='txt train topic rank', name='train_ngram', type='textfile')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(\"creating example on testing\")\n",
    "ngram_x_test = feature_extraction.create_features(test_raw, test_data, test_ngram_candidates, \n",
    "                test_label, test_tf_corpus, topic_rank='txt test topic rank', name='test_ngram', type='textfile')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "'''\n",
    "\n",
    "nounphrase_train = feature_extraction.create_features(train_raw, train_data, nounphrase_candidates, \n",
    "                    train_label, train_tf_nounphrase_corpus, topic_rank='txt train topic rank', name='train_nounphrase', \n",
    "                    type='textfile', n_keyphrase = number_keyphrase)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(\"creating data on testing\")\n",
    "nounphrase_test = feature_extraction.create_features(test_raw, test_data, test_nounphrase_candidates, \n",
    "                    test_label, test_tf_nounphrase_corpus, topic_rank='txt test topic rank', name='test_nounphrase', \n",
    "                    type='textfile', n_keyphrase = number_keyphrase)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "print(\"predicting the dataset\")\n",
    "'''\n",
    "ngram_prediction = keyphrase_extraction.predict_data(test_ngram_candidates, test_label, train_data='train_ngram', \n",
    "                    test_data='test_ngram', n_keyphrase = number_keyphrase)\n",
    "print('F-measure on ngram', ngram_prediction)\n",
    "ngram_prediction_keyphrase = keyphrase_extraction.get_predicted_keyphrases(test_ngram_candidates, \n",
    "                    train_data='train_ngram', test_data='test_ngram', csv_name='txt predicted ngram keyphrases', \n",
    "                    n_keyphrase = number_keyphrase)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "'''\n",
    "\n",
    "nounphrase_prediction = keyphrase_extraction.predict_data(test_nounphrase_candidates, test_label, \n",
    "                    train_data='train_nounphrase', test_data='test_nounphrase', n_keyphrase = number_keyphrase)\n",
    "print('F-measure on noun phrase', nounphrase_prediction)\n",
    "#nounphrase_prediction_keyphrase = keyphrase_extraction.get_predicted_keyphrases(test_nounphrase_candidates,\n",
    "#                    train_data='train_nounphrase', test_data='test_nounphrase', \n",
    "#                    csv_name='txt predicted nounphrase keyphrases', n_keyphrase = number_keyphrase)\n",
    "print(\"time=\", datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F-measure on noun phrase [('LR', (41.33, 41.01, 41.17)), ('LDA', (27.07, 26.85, 26.96)), \n",
    "                          ('NB', (15.67, 15.54, 15.6)), ('DT', (30.33, 30.09, 30.21)), \n",
    "                          ('RF', (47.07, 46.69, 46.88)), ('AdaBoost', (46.73, 46.36, 46.54)),\n",
    "                          ('Bagging', (46.07, 45.7, 45.88)), \n",
    "                          ('GradientBoosting', (46.33, 45.97, 46.15)), ('MLP', (30.67, 30.42, 30.54))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "x_train=[[1,2,3,4],[2,3,4,5],[5,6,7,8]]\n",
    "y_train=[1,0,1]\n",
    "x_test=[[4,2,3,4],[2,5,4,5],[5,2,7,8]]\n",
    "y_test=[1,0,1]\n",
    "\n",
    "predict_proba = AdaBoostClassifier(n_estimators = 70, learning_rate = 1.0).fit(x_train, y_train).predict_proba(x_test)[:,1]\n",
    "print(predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If need cross validation per model\n",
    "###measure accuracy with k-fold\n",
    "print(\"Accuracy on training data with Cross-validation:\")\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, x_train_ngram, y_train_ngram, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates=[[('aa',1),('a',5),('a3',5),('a6',7)],\n",
    "            [('aq',3),('aw',4),('ag',2),('ar',8)]]\n",
    "\n",
    "feature1=[[3,4,5,6],\n",
    "            [7,9,6,5]]\n",
    "feature2=[[1,2,7,8],\n",
    "            [9,90,4,3]]\n",
    "\n",
    "for n_doc in range(len(candidates)):\n",
    "    for n_candidate in range(len(candidates[n_doc])):\n",
    "        candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature1[n_doc][n_candidate],)\n",
    "        candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate],)\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=2.34\n",
    "r=3.35\n",
    "f=2.23\n",
    "print(\"precision: {}, recall: {}, fmeasure: {}\".format(p,r,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
