{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, re, string, itertools\n",
    "import xml.etree.ElementTree as et\n",
    "import pickle, json\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk.chunk import tree2conlltags\n",
    "from pandas import DataFrame\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def create_pickle(data, name):\n",
    "    with open('%s.pickle' % name,'wb') as handle:\n",
    "        result=pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return result\n",
    "\n",
    "def open_pickle(name):\n",
    "    with open('%s.pickle' % name,'rb') as handle:\n",
    "        result=pickle.load(handle)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleansing data..\n",
      "creating bigram..\n",
      "merging bigram to doc..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a corpus..\n",
      "[['svm', 'distanc', 'spam', 'detect', 'cluster', 'descriptor', 'onlin', 'video', 'sentenc', 'classifi', 'distanc_measur', 'qo', 'adapt', 'e-mail', 'train'], ['job', 'agent', 'execut', 'declar', 'event', 'action', 'activ', 'field', 'competit', 'ratio', 'releas', 'protocol', 'schedul', 'rule', 'cours'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['node', 'sensor', 'messag', 'protocol', 'record', 'rout', 'locat', 'contact', 'forward', 'wit', 'sensor_node', 'packet', 'payment', 'contract', 'princip'], ['node', 'sensor', 'messag', 'protocol', 'record', 'rout', 'locat', 'contact', 'forward', 'wit', 'sensor_node', 'packet', 'payment', 'contract', 'princip'], ['page', 'pagerank', 'vector', 'graph', 'web', 'error', 'node', 'local', 'link', 'global', 'heat', 'player', 'export', 'sender', 'crawl'], ['site', 'local', 'inconsist', 'delay', 'entiti', 'execut', 'lag', 'opportun', 'transmiss', 'propag', 'remot', 'game', 'state_updat', 'opportun_cost', 'enabl'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['sensor', 'locat', 'attribut', 'core', 'estim', 'detect', 'trajectori', 'shot', 'weapon', 'error', 'fusion', 'aggreg', 'member', 'accuraci', 'shooter'], ['execut', 'link', 'activ', 'web', 'web_page', 'content', 'page', 'matrix', 'classif', 'grid', 'manag', 'machin', 'element', 'infrastructur', 'coordin'], ['agent', 'congest', 'profil', 'game', 'pure', 'strategi_profil', 'failur', 'nash', 'equilibrium', 'pure_strategi', 'finit', 'subset', 'equilibria', 'profit', 'lemma'], ['aggreg', 'node', 'attribut', 'probe', 'tree', 'dht', 'aggreg_valu', 'instal', 'key', 'propag', 'scalabl', 'aggreg_function', 'rout', 'flexibl', 'root'], ['server', 'game', 'client', 'player', 'proxi', 'architectur', 'author', 'region', 'movement', 'respons', 'commun_proxi', 'latenc', 'maintain', 'connect', 'action'], ['agent', 'negoti', 'argument', 'offer', 'node', 'path', 'monitor', 'qualiti', 'contract', 'dialogu', 'accept', 'player', 'protocol', 'proof', 'rout'], ['sensor', 'locat', 'attribut', 'core', 'estim', 'detect', 'trajectori', 'shot', 'weapon', 'error', 'fusion', 'aggreg', 'member', 'accuraci', 'shooter'], ['servic', 'agent', 'rate', 'event', 'correl', 'request', 'node', 'workflow', 'role', 'manag', 'busi', 'custom', 'money', 'secur', 'action'], ['grid', 'agent', 'job', 'render', 'cluster', 'instal', 'command', 'directori', 'client', 'file', 'grid_comput', 'plug-in', 'mac', 'appl', 'script'], ['bid', 'bidder', 'machin', 'latenc', 'alloc', 'car', 'parallel', 'replica', 'replac', 'request', 'index', 'storag', 'payment', 'linear', 'post'], ['learn', 'web', 'pda', 'display', 'client', 'cooper', 'server', 'histori', 'video', 'browser', 'screen', 'devic', 'player', 'servic', 'mobil'], ['node', 'sensor', 'messag', 'protocol', 'record', 'rout', 'locat', 'contact', 'forward', 'wit', 'sensor_node', 'packet', 'payment', 'contract', 'princip'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['learn', 'web', 'pda', 'display', 'client', 'cooper', 'server', 'histori', 'video', 'browser', 'screen', 'devic', 'player', 'servic', 'mobil'], ['subject', 'integr', 'grid', 'detect', 'servic', 'intrus', 'scope', 'id', 'class', 'environ', 'represent', 'analys', 'nativ', 'accept', 'attack'], ['servic', 'agent', 'rate', 'event', 'correl', 'request', 'node', 'workflow', 'role', 'manag', 'busi', 'custom', 'money', 'secur', 'action'], ['event', 'topic', 'stori', 'protocol', 'cluster', 'vector', 'causal', 'predecessor', 'messag', 'news', 'send', 'tripl', 'immedi', 'boolean', 'train'], ['event', 'environ', 'channel', 'sensor', 'dissemin', 'layer', 'tempor', 'target', 'smart', 'qualiti', 'attribut', 'architectur', 'robot', 'middlewar', 'real-tim'], ['node', 'sensor', 'local', 'queri', 'event', 'zone', 'locat', 'sensor_node', 'proxi', 'auction', 'sequenc', 'scan', 'color', 'code', 'label'], ['job', 'fit', 'incumb', 'databas', 'client', 'game', 'rule', 'cost_share', 'nativ', 'respons', 'graph', 'theorem', 'shapley', 'predictor', 'benchmark'], ['energi', 'batteri', 'cycl', 'duti', 'slot', 'power', 'harvest', 'predict', 'node', 'adapt', 'manag', 'sensor', 'neutral', 'day', 'window'], ['document', 'rank', 'page', 'class', 'score', 'classifi', 'queri', 'text', 'topic', 'input', 'charact', 'editor', 'match', 'advertis', 'taxonomi'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['queri', 'rank', 'document', 'retriev', 'topic', 'page', 'score', 'predict', 'web', 'expert', 'train', 'pagerank', 'learn', 'candid', 'accuraci'], ['svm', 'distanc', 'spam', 'detect', 'cluster', 'descriptor', 'onlin', 'video', 'sentenc', 'classifi', 'distanc_measur', 'qo', 'adapt', 'e-mail', 'train'], ['page', 'pagerank', 'vector', 'graph', 'web', 'error', 'node', 'local', 'link', 'global', 'heat', 'player', 'export', 'sender', 'crawl'], ['queri', 'stem', 'translat', 'geograph', 'languag', 'document', 'web', 'match', 'log', 'index', 'handl', 'interv', 'retriev', 'ontolog', 'string'], ['page', 'pagerank', 'vector', 'graph', 'web', 'error', 'node', 'local', 'link', 'global', 'heat', 'player', 'export', 'sender', 'crawl'], ['topic', 'plausibl', 'hub', 'path', 'link', 'author', 'belief', 'graph', 'formula', 'trec', 'matrix', 'valid', 'document', 'easi', 'eas'], ['execut', 'link', 'activ', 'web', 'web_page', 'content', 'page', 'matrix', 'classif', 'grid', 'manag', 'machin', 'element', 'infrastructur', 'coordin'], ['bid', 'bidder', 'machin', 'latenc', 'alloc', 'car', 'parallel', 'replica', 'replac', 'request', 'index', 'storag', 'payment', 'linear', 'post'], ['queri', 'rank', 'document', 'retriev', 'topic', 'page', 'score', 'predict', 'web', 'expert', 'train', 'pagerank', 'learn', 'candid', 'accuraci'], ['queri', 'rank', 'document', 'retriev', 'topic', 'page', 'score', 'predict', 'web', 'expert', 'train', 'pagerank', 'learn', 'candid', 'accuraci'], ['document', 'rank', 'page', 'class', 'score', 'classifi', 'queri', 'text', 'topic', 'input', 'charact', 'editor', 'match', 'advertis', 'taxonomi'], ['queri', 'auction', 'valuat', 'price', 'document', 'elicit', 'bundl', 'ascend', 'demand', 'polynomi', 'bidder', 'web', 'alloc', 'site', 'agent'], ['queri', 'rank', 'document', 'retriev', 'topic', 'page', 'score', 'predict', 'web', 'expert', 'train', 'pagerank', 'learn', 'candid', 'accuraci'], ['document', 'rank', 'page', 'class', 'score', 'classifi', 'queri', 'text', 'topic', 'input', 'charact', 'editor', 'match', 'advertis', 'taxonomi'], ['index', 'retriev', 'estim', 'queri', 'score', 'occurr', 'asymmetr', 'speech', 'phone', 'error', 'laplac', 'lattic', 'output', 'fit', 'path'], ['queri', 'stem', 'translat', 'geograph', 'languag', 'document', 'web', 'match', 'log', 'index', 'handl', 'interv', 'retriev', 'ontolog', 'string'], ['queri', 'document', 'retriev', 'passag', 'variant', 'domain-specif', 'abbrevi', 'extract', 'conceptu', 'semant', 'symbol', 'implicitli', 'paragraph', 'rank', 'literatur'], ['agent', 'argument', 'learn', 'predict', 'nois', 'reput', 'estim', 'document', 'procur', 'confid', 'poisson', 'joint', 'counterexampl', 'idf', 'justif'], ['page', 'advertis', 'agent', 'intent', 'negoti', 'match', 'keyword', 'variabl', 'neighbor', 'web', 'trigger', 'web_page', 'mediat', 'variabl_assign', 'color'], ['queri', 'rank', 'click', 'implicit', 'feedback', 'web', 'clickthrough', 'retriev', 'document', 'web_search', 'implicit_feedback', 'behavior', 'histori', 'summari', 'locat'], ['index', 'scheme', 'broadcast', 'locat', 'access', 'tree', 'tune', 'bucket', 'major', 'queri', 'minor', 'index_scheme', 'mobil', 'node', 'weather'], ['document', 'rank', 'page', 'class', 'score', 'classifi', 'queri', 'text', 'topic', 'input', 'charact', 'editor', 'match', 'advertis', 'taxonomi'], ['vote', 'candid', 'vector', 'rank', 'score', 'forum', 'rule', 'web', 'log', 'queri', 'win', 'rate', 'fusion', 'duplic', 'protocol'], ['document', 'databas', 'retriev', 'score', 'central', 'topic', 'estim', 'sampl', 'document_retriev', 'rocchio', 'testb', 'train', 'queri', 'probabl_relev', 'adapt'], ['titl', 'extract', 'document', 'unit', 'font', 'format', 'file', 'perceptron', 'train', 'metadata', 'line', 'learn', 'conduct', 'machin', 'accuraci'], ['queri', 'rank', 'document', 'retriev', 'topic', 'page', 'score', 'predict', 'web', 'expert', 'train', 'pagerank', 'learn', 'candid', 'accuraci'], ['svm', 'distanc', 'spam', 'detect', 'cluster', 'descriptor', 'onlin', 'video', 'sentenc', 'classifi', 'distanc_measur', 'qo', 'adapt', 'e-mail', 'train'], ['queri', 'auction', 'valuat', 'price', 'document', 'elicit', 'bundl', 'ascend', 'demand', 'polynomi', 'bidder', 'web', 'alloc', 'site', 'agent'], ['page', 'pagerank', 'vector', 'graph', 'web', 'error', 'node', 'local', 'link', 'global', 'heat', 'player', 'export', 'sender', 'crawl'], ['event', 'topic', 'stori', 'protocol', 'cluster', 'vector', 'causal', 'predecessor', 'messag', 'news', 'send', 'tripl', 'immedi', 'boolean', 'train'], ['queri', 'rank', 'click', 'implicit', 'feedback', 'web', 'clickthrough', 'retriev', 'document', 'web_search', 'implicit_feedback', 'behavior', 'histori', 'summari', 'locat'], ['document', 'databas', 'retriev', 'score', 'central', 'topic', 'estim', 'sampl', 'document_retriev', 'rocchio', 'testb', 'train', 'queri', 'probabl_relev', 'adapt'], ['agent', 'negoti', 'offer', 'produc', 'equilibrium', 'servic', 'element', 'consum', 'learn', 'wine', 'period', 'accept', 'time_period', 'onlin', 'knapsack'], ['queri', 'rank', 'click', 'implicit', 'feedback', 'web', 'clickthrough', 'retriev', 'document', 'web_search', 'implicit_feedback', 'behavior', 'histori', 'summari', 'locat'], ['queri', 'rank', 'click', 'implicit', 'feedback', 'web', 'clickthrough', 'retriev', 'document', 'web_search', 'implicit_feedback', 'behavior', 'histori', 'summari', 'locat'], ['queri', 'stem', 'translat', 'geograph', 'languag', 'document', 'web', 'match', 'log', 'index', 'handl', 'interv', 'retriev', 'ontolog', 'string'], ['subject', 'integr', 'grid', 'detect', 'servic', 'intrus', 'scope', 'id', 'class', 'environ', 'represent', 'analys', 'nativ', 'accept', 'attack'], ['svm', 'distanc', 'spam', 'detect', 'cluster', 'descriptor', 'onlin', 'video', 'sentenc', 'classifi', 'distanc_measur', 'qo', 'adapt', 'e-mail', 'train'], ['index', 'retriev', 'estim', 'queri', 'score', 'occurr', 'asymmetr', 'speech', 'phone', 'error', 'laplac', 'lattic', 'output', 'fit', 'path'], ['learn', 'web', 'pda', 'display', 'client', 'cooper', 'server', 'histori', 'video', 'browser', 'screen', 'devic', 'player', 'servic', 'mobil'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['event', 'environ', 'channel', 'sensor', 'dissemin', 'layer', 'tempor', 'target', 'smart', 'qualiti', 'attribut', 'architectur', 'robot', 'middlewar', 'real-tim'], ['action', 'commit', 'agent', 'plan', 'monoton', 'belief', 'machin', 'messag', 'rule', 'precondit', 'act', 'languag', 'pay', 'program', \"n't\"], ['agent', 'norm', 'action', 'reward', 'transit', 'represent', 'congest', 'logic', 'traffic', 'check', 'aircraft', 'ctl', 'multi-ag', 'interpret', 'local'], ['job', 'agent', 'execut', 'declar', 'event', 'action', 'activ', 'field', 'competit', 'ratio', 'releas', 'protocol', 'schedul', 'rule', 'cours'], ['agent', 'norm', 'action', 'reward', 'transit', 'represent', 'congest', 'logic', 'traffic', 'check', 'aircraft', 'ctl', 'multi-ag', 'interpret', 'local'], ['agent', 'negoti', 'argument', 'offer', 'node', 'path', 'monitor', 'qualiti', 'contract', 'dialogu', 'accept', 'player', 'protocol', 'proof', 'rout'], ['topic', 'plausibl', 'hub', 'path', 'link', 'author', 'belief', 'graph', 'formula', 'trec', 'matrix', 'valid', 'document', 'easi', 'eas'], ['agent', 'argument', 'learn', 'predict', 'nois', 'reput', 'estim', 'document', 'procur', 'confid', 'poisson', 'joint', 'counterexampl', 'idf', 'justif'], ['agent', 'negoti', 'argument', 'offer', 'node', 'path', 'monitor', 'qualiti', 'contract', 'dialogu', 'accept', 'player', 'protocol', 'proof', 'rout'], ['game', 'player', 'agent', 'coalit', 'payoff', 'equilibrium', 'shapley', 'nash', 'queri', 'node', 'tree', 'represent', 'shapley_valu', 'signal', 'world'], ['agent', 'negoti', 'offer', 'produc', 'equilibrium', 'servic', 'element', 'consum', 'learn', 'wine', 'period', 'accept', 'time_period', 'onlin', 'knapsack'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['page', 'advertis', 'agent', 'intent', 'negoti', 'match', 'keyword', 'variabl', 'neighbor', 'web', 'trigger', 'web_page', 'mediat', 'variabl_assign', 'color'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['servic', 'agent', 'rate', 'event', 'correl', 'request', 'node', 'workflow', 'role', 'manag', 'busi', 'custom', 'money', 'secur', 'action'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['agent', 'argument', 'self-interest', 'self-interest_agent', 'dialogu', 'gossip', 'road', 'node', 'graph', 'journey', 'simul', 'rout', 'lie', 'ation', 'car'], ['agent', 'norm', 'action', 'reward', 'transit', 'represent', 'congest', 'logic', 'traffic', 'check', 'aircraft', 'ctl', 'multi-ag', 'interpret', 'local'], ['agent', 'alloc', 'bid', 'action', 'buyer', 'seller', 'revenu', 'repair', 'match', 'robust', 'mdp', 'valuat', 'variabl', 'global', 'bidder'], ['agent', 'alloc', 'bid', 'action', 'buyer', 'seller', 'revenu', 'repair', 'match', 'robust', 'mdp', 'valuat', 'variabl', 'global', 'bidder'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['servic', 'agent', 'rate', 'event', 'correl', 'request', 'node', 'workflow', 'role', 'manag', 'busi', 'custom', 'money', 'secur', 'action'], ['polici', 'agent', 'joint', 'heurist', 'joint_polici', 'qualiti', 'tree', 'abstract', 'node', 'threshold', 'prune', 'upper', 'upper_bound', 'horizon', 'solut_qualiti'], ['site', 'local', 'inconsist', 'delay', 'entiti', 'execut', 'lag', 'opportun', 'transmiss', 'propag', 'remot', 'game', 'state_updat', 'opportun_cost', 'enabl'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['agent', 'negoti', 'offer', 'produc', 'equilibrium', 'servic', 'element', 'consum', 'learn', 'wine', 'period', 'accept', 'time_period', 'onlin', 'knapsack'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['agent', 'argument', 'self-interest', 'self-interest_agent', 'dialogu', 'gossip', 'road', 'node', 'graph', 'journey', 'simul', 'rout', 'lie', 'ation', 'car'], ['agent', 'messag', 'contract', 'protocol', 'node', 'send', 'propag', 'local', 'multi-ag', 'environ', 'outcom', 'reput', 'estim', 'ontolog', 'dimens'], ['agent', 'negoti', 'offer', 'produc', 'equilibrium', 'servic', 'element', 'consum', 'learn', 'wine', 'period', 'accept', 'time_period', 'onlin', 'knapsack'], ['agent', 'negoti', 'argument', 'offer', 'node', 'path', 'monitor', 'qualiti', 'contract', 'dialogu', 'accept', 'player', 'protocol', 'proof', 'rout'], ['trade', 'agent', 'rule', 'payment', 'alloc', 'privaci', 'node', 'output', 'bidder', 'round', 'price', 'cut', 'alloc_rule', 'protect', 'exchang'], ['price', 'execut', 'sequenc', 'book', 'buy', 'trade', 'market', 'trader', 'sell', 'bid', 'buyer', 'quantiti', 'absolut', 'arriv', 'offer'], ['servic', 'agent', 'rate', 'event', 'correl', 'request', 'node', 'workflow', 'role', 'manag', 'busi', 'custom', 'money', 'secur', 'action'], ['game', 'player', 'agent', 'coalit', 'payoff', 'equilibrium', 'shapley', 'nash', 'queri', 'node', 'tree', 'represent', 'shapley_valu', 'signal', 'world'], ['game', 'player', 'agent', 'coalit', 'payoff', 'equilibrium', 'shapley', 'nash', 'queri', 'node', 'tree', 'represent', 'shapley_valu', 'signal', 'world'], ['game', 'player', 'agent', 'coalit', 'payoff', 'equilibrium', 'shapley', 'nash', 'queri', 'node', 'tree', 'represent', 'shapley_valu', 'signal', 'world'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['job', 'fit', 'incumb', 'databas', 'client', 'game', 'rule', 'cost_share', 'nativ', 'respons', 'graph', 'theorem', 'shapley', 'predictor', 'benchmark'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['recommend', 'product', 'purchas', 'book', 'node', 'person', 'peopl', 'market', 'discount', 'influenc', 'buy', 'friend', 'rate', 'categori', 'custom'], ['servic', 'agent', 'rate', 'event', 'correl', 'request', 'node', 'workflow', 'role', 'manag', 'busi', 'custom', 'money', 'secur', 'action'], ['agent', 'argument', 'learn', 'predict', 'nois', 'reput', 'estim', 'document', 'procur', 'confid', 'poisson', 'joint', 'counterexampl', 'idf', 'justif'], ['queri', 'auction', 'valuat', 'price', 'document', 'elicit', 'bundl', 'ascend', 'demand', 'polynomi', 'bidder', 'web', 'alloc', 'site', 'agent'], ['market', 'price', 'predict', 'opinion', 'pool', 'trader', 'expert', 'game', 'score', 'accuraci', 'money', 'outcom', 'win', 'particip', 'payoff'], ['vote', 'candid', 'vector', 'rank', 'score', 'forum', 'rule', 'web', 'log', 'queri', 'win', 'rate', 'fusion', 'duplic', 'protocol'], ['domin', 'player', 'elimin', 'pure', 'pure_strategi', 'ate', 'game', 'mix', 'row', 'domin_strategi', 'weak', 'play', 'strict', 'row_player', 'column'], ['node', 'sensor', 'messag', 'protocol', 'record', 'rout', 'locat', 'contact', 'forward', 'wit', 'sensor_node', 'packet', 'payment', 'contract', 'princip'], ['bid', 'bidder', 'machin', 'latenc', 'alloc', 'car', 'parallel', 'replica', 'replac', 'request', 'index', 'storag', 'payment', 'linear', 'post'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['agent', 'alloc', 'bid', 'action', 'buyer', 'seller', 'revenu', 'repair', 'match', 'robust', 'mdp', 'valuat', 'variabl', 'global', 'bidder'], ['game', 'player', 'agent', 'coalit', 'payoff', 'equilibrium', 'shapley', 'nash', 'queri', 'node', 'tree', 'represent', 'shapley_valu', 'signal', 'world'], ['trade', 'agent', 'rule', 'payment', 'alloc', 'privaci', 'node', 'output', 'bidder', 'round', 'price', 'cut', 'alloc_rule', 'protect', 'exchang'], ['job', 'fit', 'incumb', 'databas', 'client', 'game', 'rule', 'cost_share', 'nativ', 'respons', 'graph', 'theorem', 'shapley', 'predictor', 'benchmark'], ['queri', 'stem', 'translat', 'geograph', 'languag', 'document', 'web', 'match', 'log', 'index', 'handl', 'interv', 'retriev', 'ontolog', 'string'], ['trade', 'agent', 'rule', 'payment', 'alloc', 'privaci', 'node', 'output', 'bidder', 'round', 'price', 'cut', 'alloc_rule', 'protect', 'exchang'], ['slot', 'truth', 'rbr', 'path', 'lemma', 'social', 'social_choic', 'theorem', 'compat', 'convex', 'cycl', 'revenu', 'proof', 'nonneg', 'player'], ['agent', 'alloc', 'bid', 'action', 'buyer', 'seller', 'revenu', 'repair', 'match', 'robust', 'mdp', 'valuat', 'variabl', 'global', 'bidder'], ['trade', 'agent', 'rule', 'payment', 'alloc', 'privaci', 'node', 'output', 'bidder', 'round', 'price', 'cut', 'alloc_rule', 'protect', 'exchang'], ['bid', 'bidder', 'machin', 'latenc', 'alloc', 'car', 'parallel', 'replica', 'replac', 'request', 'index', 'storag', 'payment', 'linear', 'post'], ['job', 'agent', 'execut', 'declar', 'event', 'action', 'activ', 'field', 'competit', 'ratio', 'releas', 'protocol', 'schedul', 'rule', 'cours'], ['learn', 'web', 'pda', 'display', 'client', 'cooper', 'server', 'histori', 'video', 'browser', 'screen', 'devic', 'player', 'servic', 'mobil'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent'], ['market', 'price', 'predict', 'opinion', 'pool', 'trader', 'expert', 'game', 'score', 'accuraci', 'money', 'outcom', 'win', 'particip', 'payoff'], ['queri', 'auction', 'valuat', 'price', 'document', 'elicit', 'bundl', 'ascend', 'demand', 'polynomi', 'bidder', 'web', 'alloc', 'site', 'agent'], ['price', 'sell', 'competit', 'volum', 'market', 'ratio', 'sequenc', 'trade', 'competit_ratio', 'execut', 'book', 'buy', 'bin', 'onlin', 'log'], ['agent', 'auction', 'bid', 'bidder', 'payment', 'equilibrium', 'outcom', 'price', 'game', 'nash', 'revenu', 'rule', 'win', 'attribut', 'incent']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import *\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_data=open_pickle('xml train data')\n",
    "'''\n",
    "train_data=[\"Henny is amazing, she is very nice person\",\n",
    "           \"Tony is a good student in his class, but he has never got a high score\",\n",
    "           \"Machine learning is a challenging course in university\",\n",
    "           \"Henny loves machine learning\"]\n",
    "'''\n",
    "stop_words=text.ENGLISH_STOP_WORDS\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "def clean_(doc):\n",
    "    remove_stop=\" \".join([i for i in word_tokenize(doc.lower()) if re.search(r\"\\b[A-Za-z-]+\\b\", i) and i not in stop_words and len(i)>2])\n",
    "    normalized=[stemmer.stem(word) for word in remove_stop.split()]\n",
    "    return normalized\n",
    "\n",
    "print(\"cleansing data..\")\n",
    "docs=[clean_(doc) for doc in train_data]\n",
    "\n",
    "#print bigram\n",
    "#from https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html\n",
    "print(\"creating bigram..\")\n",
    "bigram=Phrases(docs, min_count=2)\n",
    "#trigram=Phrases(bigram[docs], min_count=2)\n",
    "#fourgram=Phrases(trigram[docs], min_count=2)\n",
    "#fivegram=Phrases(fourgram[docs], min_count=2)\n",
    "print(\"merging bigram to doc..\")\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            docs[idx].append(token)\n",
    "\n",
    "dictionary=Dictionary(docs)\n",
    "# occurence per documents - hyperparameter\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.5)\n",
    "print(\"creating a corpus..\")\n",
    "corpus=[dictionary.doc2bow(text) for text in docs]\n",
    "#(index, occurrence in a document)\n",
    "lm=LdaModel(corpus, num_topics=55, id2word=dictionary, passes=5)\n",
    "topics=lm.print_topics(num_topics=55, num_words=15)\n",
    "\n",
    "doc_topic=lm.get_document_topics(corpus)\n",
    "\n",
    "#get all keywords from gensim\n",
    "topic_terms=[]\n",
    "for doc in range(len(doc_topic)):\n",
    "    ordered=list(sorted(doc_topic[doc], key=lambda x:x[1]))\n",
    "    topic_id=ordered[-1][0]\n",
    "    for topic in range(len(topics)):\n",
    "        if topics[topic][0]==topic_id: \n",
    "            #terms have been decrementally ordered\n",
    "            terms=[word[6:].strip('\"') for word in topics[topic][1].split(\" + \")]\n",
    "            #doc.append(((ordered[-1], terms)))\n",
    "    topic_terms.append(terms)\n",
    "print(topic_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing LDA with scikit learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import *\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_data=open_pickle('xml train data')\n",
    "\n",
    "stop_words=text.ENGLISH_STOP_WORDS\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "def clean_(doc):\n",
    "    remove_stop=\" \".join([i for i in word_tokenize(doc.lower()) if re.search(r\"\\b[A-Za-z-]+\\b\", i) and i not in stop_words and len(i)>2])\n",
    "    normalized=[stemmer.stem(word) for word in remove_stop.split()]\n",
    "    return normalized\n",
    "\n",
    "print(\"cleansing data..\")\n",
    "docs=[clean_(doc) for doc in train_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import Phrases\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import *\n",
    "from itertools import chain\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#train_data=open_pickle('xml train data')\n",
    "\n",
    "train_data=[\"Henny is amazing, she is very nice person\",\n",
    "           \"Tony is a good student in his class, but he has never got a high score\",\n",
    "           \"Machine learning is a challenging course in university\",\n",
    "           \"Henny loves machine learning\"]\n",
    "\n",
    "stop_words=text.ENGLISH_STOP_WORDS\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "def clean_(corpus):\n",
    "    clean=[]\n",
    "    for doc in corpus:\n",
    "        remove_stop=\" \".join([i for i in word_tokenize(doc.lower()) if re.search(r\"\\b[A-Za-z-]+\\b\", i) and i not in stop_words and len(i)>2])\n",
    "        normalized=[stemmer.stem(word) for word in remove_stop.split()]\n",
    "        clean.append(\" \".join([i for i in normalized]))\n",
    "    return clean\n",
    "\n",
    "lda_model=LatentDirichletAllocation(n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####C/NC value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python35\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1237959024144617, 0.1824377227735681, 0], [0.11770175662810844, 1.1128701089187656, 0], [0, 0, 1.201942644155272]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "corpus = [\n",
    "     [\"black\", \"cat\", \"white\", \"cat\"],\n",
    "     [\"cat\", \"outer\", \"space\"],\n",
    "     [\"wag\", \"dog\"]]\n",
    "\n",
    "result = get_bm25_weights(corpus)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time= 0:02:35.778508\n",
      "time= 0:02:48.802045\n",
      "0.4411129495386891\n",
      "time= 0:02:49.263781\n",
      "0.42272578472568784\n",
      "time= 0:02:49.265781\n",
      "0.2383293561146944\n",
      "time= 0:02:49.267776\n"
     ]
    }
   ],
   "source": [
    "##Word2vec \n",
    "import gensim\n",
    "from datetime import datetime\n",
    "\n",
    "start=datetime.now()\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True, limit=500000)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "model.init_sims(replace=True)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(model.similarity('learning','studying'))\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(model.similarity('finance','accounting'))\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(model.similarity('rule','system'))\n",
    "print(\"time=\", datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python35\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=19, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "t=[\"machine learning is one of difficult module.\",\n",
    "   \"high performance computing is super difficult\"]\n",
    "\n",
    "bigram_transformer = Phrases(t)\n",
    "model = Word2Vec(bigram_transformer[t], min_count=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5797386715376657\n",
      "0.5031026124151314\n",
      "0.0\n",
      "0.7092972666062738\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "##testing similarity\n",
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n",
    "# no need to normalize, since Vectorizer will return normalized tf-idf\n",
    "print(cosine_sim('neural network','network'))\n",
    "print(cosine_sim('convolutional neural network','recurrent neural network'))\n",
    "print(cosine_sim('machine learning','network'))\n",
    "print(cosine_sim('high performance computing','high computing'))\n",
    "print(cosine_sim('accounting system','finance system'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "#feature  position\n",
    "\n",
    "corpus=[\"henny is amazing henny 7877 is very nice person, henny\",\n",
    "           \"Tony is a good student in his class, but he has never got a high score\",\n",
    "           \"Machine learning is a challenging course in university\",\n",
    "            \"Luca citi is teaching machine learning\",\n",
    "           \"Henny loves machine learning\"]\n",
    "\n",
    "candidates=[[\"henny\", \"is\", \"amazing\", \"amazing henny\", \"very nice\"],\n",
    "           [\"student\", \"his\", \"class\", \"never\", \"got\", \"a\", \"high\", \"score\"],\n",
    "           [\"a\", \"challenging\", \"course\", \"in\", \"university\"],\n",
    "            [\"luca\", \"citi\", \"is\", \"teaching\", \"machine\"],\n",
    "           [\"machine\", \"learning\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Henny love machine learning', 3), ('machine learning is the best', 2), ('hey, machine', 1), ('this love is never stop', 1), ('love', 1), ('never stop', 0), ('high performance computing is one of course in computer science', 0), ('high performance computing is one of course in computer science, it was taught by adrian clark', 0)], [('Henny love machine learning', 1), ('machine learning is the best', 1), ('hey, machine', 0), ('this love is never stop', 4), ('love', 1), ('never stop', 2), ('high performance computing is one of course in computer science', 1), ('high performance computing is one of course in computer science, it was taught by adrian clark', 1)], [('Henny love machine learning', 0), ('machine learning is the best', 1), ('hey, machine', 0), ('this love is never stop', 1), ('love', 0), ('never stop', 0), ('high performance computing is one of course in computer science', 9), ('high performance computing is one of course in computer science, it was taught by adrian clark', 16)]]\n"
     ]
    }
   ],
   "source": [
    "from os.path import commonprefix\n",
    "\n",
    "candidates=['Henny love machine learning','machine learning is the best', 'hey, machine',\n",
    "           'this love is never stop','love', 'never stop',\n",
    "           'high performance computing is one of course in computer science',\n",
    "           'high performance computing is one of course in computer science, it was taught by adrian clark']\n",
    "labels=['love machine learning','love is never stop', \n",
    "        'high performance computing is one of course in computer science, it was taught by adrian clark']\n",
    "t=[]\n",
    "for label in labels:\n",
    "    lab=[]\n",
    "    label_tokens=[x for x in label.split(\" \")]\n",
    "    for sent in candidates:\n",
    "        sents=[]\n",
    "        sent_tokens=[x for x in sent.split(\" \")]\n",
    "        sents.append((sent, len(set(sent_tokens).intersection(label_tokens))))\n",
    "    #highest_match=max(sents, key=lambda x:x[1])\n",
    "        lab.append(max(sents, key=lambda x:x[1]))\n",
    "        #lab.append(sents)\n",
    "    t.append(lab)\n",
    "print(t)\n",
    "#sort=max(t, key=lambda x:x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match(a=0, b=15, size=9)\n",
      "apple pie\n",
      "apple pie\n",
      "0.4186046511627907\n",
      "0.6046511627906976\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "candidate = \"machine learning is one of subject in computer science, it is taught by luca citi\"\n",
    "label= \"machine learning is one of subject in computer science, it is taught by luca citi\"\n",
    "\n",
    "match = SequenceMatcher(None, string1, string2).find_longest_match(0, len(string1), 0, len(string2))\n",
    "ratio = SequenceMatcher(None, string1, string2)\n",
    "print(match)  # -> Match(a=0, b=15, size=9)\n",
    "print(string1[match.a: match.a + match.size])  # -> apple pie\n",
    "print(string2[match.b: match.b + match.size])  # -> apple pie\n",
    "print(ratio.ratio())\n",
    "print(ratio.quick_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4186046511627907\n",
      "0.6046511627906976\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "candidate = \"i love shopping. hnm is my favourite store\"\n",
    "label= \"i love shopping. hnm is my favourite store\"\n",
    "\n",
    "r = SequenceMatcher(None, string1, string2)\n",
    "\n",
    "print(r.ratio())\n",
    "print(r.quick_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to put label on summary\n",
    "#just use intersection, order by maximal\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
