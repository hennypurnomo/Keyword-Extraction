{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import utils\n",
    "from datetime import datetime\n",
    "\n",
    "# GDC \n",
    "tf_corpus=[[('milkshake',6), ('banana', 4),('chocolate',3),('chocolate milkshake', 2), ('milkshake banana', 3),('chocolate milkshake banana', 2),('machine',5)],\n",
    "           [('chocolate',7),('white chocolate', 4),('white', 3)]]\n",
    "\n",
    "#candidates = utils.open_pickle('txt train tf corpus')\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "gdc_values=[]\n",
    "for n_doc in range(len(tf_corpus)):\n",
    "    doc=[]\n",
    "    for n_cand in range(len(tf_corpus[n_doc])):\n",
    "        length_term = len(tf_corpus[n_doc][n_cand][0].split(\" \"))\n",
    "        tf = tf_corpus[n_doc][n_cand][1]\n",
    "        if length_term == 1:\n",
    "            # 10% from gdc value for unigram term\n",
    "            gdc = float(\"{0:.3F}\".format( 0.1 * ( length_term * math.log10 (tf) * tf ) / tf ))  \n",
    "            doc.append((tf_corpus[n_doc][n_cand][0], gdc))\n",
    "        else:\n",
    "            matched_word = [word for word in [word for word in tf_corpus[n_doc][n_cand][0].split(\" \")] \n",
    "                            if word in [value[0] for value in tf_corpus[n_doc]]]\n",
    "            freq_word = sum([value[1] for value in tf_corpus[n_doc] if value[0] in matched_word])\n",
    "            gdc = float(\"{0:.3F}\".format(( length_term * math.log10 (tf) * tf ) / freq_word ))\n",
    "            doc.append((tf_corpus[n_doc][n_cand][0], gdc))\n",
    "    gdc_values.append(doc)\n",
    "    \n",
    "print(gdc_values)\n",
    "'''\n",
    "candidates=[[('milkshake',6), ('banana', 4),('chocolate',3),('chocolate milkshake', 2), ('milkshake banana', 3),('chocolate milkshake banana', 2),('machine',5)],\n",
    "           [('chocolate',7),('white chocolate', 4),('white', 3)]]\n",
    "\n",
    "all_values=[]\n",
    "for n_doc in range(len(candidates)):\n",
    "    doc=[]\n",
    "    for n_cand in range(len(candidates[n_doc])):\n",
    "        for element, value in gdc[n_doc]:\n",
    "            if candidates[n_doc][n_cand][0] == element:\n",
    "                doc.append(value)\n",
    "\n",
    "        #doc.append(x[1] for x in gdc[n_doc] if candidates[n_doc][n_cand][0] in [x[0] for x in gdc[n_doc]])\n",
    "            #doc.append(gdc[n_doc][])\n",
    "    all_values.append(doc)\n",
    "        \n",
    "print(all_values)\n",
    "[[('milkshake', 0.078), ('banana', 0.06), ('chocolate', 0.048), ('chocolate milkshake', 0.134), ('milkshake banana', 0.286),\n",
    "('chocolate milkshake banana', 0.139), ('machine', 0.07)], [('chocolate', 0.085), ('white chocolate', 0.482), ('white', 0.048)]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#('milkshake',6), ('banana', 4),('chocolate',3),('chocolate milkshake banana', 2)\n",
    "\n",
    "length_term = 3\n",
    "tf_term = 2\n",
    "f_word = 13\n",
    "gdc = ( length_term * math.log10 (tf_term) * tf_term ) / f_word\n",
    "print(gdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import math\n",
    "\n",
    "tf_corpus=[[('milkshake',6), ('banana', 4),('chocolate',3),('chocolate milkshake', 2), ('milkshake banana', 3),('chocolate milkshake banana', 2),('machine',5)],\n",
    "           [('chocolate',7),('white chocolate', 4),('white', 3)]]\n",
    "\n",
    "candidates=[[('milkshake banana', 0.3),('banana', 0.4),('chocolate',0.3),('milkshake',0.6),('chocolate milkshake', 0.2),('chocolate milkshake banana', 0.2),('machine',0.5)],\n",
    "           [('white', 0.3),('chocolate',0.7),('white chocolate', 0.4)]]\n",
    "\n",
    "label=[['banana','chocolate', 'milkshake banana'],\n",
    "      ['chocolate', 'white chocolate']]\n",
    "\n",
    "\n",
    "def calculate_gdc(term, tf, length_term):\n",
    "    if length_term == 1:\n",
    "        # 10% from gdc value for unigram term\n",
    "        gdc = float(\"{0:.3F}\".format( 0.1 * ( length_term * math.log10 (tf) * tf ) / tf ))  \n",
    "    else:\n",
    "        matched_word = [word for word in [word for word in tf_corpus[n_doc][n_cand][0].split(\" \")] \n",
    "                            if word in [value[0] for value in tf_corpus[n_doc]]]\n",
    "        freq_word = sum([value[1] for value in tf_corpus[n_doc] if value[0] in matched_word])\n",
    "        gdc = float(\"{0:.3F}\".format(( length_term * math.log10 (tf) * tf ) / freq_word ))\n",
    "    return gdc\n",
    "        \n",
    "def feature_frequency(label, tf_corpus, candidates):\n",
    "    merged_labels = list(chain.from_iterable(label))\n",
    "    frequency = []\n",
    "    for n_doc in range(len(tf_corpus)):\n",
    "        doc = []\n",
    "        for n_cand in range(len(tf_corpus[n_doc])):\n",
    "            tf = tf_corpus[n_doc][n_cand][1]\n",
    "            length_term = len(tf_corpus[n_doc][n_cand][0].split(\" \"))\n",
    "            #put GDC in here\n",
    "            if tf_corpus[n_doc][n_cand][0] not in merged_labels:\n",
    "                supervised = 0\n",
    "            else:\n",
    "                supervised = tf_corpus[n_doc][n_cand][1]\n",
    "            \n",
    "            #calculate GDC - Generalized Dice Coefficient\n",
    "            if length_term == 1:\n",
    "            # 10% from gdc value for unigram term\n",
    "                gdc = float(\"{0:.3F}\".format( 0.1 * ( length_term * math.log10 (tf) * tf ) / tf ))  \n",
    "            else:\n",
    "                matched_word = [word for word in [word for word in tf_corpus[n_doc][n_cand][0].split(\" \")] \n",
    "                            if word in [value[0] for value in tf_corpus[n_doc]]]\n",
    "                freq_word = sum([value[1] for value in tf_corpus[n_doc] if value[0] in matched_word])\n",
    "                gdc = float(\"{0:.3F}\".format(( length_term * math.log10 (tf) * tf ) / freq_word ))\n",
    "            \n",
    "            doc.append(((tf_corpus[n_doc][n_cand][0], tf, supervised, gdc)))\n",
    "        frequency.append(doc)\n",
    "    \n",
    "    #mapping the result with candidate order ##DONE!!\n",
    "    feature = []\n",
    "    for n_doc in range(len(candidates)):\n",
    "        doc = []\n",
    "        for n_cand in range(len(candidates[n_doc])):\n",
    "            for n_freq in frequency[n_doc]:\n",
    "                if candidates[n_doc][n_cand][0] == n_freq[0]:\n",
    "                    doc.append((n_freq[1], n_freq[2], n_freq[3]))\n",
    "        feature.append(doc)\n",
    "    return feature\n",
    "\n",
    "print(feature_frequency(label, tf, candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[(3, 3, 0.286), (4, 4, 0.06), (3, 3, 0.048), (6, 0, 0.078), (2, 0, 0.134),\n",
    "  (2, 0, 0.139), (5, 0, 0.07)], [(3, 0, 0.048), (7, 7, 0.085), (4, 4, 0.482)]]\n",
    "\n",
    "tf=[[('milkshake',6), ('banana', 4),('chocolate',3),('chocolate milkshake', 2), ('milkshake banana', 3),('chocolate milkshake banana', 2),('machine',5)],\n",
    "           [('chocolate',7),('white chocolate', 4),('white', 3)]]\n",
    "\n",
    "candidates=[[('milkshake banana', 0.3),('banana', 0.4),('chocolate',0.3),('milkshake',0.6),('chocolate milkshake', 0.2),('chocolate milkshake banana', 0.2),('machine',0.5)],\n",
    "           [('white', 0.3),('chocolate',0.7),('white chocolate', 0.4)]]\n",
    "\n",
    "label=[['banana','chocolate', 'milkshake banana'],\n",
    "      ['chocolate', 'white chocolate']]\n",
    "\n",
    "gdc=[[('milkshake', 0.078), ('banana', 0.06), ('chocolate', 0.048), ('chocolate milkshake', 0.134), ('milkshake banana', 0.286), ('chocolate milkshake banana', 0.139), ('machine', 0.07)],\n",
    " [('chocolate', 0.085), ('white chocolate', 0.482), ('white', 0.048)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, glob, preprocessing\n",
    "\n",
    "train_directory=glob.glob('./se_txt/test/*.txt.final')\n",
    "train_raw=preprocessing.load_files_ref(train_directory)\n",
    "pickle_train_raw=utils.create_pickle(train_raw,'txt test ref raw')\n",
    "train_data=preprocessing.create_corpus(train_raw)\n",
    "pickle_train_data=utils.create_pickle(train_data,'txt test ref data')\n",
    "\n",
    "#o=utils.open_pickle('txt test ref data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[1,2,3,4,5]\n",
    "print(t[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
