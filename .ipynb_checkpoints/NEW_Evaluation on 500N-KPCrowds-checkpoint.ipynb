{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-24 08:05:54,135: DEBUG: CACHEDIR=C:\\Users\\user\\.matplotlib\n",
      "2018-08-24 08:05:54,242: DEBUG: Using fontManager instance from C:\\Users\\user\\.matplotlib\\fontList.json\n",
      "2018-08-24 08:05:58,929: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n",
      "2018-08-24 08:06:00,748: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import utils, preprocessing, generate_candidate\n",
    "import mod_feature_extraction, generate_keyphrase\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only run one time, if pickles have been generated, please skip into next step\n",
    "\n",
    "train_directory = natsorted(glob.glob('./data/500N-KPCrowd/train/*.xml'))\n",
    "train_raw = preprocessing.load_xml_non_title(train_directory)\n",
    "pickle_train_raw = utils.create_pickle(train_raw,'./pickle/500N-KPCrowd/train raw')\n",
    "train_data = preprocessing.create_xml_corpus(train_raw)\n",
    "pickle_train_data = utils.create_pickle(train_data,'./pickle/500N-KPCrowd/train data')\n",
    "train_tf_corpus = feature_extraction.calculate_tf(train_data, vocab = None, type = 'ngram')\n",
    "pickle_train_tf_corpus = utils.create_pickle(train_tf_corpus,'./pickle/500N-KPCrowd/train tf corpus')\n",
    "\n",
    "###load testing data\n",
    "test_directory = natsorted(glob.glob('./data/500N-KPCrowd/test/*.xml'))\n",
    "test_raw = preprocessing.load_xml_non_title(test_directory)\n",
    "pickle_test_raw = utils.create_pickle(test_raw,'./pickle/500N-KPCrowd/test raw')\n",
    "test_data = preprocessing.create_xml_corpus(test_raw)\n",
    "pickle_test_data = utils.create_pickle(test_data,'./pickle/500N-KPCrowd/test data')\n",
    "test_tf_corpus = feature_extraction.calculate_tf(test_data, vocab = None, type = 'ngram')\n",
    "pickle_test_tf_corpus = utils.create_pickle(test_tf_corpus,'./pickle/500N-KPCrowd/test tf corpus')\n",
    "\n",
    "#create label\n",
    "train_label_directory = open('./data/500N-KPCrowd/references/train.reader.stem.json')\n",
    "train_label = preprocessing.extract_json_label(train_label_directory, raw_data = train_raw, \n",
    "                                               file_type='news')\n",
    "train_label_pickle = utils.create_pickle(train_label, './pickle/500N-KPCrowd/train label')\n",
    "\n",
    "test_label_directory = open('./data/500N-KPCrowd/references/test.reader.stem.json')\n",
    "test_label = preprocessing.extract_json_label(test_label_directory, raw_data = test_raw, \n",
    "                                              file_type='news')\n",
    "test_label_pickle = utils.create_pickle(test_label, './pickle/500N-KPCrowd/test label')\n",
    "\n",
    "###Ngram version\n",
    "print(\"N-gram TF-IDF version\")\n",
    "ngram_candidates = generate_candidate.calculate_tfidf(train_data, vocab=None, type='ngram') \n",
    "pickle_ngram_candidates = utils.create_pickle(ngram_candidates, \n",
    "                                              './pickle/500N-KPCrowd/ngram candidates')\n",
    "\n",
    "test_ngram_candidates = generate_candidate.calculate_tfidf(test_data, vocab=None, type='ngram') \n",
    "pickle_test_ngram_candidates = utils.create_pickle(test_ngram_candidates, \n",
    "                                    './pickle/500N-KPCrowd/test ngram candidates')\n",
    "\n",
    "\n",
    "#for supervised\n",
    "supervised_key = new_feature_extraction.create_supervised_list(train_label, train_tf_corpus)\n",
    "supervised_corpus = utils.create_pickle(supervised_key, './pickle/500N-KPCrowd/supervised keyphraseness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening all pickles\n",
      "Fmeasure on full features:\n",
      "Evaluation metric on top 50 keyphrase: [('LR', (35.52, 38.44, 36.92)), ('NB', (31.64, 34.24, 32.89)), ('RF', (33.16, 35.89, 34.47)), ('AdaBoost', (33.76, 36.54, 35.1)), ('Bagging', (32.92, 35.63, 34.22)), ('GradientBoosting', (33.4, 36.15, 34.72)), ('MLP', (32.68, 35.37, 33.97))]\n"
     ]
    }
   ],
   "source": [
    "#opening all relevant pickles\n",
    "\n",
    "\n",
    "number_keyphrase=50\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('./pickle/500N-KPCrowd/train raw')\n",
    "train_data = utils.open_pickle('./pickle/500N-KPCrowd/train data')\n",
    "\n",
    "train_label = utils.open_pickle('./pickle/500N-KPCrowd/train label')\n",
    "train_tf_corpus = utils.open_pickle('./pickle/500N-KPCrowd/train tf corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('./pickle/500N-KPCrowd/test raw')\n",
    "test_data = utils.open_pickle('./pickle/500N-KPCrowd/test data')\n",
    "\n",
    "test_label = utils.open_pickle('./pickle/500N-KPCrowd/test label')\n",
    "test_tf_corpus = utils.open_pickle('./pickle/500N-KPCrowd/test tf corpus')\n",
    "\n",
    "train_topics = utils.open_pickle('./pickle/500N-KPCrowd/train topics')\n",
    "test_topics = utils.open_pickle('./pickle/500N-KPCrowd/test topics')\n",
    "\n",
    "ngram_candidates = utils.open_pickle('./pickle/500N-KPCrowd/ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('./pickle/500N-KPCrowd/test ngram candidates')\n",
    "\n",
    "supervised_corpus = utils.open_pickle('./pickle/500N-KPCrowd/supervised keyphraseness')\n",
    "\n",
    "'''\n",
    "#create examples on training and testing data\n",
    "print(\"creating examples..\")\n",
    "\n",
    "ngram_train = mod_feature_extraction.create_features(train_data, ngram_candidates, train_label, \n",
    "                supervised_corpus, train_tf_corpus, train_topics, name='./csv/500N-KPCrowd/fast_train_ngram',\n",
    "                n_keyphrase = number_keyphrase)\n",
    "\n",
    "ngram_test = mod_feature_extraction.create_features(test_data, test_ngram_candidates, test_label, \n",
    "                supervised_corpus, test_tf_corpus, test_topics, name='./csv/500N-KPCrowd/fast_test_ngram',\n",
    "                n_keyphrase = number_keyphrase)\n",
    "'''\n",
    "\n",
    "#evaluation\n",
    "ngram_prediction = generate_keyphrase.predict_data(test_ngram_candidates, test_label, \n",
    "                train_data='./csv/500N-KPCrowd/train_ngram', \n",
    "                test_data='./csv/500N-KPCrowd/test_ngram', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "print('Evaluation metric on top 50 keyphrase:', ngram_prediction)\n",
    "\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates,\n",
    "                    train_data='./csv/500N-KPCrowd/train_ngram', \n",
    "                    test_data='./csv/500N-KPCrowd/test_ngram', \n",
    "                    csv_name='./csv/500N-KPCrowd/predicted fast ngram keyphrases 50 keywords', \n",
    "                    n_keyphrase = number_keyphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fmeasure on full features:\n",
      "Evaluation metric on top 10 candidates: [('LR', (59.2, 12.81, 21.06)), ('NB', (47.6, 10.3, 16.94)), ('RF', (52.0, 11.26, 18.51)), ('AdaBoost', (50.2, 10.87, 17.87)), ('Bagging', (45.0, 9.74, 16.01)), ('GradientBoosting', (50.6, 10.95, 18.0)), ('MLP', (49.4, 10.69, 17.58))]\n"
     ]
    }
   ],
   "source": [
    "#without supervised keyphrase\n",
    "number_keyphrase2 = 10\n",
    "ngram_prediction = generate_keyphrase.predict_data(test_ngram_candidates, test_label, \n",
    "                train_data='./csv/500N-KPCrowd/train_ngram', \n",
    "                test_data='./csv/500N-KPCrowd/test_ngram', \n",
    "                n_keyphrase = number_keyphrase2)\n",
    "print('Evaluation metric on top 10 candidates:', ngram_prediction)\n",
    "\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates,\n",
    "                    train_data='./csv/500N-KPCrowd/train_ngram', \n",
    "                    test_data='./csv/500N-KPCrowd/test_ngram', \n",
    "                    csv_name='./csv/500N-KPCrowd/predicted ngram keyphrases 10 keywords', \n",
    "                    n_keyphrase = number_keyphrase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without supervised keyphrase\n",
    "ngram_prediction = generate_keyphrase.predict_data(test_ngram_candidates, test_label, \n",
    "                train_data='./csv/500N-KPCrowd/train_ngram', \n",
    "                test_data='./csv/500N-KPCrowd/test_ngram', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "print('Evaluation metric on top 50 keyphrase:', ngram_prediction)\n",
    "\n",
    "\n",
    "#generate the result of prediction into excel\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates,\n",
    "                    train_data='./csv/500N-KPCrowd/9train_ngram', \n",
    "                    test_data='./csv/500N-KPCrowd/9test_ngram', \n",
    "                    csv_name='./csv/500N-KPCrowd/predicted ngram keyphrases 50 keywords', \n",
    "                    n_keyphrase = number_keyphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
