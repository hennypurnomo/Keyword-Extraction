{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-24 10:41:23,192: DEBUG: CACHEDIR=C:\\Users\\user\\.matplotlib\n",
      "2018-08-24 10:41:23,378: DEBUG: Using fontManager instance from C:\\Users\\user\\.matplotlib\\fontList.json\n",
      "2018-08-24 10:41:27,973: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n",
      "2018-08-24 10:41:29,554: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from datetime import datetime\n",
    "import utils, preprocessing, generate_candidate\n",
    "import fast_feature_extraction, generate_keyphrase\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only run one time, if pickles have been generated, please skip into next step\n",
    "\n",
    "train_directory = natsorted(glob.glob('./data/inspec/train/dummy/*.xml'))\n",
    "train_raw = preprocessing.load_xml_non_title(train_directory)\n",
    "pickle_train_raw = utils.create_pickle(train_raw,'./pickle/inspec/dummy train raw')\n",
    "train_data = preprocessing.create_xml_corpus(train_raw)\n",
    "pickle_train_data = utils.create_pickle(train_data,'./pickle/inspec/dummy train data')\n",
    "train_tf_corpus = fast_feature_extraction.calculate_tf(train_data, vocab = None, type = 'ngram')\n",
    "pickle_train_tf_corpus = utils.create_pickle(train_tf_corpus,'./pickle/inspec/dummy train tf corpus')\n",
    "\n",
    "###load testing data\n",
    "test_directory = natsorted(glob.glob('./data/inspec/test/dummy/*.xml'))\n",
    "test_raw = preprocessing.load_xml_non_title(test_directory)\n",
    "pickle_test_raw = utils.create_pickle(test_raw,'./pickle/inspec/dummy test raw')\n",
    "test_data = preprocessing.create_xml_corpus(test_raw)\n",
    "pickle_test_data = utils.create_pickle(test_data,'./pickle/inspec/dummy test data')\n",
    "test_tf_corpus = fast_feature_extraction.calculate_tf(test_data, vocab = None, type = 'ngram')\n",
    "pickle_test_tf_corpus = utils.create_pickle(test_tf_corpus,'./pickle/inspec/dummy test tf corpus')\n",
    "\n",
    "'''\n",
    "#create label\n",
    "uncontr_train_label_directory = open('./data/Inspec/references/train.uncontr.stem.json')\n",
    "uncontr_train_label = preprocessing.extract_json_label(uncontr_train_label_directory, \n",
    "                                                     raw_data = train_raw, file_type='default')\n",
    "uncontr_train_label_pickle = utils.create_pickle(uncontr_train_label, \n",
    "                                                 './pickle/Inspec/uncontr train label')\n",
    "\n",
    "uncontr_test_label_directory = open('./data/Inspec/references/test.uncontr.stem.json')\n",
    "uncontr_test_label = preprocessing.extract_json_label(uncontr_test_label_directory, \n",
    "                                                    raw_data = test_raw, file_type='default')\n",
    "uncontr_test_label_pickle = utils.create_pickle(uncontr_test_label, \n",
    "                                             './pickle/Inspec/uncontr test label')\n",
    "'''\n",
    "uncontr_train_label = utils.open_pickle('./pickle/inspec/train uncontr label')\n",
    "uncontr_test_label = utils.open_pickle('./pickle/inspec/test uncontr label')\n",
    "\n",
    "###Ngram version\n",
    "ngram_candidates = generate_candidate.calculate_tfidf(train_data, vocab=None, type='ngram') \n",
    "pickle_ngram_candidates = utils.create_pickle(ngram_candidates, './pickle/inspec/dummy ngram candidates')\n",
    "test_ngram_candidates = generate_candidate.calculate_tfidf(test_data, vocab=None, type='ngram') \n",
    "pickle_test_ngram_candidates = utils.create_pickle(test_ngram_candidates, \n",
    "                                                   './pickle/inspec/dummy test ngram candidates')\n",
    "#for supervised\n",
    "supervised_key = fast_feature_extraction.create_supervised_list(uncontr_train_label, train_tf_corpus)\n",
    "supervised_corpus = utils.create_pickle(supervised_key, './pickle/inspec/dummy supervised keyphraseness')\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening all pickles\n",
      "Prediction on uncontrol label - 10 keywords\n",
      "Accuracy on training data with Cross-validation:\n",
      "LR: 0.951 (0.006)\n",
      "NB: 0.903 (0.029)\n",
      "RF: 0.982 (0.011)\n",
      "AdaBoost: 0.984 (0.010)\n",
      "Bagging: 0.982 (0.010)\n",
      "GradientBoosting: 0.985 (0.009)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP: 0.952 (0.003)\n",
      "Evaluation metric on 10 keywords: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates,\\n                    train_data='./csv/inspec/uncontr_train_ngram', \\n                    test_data='./csv/inspec/uncontr_test_ngram', \\n                    csv_name='./csv/inspec/uncontr predicted ngram keyphrases keywords', \\n                    n_keyphrase = number_keyphrase)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation on Inspec with uncontrolled label (10 keywords)\n",
    "number_keyphrase = 10\n",
    "\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw = utils.open_pickle('./pickle/inspec/dummy train raw')\n",
    "train_data = utils.open_pickle('./pickle/inspec/dummy train data')\n",
    "\n",
    "uncontr_train_label = utils.open_pickle('./pickle/inspec/train uncontr label')\n",
    "train_tf_corpus = utils.open_pickle('./pickle/inspec/dummy train tf corpus')\n",
    "\n",
    "test_raw = utils.open_pickle('./pickle/inspec/dummy test raw')\n",
    "test_data = utils.open_pickle('./pickle/inspec/dummy test data')\n",
    "\n",
    "uncontr_test_label = utils.open_pickle('./pickle/inspec/test uncontr label')\n",
    "test_tf_corpus = utils.open_pickle('./pickle/inspec/dummy test tf corpus')\n",
    "\n",
    "train_topics = utils.open_pickle('./pickle/inspec/train topics')\n",
    "test_topics = utils.open_pickle('./pickle/inspec/test topics')\n",
    "\n",
    "ngram_candidates = utils.open_pickle('./pickle/inspec/dummy ngram candidates')\n",
    "test_ngram_candidates = utils.open_pickle('./pickle/inspec/dummy test ngram candidates')\n",
    "\n",
    "\n",
    "supervised_corpus = utils.open_pickle('./pickle/inspec/dummy supervised keyphraseness')\n",
    "\n",
    "#create examples on training and testing\n",
    "'''\n",
    "ngram_train = fast_feature_extraction.create_features(train_data, \n",
    "                ngram_candidates, uncontr_train_label, \n",
    "                supervised_corpus, train_tf_corpus, \n",
    "                train_topics, name='./csv/inspec/dummy_uncontr_train_ngram', \n",
    "                n_keyphrase = number_keyphrase)\n",
    "               \n",
    "ngram_test = fast_feature_extraction.create_features(test_data, \n",
    "                test_ngram_candidates, uncontr_test_label, \n",
    "                supervised_corpus, test_tf_corpus,\n",
    "                test_topics, name='./csv/inspec/dummy_uncontr_test_ngram',\n",
    "                n_keyphrase = number_keyphrase)\n",
    "'''\n",
    "\n",
    "print(\"Prediction on uncontrol label - 10 keywords\")\n",
    "ngram_prediction = generate_keyphrase.cross_validation( \n",
    "                uncontr_train_label, train_data='./csv/inspec/dummy_uncontr_train_ngram' \n",
    "                )\n",
    "\n",
    "print('Evaluation metric on 10 keywords:', ngram_prediction)\n",
    "'''\n",
    "ngram_prediction_keyphrase = generate_keyphrase.get_predicted_keyphrases(test_ngram_candidates,\n",
    "                    train_data='./csv/inspec/uncontr_train_ngram', \n",
    "                    test_data='./csv/inspec/uncontr_test_ngram', \n",
    "                    csv_name='./csv/inspec/uncontr predicted ngram keyphrases keywords', \n",
    "                    n_keyphrase = number_keyphrase)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = generate_keyphrase.feature_selection(train_data='./csv/inspec/uncontr_train_ngram')\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs = generate_keyphrase.feature_selection(train_data='./csv/inspec/uncontr_test_ngram')\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
