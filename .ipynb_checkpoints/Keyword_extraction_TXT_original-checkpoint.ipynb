{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, re, string, itertools\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from time import time\n",
    "from nltk.stem.porter import *\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk.chunk import tree2conlltags\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn import svm \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def create_pickle(data, name):\n",
    "    with open('%s.pickle' % name,'wb') as handle:\n",
    "        result=pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return result\n",
    "\n",
    "def open_pickle(name):\n",
    "    with open('%s.pickle' % name,'rb') as handle:\n",
    "        result=pickle.load(handle)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input_list):\n",
    "    result=[]\n",
    "    #remove unwanted character per line\n",
    "    for line in input_list:\n",
    "        clean=re.sub(\"(\\.)?\\n\",'', line) #remove \\n\n",
    "        clean=re.sub(\"('s)\",'', clean) #remove 's\n",
    "        clean=re.sub(\"\\[([0-9]{1,2}\\,?\\s?)+\\]\",'', clean) #remove [2]\n",
    "        clean=re.sub(\"\\(([0-9]{1,2}\\,?\\s?)+\\)\",'', clean) #remove (2)\n",
    "        #clean=re.sub(r\"\\b(iv|ix|x|v?i{0,3})+\\b\",'', clean) #remove roman number\n",
    "        #remove fig. 2 etc, need improvement to catch the sentence after it\n",
    "        #clean=re.sub(r\"\\b(i.e.g.|e.g.|i.e.)\",'', clean) #remove i.e.g., i.e., e.g.\n",
    "        clean=re.sub(\"([Ff]ig.|[Ff]igure|[Tt]ab.|[Tt]able)\\s?[0-9]{1,2}\",'', clean) #remove fig. 2 etc\n",
    "        clean=re.sub(r\"\\b((https?://|www.)[^\\s]+)\",'', clean) #remove email\n",
    "        result.append(clean)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    raw=[]\n",
    "    for file in path:\n",
    "        dict_doc={'doc_id': None, 'title': None, 'abstract': None, 'introduction': None, 'full-text': None}\n",
    "        file_id=os.path.basename(file).rstrip('.txt.final') #catch only file name  \n",
    "        dict_doc['doc_id']=file_id\n",
    "        \n",
    "        source=open(file,encoding='utf-8').readlines()\n",
    "        source=clean(source)\n",
    "        \n",
    "        ##########detect title\n",
    "        beginning=re.sub(\"\\n\", \"\", source[0]) #retrieve title\n",
    "        candidate=re.sub(\"\\n\", \"\", source[1]) # retrieve title candidate\n",
    "        h_candidate=word_tokenize(re.sub(\"-\",' ',candidate)) #tokenize the candidate\n",
    "        \n",
    "        title=[]\n",
    "        name=[]\n",
    "        for word in h_candidate:\n",
    "            if wordnet.synsets(word): #check if title candidate exist on wordnet\n",
    "                title.append(word)\n",
    "            else:\n",
    "                name.append(word)\n",
    "            #if title>\n",
    "            if len(title)>len(name): \n",
    "                newtitle=beginning+' '+candidate\n",
    "            elif len(title)==len(name):\n",
    "                newtitle=beginning\n",
    "            else:\n",
    "                newtitle=beginning\n",
    "\n",
    "        dict_doc['title']=newtitle\n",
    "        \n",
    "        content=source[2:]\n",
    "        ######check header, inconsistency all file\n",
    "        r_intro=re.compile(\"^1\\.?\\s[A-Z]+\")\n",
    "        r_after_intro=re.compile(\"^2\\.?\\s[A-Z]+\")\n",
    "        r_ref=re.compile(\"[0-9]{1,2}?\\.?\\s?R[EFERENCES|eferences]\") #detect reference\n",
    "        #r_header=re.compile(\"[0-9]{1,2}?\\.?\\s?[A-Z]\")\n",
    "        \n",
    "        in_abstract=content.index('ABSTRACT')\n",
    "        in_authorkey=content.index('Categories and Subject Descriptors')\n",
    "        \n",
    "        list_intro=[i for i, item in enumerate(content) if re.search(r_intro, item)]\n",
    "        in_intro=list_intro[0]\n",
    "        list_after_intro=[i for i, item in enumerate(content) if re.search(r_after_intro, item)]\n",
    "        in_after_intro=list_after_intro[0]\n",
    "        list_ref=[i for i, item in enumerate(content) if re.search(r_ref, item)]\n",
    "        in_ref=list_ref[0]\n",
    "        \n",
    "        abstract=content[in_abstract+1:in_authorkey] #eliminate keyword and category\n",
    "        intro=content[in_intro+1:in_after_intro]\n",
    "        body=content[in_after_intro+1:in_ref]      \n",
    "        \n",
    "        list_title=[]\n",
    "        list_title.append(newtitle)\n",
    "        \n",
    "        full_text=list(chain(list_title, abstract, intro, body))\n",
    "        dict_doc['abstract']=abstract\n",
    "        dict_doc['introduction']=intro\n",
    "        dict_doc['body']=body\n",
    "        dict_doc['full_text']=full_text\n",
    "        \n",
    "        #per sentence in a document\n",
    "        raw.append(dict_doc)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to tfidfvectorizer format\n",
    "#corpus=['a','b','c']\n",
    "#RENAME TO CREATE CORPUS\n",
    "def create_corpus(raw_data):\n",
    "    train_data=[]\n",
    "    for doc in raw_data:\n",
    "        #add to list and join all element in full text into a text\n",
    "        train_data.append(' '.join(doc['full_text']))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_tfidf(corpus):\n",
    "    \n",
    "    #porter stemmer\n",
    "    stemmer=PorterStemmer()\n",
    "\n",
    "    #eliminate ngram which starts or ends from stopwords\n",
    "    #from https://stackoverflow.com/questions/49746555/sklearn-tfidfvectorizer-generate-custom\n",
    "    #-ngrams-by-not-removing-stopword-in-the/49775000#49775000\n",
    "    class NewTfidfVectorizer(TfidfVectorizer):\n",
    "        def _word_ngrams(self, tokens, stop_words=None):\n",
    "            # First get tokens without stop words\n",
    "            tokens = super(TfidfVectorizer, self)._word_ngrams(tokens, None)\n",
    "            if stop_words is not None:\n",
    "                new_tokens=[]\n",
    "                for token in tokens:\n",
    "                    split_words = token.split(' ')\n",
    "                    # Only check the first and last word for stop words\n",
    "                    if len(token)>2 and split_words[0] not in stop_words and split_words[-1] not in stop_words:\n",
    "                        #stem every word in token\n",
    "                        if len(split_words)==1 and len(split_words[0])>2:\n",
    "                            new_tokens.append(stemmer.stem(token))\n",
    "                        elif len(split_words)==2 and split_words[-1]==\"'\":\n",
    "                            del(token)\n",
    "                        elif len(split_words[0])<3 and len(split_words[1])<3:\n",
    "                            del(token)\n",
    "                        elif split_words[1]==\"'\" and split_words[2]==\"s\":\n",
    "                            new_tokens.append(stemmer.stem(split_words[0])+split_words[1]+split_words[2])\n",
    "                        else:\n",
    "                            new_tokens.append(' '.join(list(stemmer.stem(word) for word in word_tokenize(token))))\n",
    "                return new_tokens\n",
    "            return tokens\n",
    "    \n",
    "    stop_words=text.ENGLISH_STOP_WORDS\n",
    "    \n",
    "    tfidf=NewTfidfVectorizer(ngram_range=(1,5), stop_words=stop_words,\n",
    "                                token_pattern=r\"(?u)\\b[A-Za-z-]+\\b\")\n",
    "    \n",
    "    matrix=tfidf.fit_transform(corpus)\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "\n",
    "    #how to print tf-idf from https://stackoverflow.com/questions/34449127/\n",
    "    #sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "    candidates=[]\n",
    "    for doc in range(0,len(corpus)):\n",
    "        feature_index=matrix[doc,:].nonzero()[1]\n",
    "        tfidf_doc=zip(feature_index, [matrix[doc, x] for x in feature_index])\n",
    "        names_tfidf=[(w, s) for w, s in [(feature_names[i], s) for (i, s) in tfidf_doc]]\n",
    "        candidates.append(names_tfidf)\n",
    "    \n",
    "    #this is the candidates per document\n",
    "    #vocab_perdoc=tfidf.inverse_transform(matrix)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate noun phrases based on corpus\n",
    "def create_phrase_vocabulary(raw_data):\n",
    "    \n",
    "    #porter stemmer\n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    #from http://bdewilde.github.io/blog/2014/09/23/intro-to-automatic-keyphrase-extraction/\n",
    "    #basic\n",
    "    #grammar=r'NP: {(<JJ.*>* <NN.*>+ <IN>)? (<JJ.*>* <NN.*>+)+}' #only detect noun phrases that contain specific pattern, hypen word is counted as one NN\n",
    "    \n",
    "    #grammar from c-value\n",
    "    #grammar=r'NP: {((<JJ.*>|<NN.*>)+ | ((<JJ.*>|<NN.*>)* (<IN>)?) (<JJ.*>|<NN.*>)\n",
    "    #test new grammar\n",
    "    grammar=r'NP: {(<JJ.*>* <VBN>? <NN.*>+ <IN>)? <JJ.*>* <VBG>? <NN.*>+}' \n",
    "    \n",
    "    punct = set(string.punctuation) #list of punctuation\n",
    "    chunker = RegexpParser(grammar) #chunker from nltk\n",
    "    \n",
    "    def lambda_unpack(f):\n",
    "        return lambda args:f(*args)\n",
    "    \n",
    "    postag_sents = pos_tag_sents(word_tokenize(sent) for sent in raw_data) #tokenize and create pos tag per sentence\n",
    "    #list of IOB of noun phrases based on the specific grammar\n",
    "    noun_phrases = list(chain.from_iterable(tree2conlltags(chunker.parse(tagged_sent)) for tagged_sent in postag_sents)) \n",
    "    \n",
    "    #join B-NP and I-NP tags as one noun phrase excluding O tags    \n",
    "    merged_nounphrase = [' '.join(stemmer.stem(word) for word, pos, chunk in group).lower() for key, group in\n",
    "                    itertools.groupby(noun_phrases, lambda_unpack(lambda word, pos, chunk: chunk != 'O')) if key]\n",
    "    \n",
    "    #filter noun phrases from stopwords and punctuation\n",
    "    all_nounphrases=[cand for cand in merged_nounphrase\n",
    "            if len(cand)>2 and not all(char in punct for char in cand)]\n",
    "    \n",
    "    #select distinct noun phrases\n",
    "    vocabulary=(list(set(all_nounphrases)))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nounphrase_tfidf(corpus, voc):\n",
    "    \n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "        def build_tokenizer(self):\n",
    "            tokenizer=super(TfidfVectorizer, self).build_tokenizer()\n",
    "            return lambda doc: (stemmer.stem(token) for token in tokenizer(doc) if token not in stop_words)\n",
    "\n",
    "    stop_words=set(text.ENGLISH_STOP_WORDS)\n",
    "    s=['of','in','on','for']\n",
    "    stop_words=stop_words.difference(s)\n",
    "    tfidf=StemmedTfidfVectorizer(ngram_range=(1,5), stop_words=stop_words, vocabulary=voc, token_pattern=r\"(?u)\\b[A-Za-z-]+\\b\")\n",
    "    \n",
    "    matrix=tfidf.fit_transform(corpus)\n",
    "    feature_names=tfidf.get_feature_names()\n",
    "\n",
    "    #how to print tf-idf from https://stackoverflow.com/questions/34449127/\n",
    "    #sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "    candidates=[]\n",
    "    for doc in range(0,len(corpus)):\n",
    "        feature_index=matrix[doc,:].nonzero()[1]\n",
    "        tfidf_doc=zip(feature_index, [matrix[doc, x] for x in feature_index])\n",
    "        names_tfidf=[(w, s) for w, s in [(feature_names[i], s) for (i, s) in tfidf_doc]]\n",
    "        candidates.append(names_tfidf)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###sorting candidates based on 15 keywords\n",
    "def get_top_candidates(candidates_list, number_keyphrases):\n",
    "    best_candidates=[]\n",
    "    for doc in candidates_list:\n",
    "        #sort candidates by tf-idf value\n",
    "        sorted_candidates=sorted(doc, key=lambda x: x[1], reverse=True)[:number_keyphrases]\n",
    "        #best_candidates.append(sorted_candidates)\n",
    "        best_candidates.append([x for x,_ in sorted_candidates])\n",
    "        #remove overlapping keywords\n",
    "    return best_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###compare candidates to goldstandard\n",
    "def extract_goldkeyphrase(gold_data):\n",
    "    \n",
    "    r_plus=re.compile(\"^.*\\+.*$\")\n",
    "    r_slash=re.compile(\"^.*\\s.*\\/.*$\")\n",
    "    \n",
    "    gold_standard=[]\n",
    "    for line in gold_data.split('\\n'):\n",
    "        doc=[]      \n",
    "        for key in line[6:].split(','):\n",
    "            if key[0]==' ':\n",
    "                doc.append(key[1:])\n",
    "            elif re.search(r_plus, key):\n",
    "                split=[]\n",
    "                for element in key.split('+'):\n",
    "                    doc.append(element)\n",
    "            elif re.search(r_slash, key):\n",
    "                split=[]\n",
    "                for element in key.split('/'):\n",
    "                    doc.append(element)\n",
    "            else:\n",
    "                doc.append(key)\n",
    "        gold_standard.append(doc)\n",
    "    return gold_standard\n",
    "\n",
    "def calculate_fmeasure(candidates_list, gold_data):\n",
    "    #true positive\n",
    "    all_matches=[]\n",
    "    for index in range(len(candidates_list)):\n",
    "        #store all measure per document in dic\n",
    "        value={'tp': None, 'fp': None, 'fn': None, 'gold': None}\n",
    "        value['gold']=len(gold_data[index])\n",
    "        #counter true positive per document\n",
    "        true_positive=0\n",
    "        #loop between elements\n",
    "        for element_candidate in candidates_list[index]:                    \n",
    "            for element_goldkeyphrase in gold_data[index]:\n",
    "                #matched predicted keyword in gold keyphrase\n",
    "                if element_candidate==element_goldkeyphrase:\n",
    "                    #matches_perdoc.append(element_candidate)\n",
    "                    true_positive+=1\n",
    "            #if need the detail of evaluation\n",
    "            value['tp']=int(true_positive) #matched pair\n",
    "            value['fp']=int(15-true_positive) #depend how many keyword should we use\n",
    "            value['fn']=int(value['gold']-value['tp'])\n",
    "        #return all metrics per document\n",
    "        all_matches.append(value)\n",
    "\n",
    "    true_positive=sum(doc['tp'] for doc in all_matches)\n",
    "    false_positive=sum(doc['fp'] for doc in all_matches)\n",
    "    false_negative=sum(doc['fn'] for doc in all_matches)\n",
    "    \n",
    "    #matched/total top n\n",
    "    precision=float(true_positive/(false_positive+true_positive))\n",
    "    #matched/total gold standard\n",
    "    recall=float(true_positive/(false_negative+true_positive))\n",
    "    # calculate with micro averagedprecision\n",
    "    f_measure=float(\"{0:.2F}\".format(2*(precision*recall)/(precision+recall)*100))\n",
    "    return f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_term_frequency(section):\n",
    "     #porter stemmer\n",
    "    stemmer=PorterStemmer()\n",
    "    \n",
    "    #eliminate ngram which starts or ends from stopwords\n",
    "    class NewCountVectorizer(CountVectorizer):\n",
    "        def _word_ngrams(self, tokens, stop_words=None):\n",
    "            # First get tokens without stop words\n",
    "            tokens = super(CountVectorizer, self)._word_ngrams(tokens, None)\n",
    "            if stop_words is not None:\n",
    "                new_tokens=[]\n",
    "                for token in tokens:\n",
    "                    split_words = token.split(' ')\n",
    "                    # Only check the first and last word for stop words\n",
    "                    if len(token)>2 and split_words[0] not in stop_words and split_words[-1] not in stop_words:\n",
    "                        #stem every word in token\n",
    "                        if len(split_words)==1 and len(split_words[0])>2:\n",
    "                            new_tokens.append(stemmer.stem(token))\n",
    "                        elif len(split_words)==2 and split_words[-1]==\"'\":\n",
    "                            del(token)\n",
    "                        elif len(split_words[0])<3 and len(split_words[1])<3:\n",
    "                            del(token)\n",
    "                        elif split_words[1]==\"'\" and split_words[2]==\"s\":\n",
    "                            new_tokens.append(stemmer.stem(split_words[0])+split_words[1]+split_words[2])\n",
    "                        else:\n",
    "                            new_tokens.append(' '.join(list(stemmer.stem(word) for word in word_tokenize(token))))\n",
    "                return new_tokens\n",
    "            return tokens\n",
    "    \n",
    "    stop_words=text.ENGLISH_STOP_WORDS\n",
    "    \n",
    "    count_vect=NewCountVectorizer(ngram_range=(1,5), stop_words=stop_words,\n",
    "                                token_pattern=r\"(?u)\\b[A-Za-z-]+\\b\")\n",
    "    \n",
    "    matrix=count_vect.fit_transform(section)\n",
    "    feature_names=count_vect.get_feature_names()\n",
    "\n",
    "    #how to print tf-idf from https://stackoverflow.com/questions/34449127/\n",
    "    #sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-document\n",
    "    ngrams=[]\n",
    "    for doc in range(0,len(section)):\n",
    "        feature_index=matrix[doc,:].nonzero()[1]\n",
    "        count_vect_doc=zip(feature_index, [matrix[doc, x] for x in feature_index])\n",
    "        names_count_vect=[(w, s) for w, s in [(feature_names[i], s) for (i, s) in count_vect_doc]]\n",
    "        ngrams.append(names_count_vect)\n",
    "    \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Dont run it twice\n",
    "#----------------------------------------------------TF-IDF version\n",
    "###load training data\n",
    "train_directory=glob.glob('./se_txt/train/*.txt.final')\n",
    "train_raw=load_files(train_directory)\n",
    "pickle_train_raw=create_pickle(train_raw,'txt train raw')\n",
    "train_data=create_corpus(train_raw)\n",
    "pickle_train_data=create_pickle(train_data,'txt train data')\n",
    "train_tf_corpus=calculate_term_frequency(train_data)\n",
    "pickle_train_tf_corpus=create_pickle(train_tf_corpus,'txt train tf corpus')\n",
    "\n",
    "\n",
    "#load gold keyphrase\n",
    "train_label_directory=open('./se_txt/train/train.combined.stem.final', encoding='utf-8').read()\n",
    "train_label=extract_goldkeyphrase(train_label_directory)\n",
    "pickle_train_label=create_pickle(train_label, 'txt train label')\n",
    "\n",
    "###Load testing data\n",
    "test_directory=glob.glob('./se_txt/test/*.txt.final')\n",
    "test_raw=load_files(test_directory)\n",
    "pickle_test_raw=create_pickle(test_raw,'txt test raw')\n",
    "test_data=create_corpus(test_raw)\n",
    "pickle_test_data=create_pickle(test_data,'txt test data')\n",
    "test_tf_corpus=calculate_term_frequency(test_data)\n",
    "pickle_test_tf_corpus=create_pickle(test_tf_corpus,'txt test tf corpus')\n",
    "\n",
    "test_label_directory=open('./se_txt/test_answer/test.combined.stem.final', encoding='utf-8').read()\n",
    "test_label=extract_goldkeyphrase(test_label_directory)\n",
    "pickle_test_label=create_pickle(test_label, 'txt test label')\n",
    "\n",
    "#### Ngram version\n",
    "print(\"N-gram TF-IDF version\")\n",
    "ngram_candidates=calculate_ngram_tfidf(train_data) \n",
    "pickle_ngram_candidates=create_pickle(ngram_candidates, 'txt ngram candidates')\n",
    "#ngram_top_keyphrases=get_top_candidates(ngram_candidates, 15)\n",
    "#ngram_fmeasure=calculate_fmeasure(ngram_top_keyphrases, train_label)\n",
    "#print(\"F-measure on training:\", ngram_fmeasure)\n",
    "\n",
    "test_ngram_candidates=calculate_ngram_tfidf(test_data)\n",
    "pickle_test_ngram_candidates=create_pickle(test_ngram_candidates, 'txt test ngram candidates')\n",
    "#test_ngram_top_candidates=get_top_candidates(test_ngram_candidates, 15)\n",
    "#test_ngram_fmeasure=calculate_fmeasure(test_ngram_top_candidates, test_label)\n",
    "#print(\"F-measure on testing:\", test_ngram_fmeasure)\n",
    "\n",
    "\n",
    "#### Noun phrase version\n",
    "print(\"Noun phrase TF-IDF version\")\n",
    "nounphrase_vocabulary=create_phrase_vocabulary(train_data)\n",
    "train_tf_nounphrase_corpus=calculate_tf_nounphrase(train_data, nounphrase_vocabulary)\n",
    "pickle_train_tf_nounphrase_corpus=create_pickle(train_tf_nounphrase_corpus,'txt train tf nounphrase corpus')\n",
    "nounphrase_candidates=calculate_nounphrase_tfidf(train_data, nounphrase_vocabulary)\n",
    "pickle_nounphrase_candidates=create_pickle(nounphrase_candidates, 'txt nounphrase candidates')\n",
    "#nounphrase_top_keyphrases=get_top_candidates(nounphrase_candidates, 15)\n",
    "#nounphrase_fmeasure=calculate_fmeasure(nounphrase_top_keyphrases, train_label)\n",
    "#print(\"F-measure on training:\", nounphrase_fmeasure)\n",
    "\n",
    "test_nounphrase_vocabulary=create_phrase_vocabulary(test_data)\n",
    "test_tf_nounphrase_corpus=calculate_tf_nounphrase(test_data, test_nounphrase_vocabulary)\n",
    "pickle_test_tf_nounphrase_corpus=create_pickle(test_tf_nounphrase_corpus,'txt test tf nounphrase corpus')\n",
    "test_nounphrase_candidates=calculate_nounphrase_tfidf(test_data, test_nounphrase_vocabulary)\n",
    "pickle_test_nounphrase_candidates=create_pickle(test_nounphrase_candidates, 'txt test nounphrase candidates')\n",
    "#test_nounphrase_top_candidates=get_top_candidates(test_nounphrase_candidates, 15)\n",
    "#test_nounphrase_fmeasure=calculate_fmeasure(test_nounphrase_top_candidates, test_label)\n",
    "#print(\"F-measure on testing:\", test_nounphrase_fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_corpus(corpus):\n",
    "    clean=[]\n",
    "    stemmer=PorterStemmer()\n",
    "    for doc in corpus:\n",
    "        cleaned_words=\" \".join([word for word in word_tokenize(doc.lower()) if re.search(r\"\\b[A-Za-z-]+\\b\", word) and len(word)>2])\n",
    "        stemmed_words=[stemmer.stem(word) for word in cleaned_words.split()]\n",
    "        clean.append(\" \".join([word for word in stemmed_words]))\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_data(raw_data, corpus, candidates, label, tf_corpus, name):\n",
    "    \n",
    "    #binary_title, frequency_title, binary_abstract, frequency_abstract, binary_introduction, frequency_introduction\n",
    "    def feature_structure(candidates, raw_data):\n",
    "        title_raw=[doc['title'] for doc in raw_data]\n",
    "        abstract_raw=[' '.join(doc['abstract']) for doc in raw_data]\n",
    "        introduction_raw=[' '.join(doc['introduction']) for doc in raw_data]  \n",
    "        title=calculate_term_frequency(title_raw)\n",
    "        abstract=calculate_term_frequency(abstract_raw)\n",
    "        introduction=calculate_term_frequency(introduction_raw) \n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_cand in range(len(candidates[n_doc])):\n",
    "                title_perdoc=[feature for (feature, value) in title[n_doc]]\n",
    "                abstract_perdoc=[feature for (feature, value) in abstract[n_doc]]\n",
    "                introduction_perdoc=[feature for (feature, value) in introduction[n_doc]]\n",
    "                if candidates[n_doc][n_cand][0] in title_perdoc:\n",
    "                    binary_title=1\n",
    "                    value=[value for (feature, value) in title[n_doc] if feature in candidates[n_doc][n_cand][0]]\n",
    "                    frequency_title=value[0]\n",
    "                else:\n",
    "                    binary_title=0\n",
    "                    frequency_title=0\n",
    "                if candidates[n_doc][n_cand][0] in abstract_perdoc:\n",
    "                    binary_abstract=1\n",
    "                    value=[value for (feature, value) in abstract[n_doc] if feature in candidates[n_doc][n_cand][0]]\n",
    "                    frequency_abstract=value[0]\n",
    "                else:\n",
    "                    binary_abstract=0\n",
    "                    frequency_abstract=0\n",
    "                if candidates[n_doc][n_cand][0] in introduction_perdoc:\n",
    "                    binary_introduction=1\n",
    "                    value=[value for (feature, value) in introduction[n_doc] if feature in candidates[n_doc][n_cand][0]]\n",
    "                    frequency_introduction=value[0]\n",
    "                else:\n",
    "                    binary_introduction=0\n",
    "                    frequency_introduction=0\n",
    "                doc.append(((binary_title, frequency_title, binary_abstract, frequency_abstract, binary_introduction, frequency_introduction)))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    def feature_candidate_length(candidates):\n",
    "        feature=[]\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_feature in range(len(candidates[n_doc])):\n",
    "                doc.append(len(candidates[n_doc][n_feature][0]))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "        \n",
    "    def feature_frequency(label, tf_corpus):\n",
    "        merged_labels=list(chain.from_iterable(label))\n",
    "        feature=[]\n",
    "        for n_doc in range(len(tf_corpus)):\n",
    "            doc=[]\n",
    "            for n_cand in range(len(tf_corpus[n_doc])):\n",
    "                cand_freq=tf_corpus[n_doc][n_cand][1]\n",
    "                if tf_corpus[n_doc][n_cand][0] not in merged_labels:\n",
    "                    supervised=0\n",
    "                else:\n",
    "                    supervised=tf_corpus[n_doc][n_cand][1]\n",
    "                doc.append(((cand_freq, supervised)))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    #create first, last occurence, distance from first occurence, spread from first and last occurence\n",
    "    def feature_occurence(candidates, corpus):\n",
    "        feature=[]\n",
    "        cleaned_corpus=clean_corpus(corpus)\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            corpus_words=len(cleaned_corpus[n_doc].split(\" \"))\n",
    "            for n_cand in range(len(candidates[n_doc])):\n",
    "                first_index=cleaned_corpus[n_doc].lower().find(candidates[n_doc][n_cand][0])\n",
    "                last_index=cleaned_corpus[n_doc].lower().rfind(candidates[n_doc][n_cand][0])\n",
    "                preceding_words=len(cleaned_corpus[n_doc][:first_index].split(\" \"))-1\n",
    "                following_words=len(cleaned_corpus[n_doc][:last_index].split(\" \"))-1\n",
    "                distance=float(\"{0:.6F}\".format(preceding_words/corpus_words))\n",
    "                spread=len(cleaned_corpus[n_doc][first_index:last_index].split(\" \"))-1\n",
    "                doc.append(((preceding_words, following_words, distance, spread)))\n",
    "            feature.append(doc)\n",
    "        return feature\n",
    "    \n",
    "    \n",
    "    #lists of feature\n",
    "    feature2=feature_structure(candidates, raw_data)\n",
    "    feature3=feature_candidate_length(candidates)\n",
    "    feature4=feature_frequency(label, tf_corpus)\n",
    "    feature5=feature_occurence(candidates, corpus)\n",
    "    \n",
    "    #add values of all features into candidate list\n",
    "    for n_doc in range(len(candidates)):\n",
    "        for n_candidate in range(len(candidates[n_doc])):\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate][0],) #b_title\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate][1],) #n_title\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate][2],) #b_abstract\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate][3],) #n_abstract\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate][4],) #b_intro\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate][5],) #n_intro\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature3[n_doc][n_candidate],)    #length\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature4[n_doc][n_candidate][0],) #tf\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature4[n_doc][n_candidate][1],) #supervised\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature5[n_doc][n_candidate][0],) #first_occurence\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature5[n_doc][n_candidate][1],) #last_occurrence\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature5[n_doc][n_candidate][2],) #distance\n",
    "            candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature5[n_doc][n_candidate][3],) #spread\n",
    "            \n",
    "    #create example as well as label\n",
    "    x_data=[]\n",
    "    y_label=[]\n",
    "    header=['candidates','tf-idf', 'b_title', 'n_title', 'b_abstract', 'n_abstract', 'b_intro', 'n_intro', 'length', \n",
    "            'tf', 'supervised_key', 'first_occurr', 'last_occurr', 'distance', 'spread']\n",
    "\n",
    "    #merge all features and create label\n",
    "    for n_doc in range(len(candidates)):\n",
    "        for n_candidate in range(len(candidates[n_doc])):\n",
    "            keyphrase_document=list(label[n_doc])\n",
    "            if candidates[n_doc][n_candidate][0] not in keyphrase_document:\n",
    "                y_label.append(0)\n",
    "            else:\n",
    "                y_label.append(1)            \n",
    "            x_data.append(list(candidates[n_doc][n_candidate]))\n",
    "    \n",
    "    data=df.from_records(x_data, columns=header)\n",
    "    data['label']=pd.Series(y_label).values\n",
    "    csv=data.to_csv('%s_data.csv' % name, encoding='utf-8')\n",
    "    \n",
    "    return 'complete to create machine learning data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_to_fmeasure(predict_proba, candidates, labels, models):\n",
    "\n",
    "    #all_fmeasure=[]\n",
    "    for model in range(0, len(predict_proba)):\n",
    "        probability=[]\n",
    "        counter=0\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_cand in range(len(candidates[n_doc])):\n",
    "                doc.append((candidates[n_doc][n_cand][0], predict_proba[model][counter]))\n",
    "                counter+=1\n",
    "            probability.append(doc)\n",
    "        fmeasure=calculate_fmeasure(get_top_candidates(probability, 15), labels)\n",
    "        print(\"Model %s: %.3f\" % (models[model][0], fmeasure))\n",
    "        #all_fmeasure.append((models[model][0], fmeasure))\n",
    "    return 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(candidates, labels, train_data, test_data):\n",
    "    \n",
    "    features=['tf-idf', 'b_title', 'n_title', 'b_abstract', 'n_abstract', 'b_intro', 'n_intro', 'length', \n",
    "            'tf', 'supervised_key', 'first_occurr', 'last_occurr', 'distance', 'spread']\n",
    "   \n",
    "    x_train=pd.read_csv('%s_data.csv' % train_data)[features].values\n",
    "    y_train=pd.read_csv('%s_data.csv' % train_data)['label'].values\n",
    "    \n",
    "    x_test=pd.read_csv('%s_data.csv' % test_data)[features].values\n",
    "    y_test=pd.read_csv('%s_data.csv' % train_data)['label'].values\n",
    "    \n",
    "    seed = 7 #just randomly select the number\n",
    "    models = []\n",
    "    models.append(('LR', LogisticRegression(C=1)))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('DT', DecisionTreeClassifier()))\n",
    "    #models.append(('SVM', SVC(probability=True)))\n",
    "    models.append(('RF', RF(n_estimators=20, max_depth=11)))#highest\n",
    "    models.append(('AdaBoost', AdaBoostClassifier(n_estimators=70, learning_rate=1.0)))#highest, learning rate must be 1\n",
    "    models.append(('Bagging', BaggingClassifier(n_estimators=30)))#highest\n",
    "    models.append(('GradientBoosting', (GradientBoostingClassifier(n_estimators=85, learning_rate=0.2))))\n",
    "    models.append(('MLP', (MLPClassifier(learning_rate_init=0.0001)))) \n",
    "    \n",
    "    '''\n",
    "    #loop as many as features\n",
    "    print(\"Take one feature out\")\n",
    "    for feature in range(len(x_train[0])):\n",
    "        print(\"Remove feature number\", feature+1)\n",
    "     \n",
    "        modified_train=[doc[:feature]+doc[feature+1:] for doc in x_train] \n",
    "        modified_test=[doc[:feature]+doc[feature+1:] for doc in x_test]\n",
    "        \n",
    "        predict_proba=[]\n",
    "        for name, model in models:\n",
    "        #calculate F-score, recall and precision\n",
    "            #print(\"%s: %.3f\" % (name, accuracy_score(model.fit(modified_train, train_label).predict(modified_test), test_label)))\n",
    "            predict_proba.append(model.fit(x_train, y_train).predict_proba(x_test)[:,1])\n",
    "            \n",
    "        #calculate f-measure\n",
    "        fmeasure=probability_to_fmeasure(predict_proba, candidates, labels, models)\n",
    "    '''\n",
    "    \n",
    "    #results = []\n",
    "    #names = []\n",
    "    #scoring='accuracy'\n",
    "    #print(\"\\nAccuracy on testing data:\")\n",
    "    all_predict_proba=[]\n",
    "    for name, model in models:\n",
    "        #accuracy\n",
    "        #print(\"%s: %.3f\" % (name, accuracy_score(model.fit(x_train, y_train).predict(x_test), y_test)))\n",
    "        all_predict_proba.append(model.fit(x_train, y_train).predict_proba(x_test)[:,1])\n",
    "    \n",
    "    print(\"Fmeasure on full features:\")\n",
    "    all_fmeasure=[]\n",
    "    for model in range(0, len(all_predict_proba)):\n",
    "        probability=[]\n",
    "        counter=0\n",
    "        for n_doc in range(len(candidates)):\n",
    "            doc=[]\n",
    "            for n_cand in range(len(candidates[n_doc])):\n",
    "                doc.append((candidates[n_doc][n_cand][0], all_predict_proba[model][counter]))\n",
    "                counter+=1\n",
    "            probability.append(doc)\n",
    "        fmeasure=calculate_fmeasure(get_top_candidates(probability, 15), labels)\n",
    "        all_fmeasure.append((models[model][0], fmeasure))\n",
    "    return all_fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening all pickles\n",
      "time= 0:00:36.796570\n",
      "creating example on training\n",
      "creating data on training\n",
      "time= 0:06:08.843336\n",
      "creating data on testing\n",
      "time= 0:09:09.999786\n",
      "predicting the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fmeasure on full features:\n",
      "F-measure on noun phrase [('LR', 18.13), ('LDA', 18.13), ('NB', 14.67), ('DT', 9.83), ('RF', 21.65), ('AdaBoost', 23.37), ('Bagging', 17.73), ('GradientBoosting', 22.38), ('MLP', 10.76)]\n",
      "time= 0:10:15.291262\n"
     ]
    }
   ],
   "source": [
    "####with machine learning\n",
    "##NGRAM\n",
    "#open all pickle\n",
    "start=datetime.now()\n",
    "\n",
    "print(\"Opening all pickles\")\n",
    "train_raw=open_pickle('txt train raw')\n",
    "train_data=open_pickle('txt train data')\n",
    "\n",
    "train_label=open_pickle('txt train label')\n",
    "train_tf_corpus=open_pickle('txt train tf corpus')\n",
    "\n",
    "test_raw=open_pickle('txt test raw')\n",
    "test_data=open_pickle('txt test data')\n",
    "\n",
    "test_label=open_pickle('txt test label')\n",
    "test_tf_corpus=open_pickle('txt test tf corpus')\n",
    "\n",
    "'''\n",
    "ngram_candidates=open_pickle('txt ngram candidates')\n",
    "test_ngram_candidates=open_pickle('txt test ngram candidates')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "'''\n",
    "nounphrase_candidates=open_pickle('txt nounphrase candidates')\n",
    "test_nounphrase_candidates=open_pickle('txt test nounphrase candidates')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "\n",
    "print(\"creating example on training\")\n",
    "'''\n",
    "ngram_x_train=create_ml_data(train_raw, train_data, ngram_candidates, train_label, train_tf_corpus, name='train_ngram')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(\"creating example on testing\")\n",
    "ngram_x_test=create_ml_data(test_raw, test_data, test_ngram_candidates, test_label, test_tf_corpus, name='test_ngram')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "'''\n",
    "\n",
    "print(\"creating data on training\")\n",
    "nounphrase_train=create_ml_data(train_raw, train_data, nounphrase_candidates, train_label, train_tf_corpus, name='train_nounphrase')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "print(\"creating data on testing\")\n",
    "nounphrase_test=create_ml_data(test_raw, test_data, test_nounphrase_candidates, test_label, test_tf_corpus, name='test_nounphrase')\n",
    "print(\"time=\", datetime.now()-start)\n",
    "\n",
    "print(\"predicting the dataset\")\n",
    "'''\n",
    "ngram_prediction=predict_data(test_ngram_candidates, test_label, train_data='train_ngram', test_data='test_ngram')\n",
    "print('F-measure on ngram', ngram_prediction)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "'''\n",
    "\n",
    "nounphrase_prediction=predict_data(test_nounphrase_candidates, test_label, train_data='train_nounphrase', test_data='test_nounphrase')\n",
    "print('F-measure on noun phrase', nounphrase_prediction)\n",
    "print(\"time=\", datetime.now()-start)\n",
    "#print(len(x_train_ngram))#print(len(y_train_ngram))#print(len(x_test_ngram))#print(len(y_test_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If need cross validation per model\n",
    "###measure accuracy with k-fold\n",
    "print(\"Accuracy on training data with Cross-validation:\")\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, x_train_ngram, y_train_ngram, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "'''\n",
    "'''\n",
    "if need remove one feature\n",
    "\n",
    "    #loop as many as features\n",
    "    print(\"Take one feature out\")\n",
    "    for feature in range(len(x_train[0])):\n",
    "        print(\"Remove feature number\", feature+1)\n",
    "     \n",
    "        modified_train=[doc[:feature]+doc[feature+1:] for doc in x_train] \n",
    "        modified_test=[doc[:feature]+doc[feature+1:] for doc in x_test]\n",
    "        \n",
    "        predict_proba=[]\n",
    "        for name, model in models:\n",
    "        #calculate F-score, recall and precision\n",
    "            #print(\"%s: %.3f\" % (name, accuracy_score(model.fit(modified_train, train_label).predict(modified_test), test_label)))\n",
    "            predict_proba.append(model.fit(x_train, y_train).predict_proba(x_test)[:,1])\n",
    "            \n",
    "        #calculate f-measure\n",
    "        fmeasure=probability_to_fmeasure(predict_proba, candidates, labels, models)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates=[[('aa',1),('a',5),('a3',5),('a6',7)],\n",
    "            [('aq',3),('aw',4),('ag',2),('ar',8)]]\n",
    "\n",
    "feature1=[[3,4,5,6],\n",
    "            [7,9,6,5]]\n",
    "feature2=[[1,2,7,8],\n",
    "            [9,90,4,3]]\n",
    "\n",
    "for n_doc in range(len(candidates)):\n",
    "    for n_candidate in range(len(candidates[n_doc])):\n",
    "        candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature1[n_doc][n_candidate],)\n",
    "        candidates[n_doc][n_candidate]=candidates[n_doc][n_candidate]+(feature2[n_doc][n_candidate],)\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
